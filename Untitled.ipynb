{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1517427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d86f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(model):\n",
    "    print(model)\n",
    "    print(summary(model, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897f7cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "BertModel                                          --\n",
      "├─BertEmbeddings: 1-1                              --\n",
      "│    └─word_embeddings.weight                      ├─23,440,896\n",
      "│    └─position_embeddings.weight                  ├─393,216\n",
      "│    └─token_type_embeddings.weight                ├─1,536\n",
      "│    └─LayerNorm.weight                            ├─768\n",
      "│    └─LayerNorm.bias                              └─768\n",
      "│    └─Embedding: 2-1                              23,440,896\n",
      "│    │    └─weight                                 └─23,440,896\n",
      "│    └─Embedding: 2-2                              393,216\n",
      "│    │    └─weight                                 └─393,216\n",
      "│    └─Embedding: 2-3                              1,536\n",
      "│    │    └─weight                                 └─1,536\n",
      "│    └─LayerNorm: 2-4                              1,536\n",
      "│    │    └─weight                                 ├─768\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Dropout: 2-5                                --\n",
      "├─BertEncoder: 1-2                                 --\n",
      "│    └─layer.0.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.query.bias           ├─768\n",
      "│    └─layer.0.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.0.attention.self.key.bias             ├─768\n",
      "│    └─layer.0.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.value.bias           ├─768\n",
      "│    └─layer.0.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.0.attention.output.dense.bias         ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.0.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.0.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.0.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.0.output.dense.bias                   ├─768\n",
      "│    └─layer.0.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.0.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.1.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.query.bias           ├─768\n",
      "│    └─layer.1.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.1.attention.self.key.bias             ├─768\n",
      "│    └─layer.1.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.value.bias           ├─768\n",
      "│    └─layer.1.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.1.attention.output.dense.bias         ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.1.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.1.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.1.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.1.output.dense.bias                   ├─768\n",
      "│    └─layer.1.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.1.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.2.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.query.bias           ├─768\n",
      "│    └─layer.2.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.2.attention.self.key.bias             ├─768\n",
      "│    └─layer.2.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.value.bias           ├─768\n",
      "│    └─layer.2.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.2.attention.output.dense.bias         ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.2.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.2.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.2.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.2.output.dense.bias                   ├─768\n",
      "│    └─layer.2.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.2.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.3.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.query.bias           ├─768\n",
      "│    └─layer.3.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.3.attention.self.key.bias             ├─768\n",
      "│    └─layer.3.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.value.bias           ├─768\n",
      "│    └─layer.3.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.3.attention.output.dense.bias         ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.3.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.3.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.3.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.3.output.dense.bias                   ├─768\n",
      "│    └─layer.3.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.3.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.4.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.query.bias           ├─768\n",
      "│    └─layer.4.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.4.attention.self.key.bias             ├─768\n",
      "│    └─layer.4.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.value.bias           ├─768\n",
      "│    └─layer.4.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.4.attention.output.dense.bias         ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.4.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.4.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.4.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.4.output.dense.bias                   ├─768\n",
      "│    └─layer.4.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.4.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.5.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.query.bias           ├─768\n",
      "│    └─layer.5.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.5.attention.self.key.bias             ├─768\n",
      "│    └─layer.5.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.value.bias           ├─768\n",
      "│    └─layer.5.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.5.attention.output.dense.bias         ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.5.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.5.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.5.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.5.output.dense.bias                   ├─768\n",
      "│    └─layer.5.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.5.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.6.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.query.bias           ├─768\n",
      "│    └─layer.6.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.6.attention.self.key.bias             ├─768\n",
      "│    └─layer.6.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.value.bias           ├─768\n",
      "│    └─layer.6.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.6.attention.output.dense.bias         ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.6.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.6.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.6.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.6.output.dense.bias                   ├─768\n",
      "│    └─layer.6.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.6.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.7.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.query.bias           ├─768\n",
      "│    └─layer.7.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.7.attention.self.key.bias             ├─768\n",
      "│    └─layer.7.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.value.bias           ├─768\n",
      "│    └─layer.7.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.7.attention.output.dense.bias         ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.7.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.7.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.7.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.7.output.dense.bias                   ├─768\n",
      "│    └─layer.7.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.7.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.8.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.query.bias           ├─768\n",
      "│    └─layer.8.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.8.attention.self.key.bias             ├─768\n",
      "│    └─layer.8.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.value.bias           ├─768\n",
      "│    └─layer.8.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.8.attention.output.dense.bias         ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.8.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.8.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.8.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.8.output.dense.bias                   ├─768\n",
      "│    └─layer.8.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.8.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.9.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.query.bias           ├─768\n",
      "│    └─layer.9.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.9.attention.self.key.bias             ├─768\n",
      "│    └─layer.9.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.value.bias           ├─768\n",
      "│    └─layer.9.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.9.attention.output.dense.bias         ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.9.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.9.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.9.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.9.output.dense.bias                   ├─768\n",
      "│    └─layer.9.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.9.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.10.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.query.bias          ├─768\n",
      "│    └─layer.10.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.10.attention.self.key.bias            ├─768\n",
      "│    └─layer.10.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.value.bias          ├─768\n",
      "│    └─layer.10.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.10.attention.output.dense.bias        ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.10.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.10.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.10.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.10.output.dense.bias                  ├─768\n",
      "│    └─layer.10.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.10.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.11.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.query.bias          ├─768\n",
      "│    └─layer.11.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.11.attention.self.key.bias            ├─768\n",
      "│    └─layer.11.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.value.bias          ├─768\n",
      "│    └─layer.11.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.11.attention.output.dense.bias        ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.11.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.11.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.11.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.11.output.dense.bias                  ├─768\n",
      "│    └─layer.11.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.11.output.LayerNorm.bias              └─768\n",
      "│    └─ModuleList: 2-6                             --\n",
      "│    │    └─0.attention.self.query.weight          ├─589,824\n",
      "│    │    └─0.attention.self.query.bias            ├─768\n",
      "│    │    └─0.attention.self.key.weight            ├─589,824\n",
      "│    │    └─0.attention.self.key.bias              ├─768\n",
      "│    │    └─0.attention.self.value.weight          ├─589,824\n",
      "│    │    └─0.attention.self.value.bias            ├─768\n",
      "│    │    └─0.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─0.attention.output.dense.bias          ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─0.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─0.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─0.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─0.output.dense.bias                    ├─768\n",
      "│    │    └─0.output.LayerNorm.weight              ├─768\n",
      "│    │    └─0.output.LayerNorm.bias                ├─768\n",
      "│    │    └─1.attention.self.query.weight          ├─589,824\n",
      "│    │    └─1.attention.self.query.bias            ├─768\n",
      "│    │    └─1.attention.self.key.weight            ├─589,824\n",
      "│    │    └─1.attention.self.key.bias              ├─768\n",
      "│    │    └─1.attention.self.value.weight          ├─589,824\n",
      "│    │    └─1.attention.self.value.bias            ├─768\n",
      "│    │    └─1.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─1.attention.output.dense.bias          ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─1.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─1.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─1.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─1.output.dense.bias                    ├─768\n",
      "│    │    └─1.output.LayerNorm.weight              ├─768\n",
      "│    │    └─1.output.LayerNorm.bias                ├─768\n",
      "│    │    └─2.attention.self.query.weight          ├─589,824\n",
      "│    │    └─2.attention.self.query.bias            ├─768\n",
      "│    │    └─2.attention.self.key.weight            ├─589,824\n",
      "│    │    └─2.attention.self.key.bias              ├─768\n",
      "│    │    └─2.attention.self.value.weight          ├─589,824\n",
      "│    │    └─2.attention.self.value.bias            ├─768\n",
      "│    │    └─2.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─2.attention.output.dense.bias          ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─2.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─2.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─2.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─2.output.dense.bias                    ├─768\n",
      "│    │    └─2.output.LayerNorm.weight              ├─768\n",
      "│    │    └─2.output.LayerNorm.bias                ├─768\n",
      "│    │    └─3.attention.self.query.weight          ├─589,824\n",
      "│    │    └─3.attention.self.query.bias            ├─768\n",
      "│    │    └─3.attention.self.key.weight            ├─589,824\n",
      "│    │    └─3.attention.self.key.bias              ├─768\n",
      "│    │    └─3.attention.self.value.weight          ├─589,824\n",
      "│    │    └─3.attention.self.value.bias            ├─768\n",
      "│    │    └─3.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─3.attention.output.dense.bias          ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─3.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─3.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─3.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─3.output.dense.bias                    ├─768\n",
      "│    │    └─3.output.LayerNorm.weight              ├─768\n",
      "│    │    └─3.output.LayerNorm.bias                ├─768\n",
      "│    │    └─4.attention.self.query.weight          ├─589,824\n",
      "│    │    └─4.attention.self.query.bias            ├─768\n",
      "│    │    └─4.attention.self.key.weight            ├─589,824\n",
      "│    │    └─4.attention.self.key.bias              ├─768\n",
      "│    │    └─4.attention.self.value.weight          ├─589,824\n",
      "│    │    └─4.attention.self.value.bias            ├─768\n",
      "│    │    └─4.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─4.attention.output.dense.bias          ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─4.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─4.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─4.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─4.output.dense.bias                    ├─768\n",
      "│    │    └─4.output.LayerNorm.weight              ├─768\n",
      "│    │    └─4.output.LayerNorm.bias                ├─768\n",
      "│    │    └─5.attention.self.query.weight          ├─589,824\n",
      "│    │    └─5.attention.self.query.bias            ├─768\n",
      "│    │    └─5.attention.self.key.weight            ├─589,824\n",
      "│    │    └─5.attention.self.key.bias              ├─768\n",
      "│    │    └─5.attention.self.value.weight          ├─589,824\n",
      "│    │    └─5.attention.self.value.bias            ├─768\n",
      "│    │    └─5.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─5.attention.output.dense.bias          ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─5.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─5.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─5.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─5.output.dense.bias                    ├─768\n",
      "│    │    └─5.output.LayerNorm.weight              ├─768\n",
      "│    │    └─5.output.LayerNorm.bias                ├─768\n",
      "│    │    └─6.attention.self.query.weight          ├─589,824\n",
      "│    │    └─6.attention.self.query.bias            ├─768\n",
      "│    │    └─6.attention.self.key.weight            ├─589,824\n",
      "│    │    └─6.attention.self.key.bias              ├─768\n",
      "│    │    └─6.attention.self.value.weight          ├─589,824\n",
      "│    │    └─6.attention.self.value.bias            ├─768\n",
      "│    │    └─6.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─6.attention.output.dense.bias          ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─6.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─6.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─6.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─6.output.dense.bias                    ├─768\n",
      "│    │    └─6.output.LayerNorm.weight              ├─768\n",
      "│    │    └─6.output.LayerNorm.bias                ├─768\n",
      "│    │    └─7.attention.self.query.weight          ├─589,824\n",
      "│    │    └─7.attention.self.query.bias            ├─768\n",
      "│    │    └─7.attention.self.key.weight            ├─589,824\n",
      "│    │    └─7.attention.self.key.bias              ├─768\n",
      "│    │    └─7.attention.self.value.weight          ├─589,824\n",
      "│    │    └─7.attention.self.value.bias            ├─768\n",
      "│    │    └─7.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─7.attention.output.dense.bias          ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─7.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─7.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─7.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─7.output.dense.bias                    ├─768\n",
      "│    │    └─7.output.LayerNorm.weight              ├─768\n",
      "│    │    └─7.output.LayerNorm.bias                ├─768\n",
      "│    │    └─8.attention.self.query.weight          ├─589,824\n",
      "│    │    └─8.attention.self.query.bias            ├─768\n",
      "│    │    └─8.attention.self.key.weight            ├─589,824\n",
      "│    │    └─8.attention.self.key.bias              ├─768\n",
      "│    │    └─8.attention.self.value.weight          ├─589,824\n",
      "│    │    └─8.attention.self.value.bias            ├─768\n",
      "│    │    └─8.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─8.attention.output.dense.bias          ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─8.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─8.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─8.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─8.output.dense.bias                    ├─768\n",
      "│    │    └─8.output.LayerNorm.weight              ├─768\n",
      "│    │    └─8.output.LayerNorm.bias                ├─768\n",
      "│    │    └─9.attention.self.query.weight          ├─589,824\n",
      "│    │    └─9.attention.self.query.bias            ├─768\n",
      "│    │    └─9.attention.self.key.weight            ├─589,824\n",
      "│    │    └─9.attention.self.key.bias              ├─768\n",
      "│    │    └─9.attention.self.value.weight          ├─589,824\n",
      "│    │    └─9.attention.self.value.bias            ├─768\n",
      "│    │    └─9.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─9.attention.output.dense.bias          ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─9.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─9.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─9.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─9.output.dense.bias                    ├─768\n",
      "│    │    └─9.output.LayerNorm.weight              ├─768\n",
      "│    │    └─9.output.LayerNorm.bias                ├─768\n",
      "│    │    └─10.attention.self.query.weight         ├─589,824\n",
      "│    │    └─10.attention.self.query.bias           ├─768\n",
      "│    │    └─10.attention.self.key.weight           ├─589,824\n",
      "│    │    └─10.attention.self.key.bias             ├─768\n",
      "│    │    └─10.attention.self.value.weight         ├─589,824\n",
      "│    │    └─10.attention.self.value.bias           ├─768\n",
      "│    │    └─10.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─10.attention.output.dense.bias         ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─10.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─10.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─10.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─10.output.dense.bias                   ├─768\n",
      "│    │    └─10.output.LayerNorm.weight             ├─768\n",
      "│    │    └─10.output.LayerNorm.bias               ├─768\n",
      "│    │    └─11.attention.self.query.weight         ├─589,824\n",
      "│    │    └─11.attention.self.query.bias           ├─768\n",
      "│    │    └─11.attention.self.key.weight           ├─589,824\n",
      "│    │    └─11.attention.self.key.bias             ├─768\n",
      "│    │    └─11.attention.self.value.weight         ├─589,824\n",
      "│    │    └─11.attention.self.value.bias           ├─768\n",
      "│    │    └─11.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─11.attention.output.dense.bias         ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─11.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─11.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─11.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─11.output.dense.bias                   ├─768\n",
      "│    │    └─11.output.LayerNorm.weight             ├─768\n",
      "│    │    └─11.output.LayerNorm.bias               └─768\n",
      "│    │    └─BertLayer: 3-1                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-2                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-3                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-4                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-5                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-6                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-7                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-8                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-9                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-10                        7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-11                        7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-12                        7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "├─BertPooler: 1-3                                  --\n",
      "│    └─dense.weight                                ├─589,824\n",
      "│    └─dense.bias                                  └─768\n",
      "│    └─Linear: 2-7                                 590,592\n",
      "│    │    └─weight                                 ├─589,824\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Tanh: 2-8                                   --\n",
      "===========================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "BertModel                                          --\n",
      "├─BertEmbeddings: 1-1                              --\n",
      "│    └─word_embeddings.weight                      ├─23,440,896\n",
      "│    └─position_embeddings.weight                  ├─393,216\n",
      "│    └─token_type_embeddings.weight                ├─1,536\n",
      "│    └─LayerNorm.weight                            ├─768\n",
      "│    └─LayerNorm.bias                              └─768\n",
      "│    └─Embedding: 2-1                              23,440,896\n",
      "│    │    └─weight                                 └─23,440,896\n",
      "│    └─Embedding: 2-2                              393,216\n",
      "│    │    └─weight                                 └─393,216\n",
      "│    └─Embedding: 2-3                              1,536\n",
      "│    │    └─weight                                 └─1,536\n",
      "│    └─LayerNorm: 2-4                              1,536\n",
      "│    │    └─weight                                 ├─768\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Dropout: 2-5                                --\n",
      "├─BertEncoder: 1-2                                 --\n",
      "│    └─layer.0.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.query.bias           ├─768\n",
      "│    └─layer.0.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.0.attention.self.key.bias             ├─768\n",
      "│    └─layer.0.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.value.bias           ├─768\n",
      "│    └─layer.0.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.0.attention.output.dense.bias         ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.0.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.0.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.0.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.0.output.dense.bias                   ├─768\n",
      "│    └─layer.0.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.0.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.1.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.query.bias           ├─768\n",
      "│    └─layer.1.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.1.attention.self.key.bias             ├─768\n",
      "│    └─layer.1.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.value.bias           ├─768\n",
      "│    └─layer.1.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.1.attention.output.dense.bias         ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.1.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.1.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.1.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.1.output.dense.bias                   ├─768\n",
      "│    └─layer.1.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.1.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.2.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.query.bias           ├─768\n",
      "│    └─layer.2.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.2.attention.self.key.bias             ├─768\n",
      "│    └─layer.2.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.value.bias           ├─768\n",
      "│    └─layer.2.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.2.attention.output.dense.bias         ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.2.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.2.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.2.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.2.output.dense.bias                   ├─768\n",
      "│    └─layer.2.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.2.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.3.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.query.bias           ├─768\n",
      "│    └─layer.3.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.3.attention.self.key.bias             ├─768\n",
      "│    └─layer.3.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.value.bias           ├─768\n",
      "│    └─layer.3.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.3.attention.output.dense.bias         ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.3.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.3.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.3.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.3.output.dense.bias                   ├─768\n",
      "│    └─layer.3.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.3.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.4.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.query.bias           ├─768\n",
      "│    └─layer.4.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.4.attention.self.key.bias             ├─768\n",
      "│    └─layer.4.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.value.bias           ├─768\n",
      "│    └─layer.4.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.4.attention.output.dense.bias         ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.4.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.4.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.4.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.4.output.dense.bias                   ├─768\n",
      "│    └─layer.4.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.4.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.5.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.query.bias           ├─768\n",
      "│    └─layer.5.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.5.attention.self.key.bias             ├─768\n",
      "│    └─layer.5.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.value.bias           ├─768\n",
      "│    └─layer.5.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.5.attention.output.dense.bias         ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.5.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.5.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.5.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.5.output.dense.bias                   ├─768\n",
      "│    └─layer.5.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.5.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.6.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.query.bias           ├─768\n",
      "│    └─layer.6.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.6.attention.self.key.bias             ├─768\n",
      "│    └─layer.6.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.value.bias           ├─768\n",
      "│    └─layer.6.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.6.attention.output.dense.bias         ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.6.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.6.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.6.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.6.output.dense.bias                   ├─768\n",
      "│    └─layer.6.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.6.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.7.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.query.bias           ├─768\n",
      "│    └─layer.7.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.7.attention.self.key.bias             ├─768\n",
      "│    └─layer.7.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.value.bias           ├─768\n",
      "│    └─layer.7.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.7.attention.output.dense.bias         ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.7.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.7.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.7.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.7.output.dense.bias                   ├─768\n",
      "│    └─layer.7.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.7.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.8.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.query.bias           ├─768\n",
      "│    └─layer.8.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.8.attention.self.key.bias             ├─768\n",
      "│    └─layer.8.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.value.bias           ├─768\n",
      "│    └─layer.8.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.8.attention.output.dense.bias         ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.8.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.8.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.8.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.8.output.dense.bias                   ├─768\n",
      "│    └─layer.8.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.8.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.9.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.query.bias           ├─768\n",
      "│    └─layer.9.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.9.attention.self.key.bias             ├─768\n",
      "│    └─layer.9.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.value.bias           ├─768\n",
      "│    └─layer.9.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.9.attention.output.dense.bias         ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.9.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.9.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.9.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.9.output.dense.bias                   ├─768\n",
      "│    └─layer.9.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.9.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.10.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.query.bias          ├─768\n",
      "│    └─layer.10.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.10.attention.self.key.bias            ├─768\n",
      "│    └─layer.10.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.value.bias          ├─768\n",
      "│    └─layer.10.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.10.attention.output.dense.bias        ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.10.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.10.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.10.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.10.output.dense.bias                  ├─768\n",
      "│    └─layer.10.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.10.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.11.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.query.bias          ├─768\n",
      "│    └─layer.11.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.11.attention.self.key.bias            ├─768\n",
      "│    └─layer.11.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.value.bias          ├─768\n",
      "│    └─layer.11.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.11.attention.output.dense.bias        ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.11.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.11.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.11.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.11.output.dense.bias                  ├─768\n",
      "│    └─layer.11.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.11.output.LayerNorm.bias              └─768\n",
      "│    └─ModuleList: 2-6                             --\n",
      "│    │    └─0.attention.self.query.weight          ├─589,824\n",
      "│    │    └─0.attention.self.query.bias            ├─768\n",
      "│    │    └─0.attention.self.key.weight            ├─589,824\n",
      "│    │    └─0.attention.self.key.bias              ├─768\n",
      "│    │    └─0.attention.self.value.weight          ├─589,824\n",
      "│    │    └─0.attention.self.value.bias            ├─768\n",
      "│    │    └─0.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─0.attention.output.dense.bias          ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─0.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─0.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─0.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─0.output.dense.bias                    ├─768\n",
      "│    │    └─0.output.LayerNorm.weight              ├─768\n",
      "│    │    └─0.output.LayerNorm.bias                ├─768\n",
      "│    │    └─1.attention.self.query.weight          ├─589,824\n",
      "│    │    └─1.attention.self.query.bias            ├─768\n",
      "│    │    └─1.attention.self.key.weight            ├─589,824\n",
      "│    │    └─1.attention.self.key.bias              ├─768\n",
      "│    │    └─1.attention.self.value.weight          ├─589,824\n",
      "│    │    └─1.attention.self.value.bias            ├─768\n",
      "│    │    └─1.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─1.attention.output.dense.bias          ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─1.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─1.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─1.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─1.output.dense.bias                    ├─768\n",
      "│    │    └─1.output.LayerNorm.weight              ├─768\n",
      "│    │    └─1.output.LayerNorm.bias                ├─768\n",
      "│    │    └─2.attention.self.query.weight          ├─589,824\n",
      "│    │    └─2.attention.self.query.bias            ├─768\n",
      "│    │    └─2.attention.self.key.weight            ├─589,824\n",
      "│    │    └─2.attention.self.key.bias              ├─768\n",
      "│    │    └─2.attention.self.value.weight          ├─589,824\n",
      "│    │    └─2.attention.self.value.bias            ├─768\n",
      "│    │    └─2.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─2.attention.output.dense.bias          ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─2.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─2.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─2.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─2.output.dense.bias                    ├─768\n",
      "│    │    └─2.output.LayerNorm.weight              ├─768\n",
      "│    │    └─2.output.LayerNorm.bias                ├─768\n",
      "│    │    └─3.attention.self.query.weight          ├─589,824\n",
      "│    │    └─3.attention.self.query.bias            ├─768\n",
      "│    │    └─3.attention.self.key.weight            ├─589,824\n",
      "│    │    └─3.attention.self.key.bias              ├─768\n",
      "│    │    └─3.attention.self.value.weight          ├─589,824\n",
      "│    │    └─3.attention.self.value.bias            ├─768\n",
      "│    │    └─3.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─3.attention.output.dense.bias          ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─3.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─3.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─3.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─3.output.dense.bias                    ├─768\n",
      "│    │    └─3.output.LayerNorm.weight              ├─768\n",
      "│    │    └─3.output.LayerNorm.bias                ├─768\n",
      "│    │    └─4.attention.self.query.weight          ├─589,824\n",
      "│    │    └─4.attention.self.query.bias            ├─768\n",
      "│    │    └─4.attention.self.key.weight            ├─589,824\n",
      "│    │    └─4.attention.self.key.bias              ├─768\n",
      "│    │    └─4.attention.self.value.weight          ├─589,824\n",
      "│    │    └─4.attention.self.value.bias            ├─768\n",
      "│    │    └─4.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─4.attention.output.dense.bias          ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─4.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─4.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─4.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─4.output.dense.bias                    ├─768\n",
      "│    │    └─4.output.LayerNorm.weight              ├─768\n",
      "│    │    └─4.output.LayerNorm.bias                ├─768\n",
      "│    │    └─5.attention.self.query.weight          ├─589,824\n",
      "│    │    └─5.attention.self.query.bias            ├─768\n",
      "│    │    └─5.attention.self.key.weight            ├─589,824\n",
      "│    │    └─5.attention.self.key.bias              ├─768\n",
      "│    │    └─5.attention.self.value.weight          ├─589,824\n",
      "│    │    └─5.attention.self.value.bias            ├─768\n",
      "│    │    └─5.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─5.attention.output.dense.bias          ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─5.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─5.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─5.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─5.output.dense.bias                    ├─768\n",
      "│    │    └─5.output.LayerNorm.weight              ├─768\n",
      "│    │    └─5.output.LayerNorm.bias                ├─768\n",
      "│    │    └─6.attention.self.query.weight          ├─589,824\n",
      "│    │    └─6.attention.self.query.bias            ├─768\n",
      "│    │    └─6.attention.self.key.weight            ├─589,824\n",
      "│    │    └─6.attention.self.key.bias              ├─768\n",
      "│    │    └─6.attention.self.value.weight          ├─589,824\n",
      "│    │    └─6.attention.self.value.bias            ├─768\n",
      "│    │    └─6.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─6.attention.output.dense.bias          ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─6.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─6.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─6.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─6.output.dense.bias                    ├─768\n",
      "│    │    └─6.output.LayerNorm.weight              ├─768\n",
      "│    │    └─6.output.LayerNorm.bias                ├─768\n",
      "│    │    └─7.attention.self.query.weight          ├─589,824\n",
      "│    │    └─7.attention.self.query.bias            ├─768\n",
      "│    │    └─7.attention.self.key.weight            ├─589,824\n",
      "│    │    └─7.attention.self.key.bias              ├─768\n",
      "│    │    └─7.attention.self.value.weight          ├─589,824\n",
      "│    │    └─7.attention.self.value.bias            ├─768\n",
      "│    │    └─7.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─7.attention.output.dense.bias          ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─7.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─7.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─7.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─7.output.dense.bias                    ├─768\n",
      "│    │    └─7.output.LayerNorm.weight              ├─768\n",
      "│    │    └─7.output.LayerNorm.bias                ├─768\n",
      "│    │    └─8.attention.self.query.weight          ├─589,824\n",
      "│    │    └─8.attention.self.query.bias            ├─768\n",
      "│    │    └─8.attention.self.key.weight            ├─589,824\n",
      "│    │    └─8.attention.self.key.bias              ├─768\n",
      "│    │    └─8.attention.self.value.weight          ├─589,824\n",
      "│    │    └─8.attention.self.value.bias            ├─768\n",
      "│    │    └─8.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─8.attention.output.dense.bias          ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─8.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─8.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─8.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─8.output.dense.bias                    ├─768\n",
      "│    │    └─8.output.LayerNorm.weight              ├─768\n",
      "│    │    └─8.output.LayerNorm.bias                ├─768\n",
      "│    │    └─9.attention.self.query.weight          ├─589,824\n",
      "│    │    └─9.attention.self.query.bias            ├─768\n",
      "│    │    └─9.attention.self.key.weight            ├─589,824\n",
      "│    │    └─9.attention.self.key.bias              ├─768\n",
      "│    │    └─9.attention.self.value.weight          ├─589,824\n",
      "│    │    └─9.attention.self.value.bias            ├─768\n",
      "│    │    └─9.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─9.attention.output.dense.bias          ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─9.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─9.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─9.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─9.output.dense.bias                    ├─768\n",
      "│    │    └─9.output.LayerNorm.weight              ├─768\n",
      "│    │    └─9.output.LayerNorm.bias                ├─768\n",
      "│    │    └─10.attention.self.query.weight         ├─589,824\n",
      "│    │    └─10.attention.self.query.bias           ├─768\n",
      "│    │    └─10.attention.self.key.weight           ├─589,824\n",
      "│    │    └─10.attention.self.key.bias             ├─768\n",
      "│    │    └─10.attention.self.value.weight         ├─589,824\n",
      "│    │    └─10.attention.self.value.bias           ├─768\n",
      "│    │    └─10.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─10.attention.output.dense.bias         ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─10.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─10.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─10.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─10.output.dense.bias                   ├─768\n",
      "│    │    └─10.output.LayerNorm.weight             ├─768\n",
      "│    │    └─10.output.LayerNorm.bias               ├─768\n",
      "│    │    └─11.attention.self.query.weight         ├─589,824\n",
      "│    │    └─11.attention.self.query.bias           ├─768\n",
      "│    │    └─11.attention.self.key.weight           ├─589,824\n",
      "│    │    └─11.attention.self.key.bias             ├─768\n",
      "│    │    └─11.attention.self.value.weight         ├─589,824\n",
      "│    │    └─11.attention.self.value.bias           ├─768\n",
      "│    │    └─11.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─11.attention.output.dense.bias         ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─11.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─11.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─11.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─11.output.dense.bias                   ├─768\n",
      "│    │    └─11.output.LayerNorm.weight             ├─768\n",
      "│    │    └─11.output.LayerNorm.bias               └─768\n",
      "│    │    └─BertLayer: 3-1                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-2                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-3                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-4                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-5                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-6                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-7                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-8                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-9                         7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-10                        7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-11                        7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─BertLayer: 3-12                        7,087,872\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "├─BertPooler: 1-3                                  --\n",
      "│    └─dense.weight                                ├─589,824\n",
      "│    └─dense.bias                                  └─768\n",
      "│    └─Linear: 2-7                                 590,592\n",
      "│    │    └─weight                                 ├─589,824\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Tanh: 2-8                                   --\n",
      "===========================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "print_summary(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f407d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a404bcc1cb4be9a54d96796ecfa30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db948128b604cd7a0810a17cf93d55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/489M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigBirdModel(\n",
      "  (embeddings): BigBirdEmbeddings(\n",
      "    (word_embeddings): Embedding(50358, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(4096, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BigBirdEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BigBirdLayer(\n",
      "        (attention): BigBirdAttention(\n",
      "          (self): BigBirdBlockSparseAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (output): BigBirdSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BigBirdIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): NewGELUActivation()\n",
      "        )\n",
      "        (output): BigBirdOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "BigBirdModel                                                 --\n",
      "├─BigBirdEmbeddings: 1-1                                     --\n",
      "│    └─word_embeddings.weight                                ├─38,674,944\n",
      "│    └─position_embeddings.weight                            ├─3,145,728\n",
      "│    └─token_type_embeddings.weight                          ├─1,536\n",
      "│    └─LayerNorm.weight                                      ├─768\n",
      "│    └─LayerNorm.bias                                        └─768\n",
      "│    └─Embedding: 2-1                                        38,674,944\n",
      "│    │    └─weight                                           └─38,674,944\n",
      "│    └─Embedding: 2-2                                        3,145,728\n",
      "│    │    └─weight                                           └─3,145,728\n",
      "│    └─Embedding: 2-3                                        1,536\n",
      "│    │    └─weight                                           └─1,536\n",
      "│    └─LayerNorm: 2-4                                        1,536\n",
      "│    │    └─weight                                           ├─768\n",
      "│    │    └─bias                                             └─768\n",
      "│    └─Dropout: 2-5                                          --\n",
      "├─BigBirdEncoder: 1-2                                        --\n",
      "│    └─layer.0.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.0.attention.self.query.bias                     ├─768\n",
      "│    └─layer.0.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.0.attention.self.key.bias                       ├─768\n",
      "│    └─layer.0.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.0.attention.self.value.bias                     ├─768\n",
      "│    └─layer.0.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.0.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.0.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.0.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.0.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.0.output.dense.bias                             ├─768\n",
      "│    └─layer.0.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.0.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.1.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.1.attention.self.query.bias                     ├─768\n",
      "│    └─layer.1.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.1.attention.self.key.bias                       ├─768\n",
      "│    └─layer.1.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.1.attention.self.value.bias                     ├─768\n",
      "│    └─layer.1.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.1.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.1.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.1.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.1.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.1.output.dense.bias                             ├─768\n",
      "│    └─layer.1.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.1.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.2.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.2.attention.self.query.bias                     ├─768\n",
      "│    └─layer.2.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.2.attention.self.key.bias                       ├─768\n",
      "│    └─layer.2.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.2.attention.self.value.bias                     ├─768\n",
      "│    └─layer.2.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.2.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.2.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.2.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.2.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.2.output.dense.bias                             ├─768\n",
      "│    └─layer.2.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.2.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.3.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.3.attention.self.query.bias                     ├─768\n",
      "│    └─layer.3.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.3.attention.self.key.bias                       ├─768\n",
      "│    └─layer.3.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.3.attention.self.value.bias                     ├─768\n",
      "│    └─layer.3.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.3.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.3.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.3.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.3.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.3.output.dense.bias                             ├─768\n",
      "│    └─layer.3.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.3.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.4.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.4.attention.self.query.bias                     ├─768\n",
      "│    └─layer.4.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.4.attention.self.key.bias                       ├─768\n",
      "│    └─layer.4.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.4.attention.self.value.bias                     ├─768\n",
      "│    └─layer.4.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.4.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.4.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.4.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.4.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.4.output.dense.bias                             ├─768\n",
      "│    └─layer.4.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.4.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.5.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.5.attention.self.query.bias                     ├─768\n",
      "│    └─layer.5.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.5.attention.self.key.bias                       ├─768\n",
      "│    └─layer.5.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.5.attention.self.value.bias                     ├─768\n",
      "│    └─layer.5.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.5.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.5.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.5.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.5.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.5.output.dense.bias                             ├─768\n",
      "│    └─layer.5.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.5.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.6.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.6.attention.self.query.bias                     ├─768\n",
      "│    └─layer.6.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.6.attention.self.key.bias                       ├─768\n",
      "│    └─layer.6.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.6.attention.self.value.bias                     ├─768\n",
      "│    └─layer.6.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.6.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.6.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.6.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.6.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.6.output.dense.bias                             ├─768\n",
      "│    └─layer.6.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.6.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.7.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.7.attention.self.query.bias                     ├─768\n",
      "│    └─layer.7.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.7.attention.self.key.bias                       ├─768\n",
      "│    └─layer.7.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.7.attention.self.value.bias                     ├─768\n",
      "│    └─layer.7.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.7.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.7.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.7.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.7.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.7.output.dense.bias                             ├─768\n",
      "│    └─layer.7.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.7.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.8.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.8.attention.self.query.bias                     ├─768\n",
      "│    └─layer.8.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.8.attention.self.key.bias                       ├─768\n",
      "│    └─layer.8.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.8.attention.self.value.bias                     ├─768\n",
      "│    └─layer.8.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.8.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.8.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.8.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.8.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.8.output.dense.bias                             ├─768\n",
      "│    └─layer.8.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.8.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.9.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.9.attention.self.query.bias                     ├─768\n",
      "│    └─layer.9.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.9.attention.self.key.bias                       ├─768\n",
      "│    └─layer.9.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.9.attention.self.value.bias                     ├─768\n",
      "│    └─layer.9.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.9.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.9.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.9.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.9.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.9.output.dense.bias                             ├─768\n",
      "│    └─layer.9.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.9.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.10.attention.self.query.weight                  ├─589,824\n",
      "│    └─layer.10.attention.self.query.bias                    ├─768\n",
      "│    └─layer.10.attention.self.key.weight                    ├─589,824\n",
      "│    └─layer.10.attention.self.key.bias                      ├─768\n",
      "│    └─layer.10.attention.self.value.weight                  ├─589,824\n",
      "│    └─layer.10.attention.self.value.bias                    ├─768\n",
      "│    └─layer.10.attention.output.dense.weight                ├─589,824\n",
      "│    └─layer.10.attention.output.dense.bias                  ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.10.intermediate.dense.weight                    ├─2,359,296\n",
      "│    └─layer.10.intermediate.dense.bias                      ├─3,072\n",
      "│    └─layer.10.output.dense.weight                          ├─2,359,296\n",
      "│    └─layer.10.output.dense.bias                            ├─768\n",
      "│    └─layer.10.output.LayerNorm.weight                      ├─768\n",
      "│    └─layer.10.output.LayerNorm.bias                        ├─768\n",
      "│    └─layer.11.attention.self.query.weight                  ├─589,824\n",
      "│    └─layer.11.attention.self.query.bias                    ├─768\n",
      "│    └─layer.11.attention.self.key.weight                    ├─589,824\n",
      "│    └─layer.11.attention.self.key.bias                      ├─768\n",
      "│    └─layer.11.attention.self.value.weight                  ├─589,824\n",
      "│    └─layer.11.attention.self.value.bias                    ├─768\n",
      "│    └─layer.11.attention.output.dense.weight                ├─589,824\n",
      "│    └─layer.11.attention.output.dense.bias                  ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.11.intermediate.dense.weight                    ├─2,359,296\n",
      "│    └─layer.11.intermediate.dense.bias                      ├─3,072\n",
      "│    └─layer.11.output.dense.weight                          ├─2,359,296\n",
      "│    └─layer.11.output.dense.bias                            ├─768\n",
      "│    └─layer.11.output.LayerNorm.weight                      ├─768\n",
      "│    └─layer.11.output.LayerNorm.bias                        └─768\n",
      "│    └─ModuleList: 2-6                                       --\n",
      "│    │    └─0.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─0.attention.self.query.bias                      ├─768\n",
      "│    │    └─0.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─0.attention.self.key.bias                        ├─768\n",
      "│    │    └─0.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─0.attention.self.value.bias                      ├─768\n",
      "│    │    └─0.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─0.attention.output.dense.bias                    ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─0.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─0.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─0.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─0.output.dense.bias                              ├─768\n",
      "│    │    └─0.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─0.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─1.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─1.attention.self.query.bias                      ├─768\n",
      "│    │    └─1.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─1.attention.self.key.bias                        ├─768\n",
      "│    │    └─1.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─1.attention.self.value.bias                      ├─768\n",
      "│    │    └─1.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─1.attention.output.dense.bias                    ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─1.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─1.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─1.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─1.output.dense.bias                              ├─768\n",
      "│    │    └─1.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─1.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─2.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─2.attention.self.query.bias                      ├─768\n",
      "│    │    └─2.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─2.attention.self.key.bias                        ├─768\n",
      "│    │    └─2.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─2.attention.self.value.bias                      ├─768\n",
      "│    │    └─2.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─2.attention.output.dense.bias                    ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─2.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─2.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─2.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─2.output.dense.bias                              ├─768\n",
      "│    │    └─2.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─2.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─3.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─3.attention.self.query.bias                      ├─768\n",
      "│    │    └─3.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─3.attention.self.key.bias                        ├─768\n",
      "│    │    └─3.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─3.attention.self.value.bias                      ├─768\n",
      "│    │    └─3.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─3.attention.output.dense.bias                    ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─3.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─3.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─3.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─3.output.dense.bias                              ├─768\n",
      "│    │    └─3.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─3.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─4.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─4.attention.self.query.bias                      ├─768\n",
      "│    │    └─4.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─4.attention.self.key.bias                        ├─768\n",
      "│    │    └─4.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─4.attention.self.value.bias                      ├─768\n",
      "│    │    └─4.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─4.attention.output.dense.bias                    ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─4.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─4.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─4.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─4.output.dense.bias                              ├─768\n",
      "│    │    └─4.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─4.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─5.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─5.attention.self.query.bias                      ├─768\n",
      "│    │    └─5.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─5.attention.self.key.bias                        ├─768\n",
      "│    │    └─5.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─5.attention.self.value.bias                      ├─768\n",
      "│    │    └─5.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─5.attention.output.dense.bias                    ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─5.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─5.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─5.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─5.output.dense.bias                              ├─768\n",
      "│    │    └─5.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─5.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─6.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─6.attention.self.query.bias                      ├─768\n",
      "│    │    └─6.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─6.attention.self.key.bias                        ├─768\n",
      "│    │    └─6.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─6.attention.self.value.bias                      ├─768\n",
      "│    │    └─6.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─6.attention.output.dense.bias                    ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─6.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─6.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─6.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─6.output.dense.bias                              ├─768\n",
      "│    │    └─6.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─6.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─7.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─7.attention.self.query.bias                      ├─768\n",
      "│    │    └─7.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─7.attention.self.key.bias                        ├─768\n",
      "│    │    └─7.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─7.attention.self.value.bias                      ├─768\n",
      "│    │    └─7.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─7.attention.output.dense.bias                    ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─7.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─7.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─7.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─7.output.dense.bias                              ├─768\n",
      "│    │    └─7.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─7.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─8.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─8.attention.self.query.bias                      ├─768\n",
      "│    │    └─8.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─8.attention.self.key.bias                        ├─768\n",
      "│    │    └─8.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─8.attention.self.value.bias                      ├─768\n",
      "│    │    └─8.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─8.attention.output.dense.bias                    ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─8.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─8.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─8.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─8.output.dense.bias                              ├─768\n",
      "│    │    └─8.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─8.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─9.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─9.attention.self.query.bias                      ├─768\n",
      "│    │    └─9.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─9.attention.self.key.bias                        ├─768\n",
      "│    │    └─9.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─9.attention.self.value.bias                      ├─768\n",
      "│    │    └─9.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─9.attention.output.dense.bias                    ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─9.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─9.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─9.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─9.output.dense.bias                              ├─768\n",
      "│    │    └─9.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─9.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─10.attention.self.query.weight                   ├─589,824\n",
      "│    │    └─10.attention.self.query.bias                     ├─768\n",
      "│    │    └─10.attention.self.key.weight                     ├─589,824\n",
      "│    │    └─10.attention.self.key.bias                       ├─768\n",
      "│    │    └─10.attention.self.value.weight                   ├─589,824\n",
      "│    │    └─10.attention.self.value.bias                     ├─768\n",
      "│    │    └─10.attention.output.dense.weight                 ├─589,824\n",
      "│    │    └─10.attention.output.dense.bias                   ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.weight             ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.bias               ├─768\n",
      "│    │    └─10.intermediate.dense.weight                     ├─2,359,296\n",
      "│    │    └─10.intermediate.dense.bias                       ├─3,072\n",
      "│    │    └─10.output.dense.weight                           ├─2,359,296\n",
      "│    │    └─10.output.dense.bias                             ├─768\n",
      "│    │    └─10.output.LayerNorm.weight                       ├─768\n",
      "│    │    └─10.output.LayerNorm.bias                         ├─768\n",
      "│    │    └─11.attention.self.query.weight                   ├─589,824\n",
      "│    │    └─11.attention.self.query.bias                     ├─768\n",
      "│    │    └─11.attention.self.key.weight                     ├─589,824\n",
      "│    │    └─11.attention.self.key.bias                       ├─768\n",
      "│    │    └─11.attention.self.value.weight                   ├─589,824\n",
      "│    │    └─11.attention.self.value.bias                     ├─768\n",
      "│    │    └─11.attention.output.dense.weight                 ├─589,824\n",
      "│    │    └─11.attention.output.dense.bias                   ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.weight             ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.bias               ├─768\n",
      "│    │    └─11.intermediate.dense.weight                     ├─2,359,296\n",
      "│    │    └─11.intermediate.dense.bias                       ├─3,072\n",
      "│    │    └─11.output.dense.weight                           ├─2,359,296\n",
      "│    │    └─11.output.dense.bias                             ├─768\n",
      "│    │    └─11.output.LayerNorm.weight                       ├─768\n",
      "│    │    └─11.output.LayerNorm.bias                         └─768\n",
      "│    │    └─BigBirdLayer: 3-1                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-2                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-3                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-4                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-5                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-6                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-7                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-8                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-9                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-10                               7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-11                               7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-12                               7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "├─Linear: 1-3                                                590,592\n",
      "│    └─weight                                                ├─589,824\n",
      "│    └─bias                                                  └─768\n",
      "├─Tanh: 1-4                                                  --\n",
      "=====================================================================================\n",
      "Total params: 127,468,800\n",
      "Trainable params: 127,468,800\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "BigBirdModel                                                 --\n",
      "├─BigBirdEmbeddings: 1-1                                     --\n",
      "│    └─word_embeddings.weight                                ├─38,674,944\n",
      "│    └─position_embeddings.weight                            ├─3,145,728\n",
      "│    └─token_type_embeddings.weight                          ├─1,536\n",
      "│    └─LayerNorm.weight                                      ├─768\n",
      "│    └─LayerNorm.bias                                        └─768\n",
      "│    └─Embedding: 2-1                                        38,674,944\n",
      "│    │    └─weight                                           └─38,674,944\n",
      "│    └─Embedding: 2-2                                        3,145,728\n",
      "│    │    └─weight                                           └─3,145,728\n",
      "│    └─Embedding: 2-3                                        1,536\n",
      "│    │    └─weight                                           └─1,536\n",
      "│    └─LayerNorm: 2-4                                        1,536\n",
      "│    │    └─weight                                           ├─768\n",
      "│    │    └─bias                                             └─768\n",
      "│    └─Dropout: 2-5                                          --\n",
      "├─BigBirdEncoder: 1-2                                        --\n",
      "│    └─layer.0.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.0.attention.self.query.bias                     ├─768\n",
      "│    └─layer.0.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.0.attention.self.key.bias                       ├─768\n",
      "│    └─layer.0.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.0.attention.self.value.bias                     ├─768\n",
      "│    └─layer.0.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.0.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.0.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.0.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.0.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.0.output.dense.bias                             ├─768\n",
      "│    └─layer.0.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.0.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.1.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.1.attention.self.query.bias                     ├─768\n",
      "│    └─layer.1.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.1.attention.self.key.bias                       ├─768\n",
      "│    └─layer.1.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.1.attention.self.value.bias                     ├─768\n",
      "│    └─layer.1.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.1.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.1.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.1.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.1.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.1.output.dense.bias                             ├─768\n",
      "│    └─layer.1.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.1.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.2.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.2.attention.self.query.bias                     ├─768\n",
      "│    └─layer.2.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.2.attention.self.key.bias                       ├─768\n",
      "│    └─layer.2.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.2.attention.self.value.bias                     ├─768\n",
      "│    └─layer.2.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.2.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.2.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.2.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.2.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.2.output.dense.bias                             ├─768\n",
      "│    └─layer.2.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.2.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.3.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.3.attention.self.query.bias                     ├─768\n",
      "│    └─layer.3.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.3.attention.self.key.bias                       ├─768\n",
      "│    └─layer.3.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.3.attention.self.value.bias                     ├─768\n",
      "│    └─layer.3.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.3.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.3.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.3.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.3.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.3.output.dense.bias                             ├─768\n",
      "│    └─layer.3.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.3.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.4.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.4.attention.self.query.bias                     ├─768\n",
      "│    └─layer.4.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.4.attention.self.key.bias                       ├─768\n",
      "│    └─layer.4.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.4.attention.self.value.bias                     ├─768\n",
      "│    └─layer.4.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.4.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.4.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.4.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.4.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.4.output.dense.bias                             ├─768\n",
      "│    └─layer.4.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.4.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.5.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.5.attention.self.query.bias                     ├─768\n",
      "│    └─layer.5.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.5.attention.self.key.bias                       ├─768\n",
      "│    └─layer.5.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.5.attention.self.value.bias                     ├─768\n",
      "│    └─layer.5.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.5.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.5.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.5.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.5.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.5.output.dense.bias                             ├─768\n",
      "│    └─layer.5.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.5.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.6.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.6.attention.self.query.bias                     ├─768\n",
      "│    └─layer.6.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.6.attention.self.key.bias                       ├─768\n",
      "│    └─layer.6.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.6.attention.self.value.bias                     ├─768\n",
      "│    └─layer.6.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.6.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.6.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.6.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.6.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.6.output.dense.bias                             ├─768\n",
      "│    └─layer.6.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.6.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.7.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.7.attention.self.query.bias                     ├─768\n",
      "│    └─layer.7.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.7.attention.self.key.bias                       ├─768\n",
      "│    └─layer.7.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.7.attention.self.value.bias                     ├─768\n",
      "│    └─layer.7.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.7.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.7.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.7.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.7.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.7.output.dense.bias                             ├─768\n",
      "│    └─layer.7.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.7.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.8.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.8.attention.self.query.bias                     ├─768\n",
      "│    └─layer.8.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.8.attention.self.key.bias                       ├─768\n",
      "│    └─layer.8.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.8.attention.self.value.bias                     ├─768\n",
      "│    └─layer.8.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.8.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.8.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.8.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.8.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.8.output.dense.bias                             ├─768\n",
      "│    └─layer.8.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.8.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.9.attention.self.query.weight                   ├─589,824\n",
      "│    └─layer.9.attention.self.query.bias                     ├─768\n",
      "│    └─layer.9.attention.self.key.weight                     ├─589,824\n",
      "│    └─layer.9.attention.self.key.bias                       ├─768\n",
      "│    └─layer.9.attention.self.value.weight                   ├─589,824\n",
      "│    └─layer.9.attention.self.value.bias                     ├─768\n",
      "│    └─layer.9.attention.output.dense.weight                 ├─589,824\n",
      "│    └─layer.9.attention.output.dense.bias                   ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.9.intermediate.dense.weight                     ├─2,359,296\n",
      "│    └─layer.9.intermediate.dense.bias                       ├─3,072\n",
      "│    └─layer.9.output.dense.weight                           ├─2,359,296\n",
      "│    └─layer.9.output.dense.bias                             ├─768\n",
      "│    └─layer.9.output.LayerNorm.weight                       ├─768\n",
      "│    └─layer.9.output.LayerNorm.bias                         ├─768\n",
      "│    └─layer.10.attention.self.query.weight                  ├─589,824\n",
      "│    └─layer.10.attention.self.query.bias                    ├─768\n",
      "│    └─layer.10.attention.self.key.weight                    ├─589,824\n",
      "│    └─layer.10.attention.self.key.bias                      ├─768\n",
      "│    └─layer.10.attention.self.value.weight                  ├─589,824\n",
      "│    └─layer.10.attention.self.value.bias                    ├─768\n",
      "│    └─layer.10.attention.output.dense.weight                ├─589,824\n",
      "│    └─layer.10.attention.output.dense.bias                  ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.10.intermediate.dense.weight                    ├─2,359,296\n",
      "│    └─layer.10.intermediate.dense.bias                      ├─3,072\n",
      "│    └─layer.10.output.dense.weight                          ├─2,359,296\n",
      "│    └─layer.10.output.dense.bias                            ├─768\n",
      "│    └─layer.10.output.LayerNorm.weight                      ├─768\n",
      "│    └─layer.10.output.LayerNorm.bias                        ├─768\n",
      "│    └─layer.11.attention.self.query.weight                  ├─589,824\n",
      "│    └─layer.11.attention.self.query.bias                    ├─768\n",
      "│    └─layer.11.attention.self.key.weight                    ├─589,824\n",
      "│    └─layer.11.attention.self.key.bias                      ├─768\n",
      "│    └─layer.11.attention.self.value.weight                  ├─589,824\n",
      "│    └─layer.11.attention.self.value.bias                    ├─768\n",
      "│    └─layer.11.attention.output.dense.weight                ├─589,824\n",
      "│    └─layer.11.attention.output.dense.bias                  ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.11.intermediate.dense.weight                    ├─2,359,296\n",
      "│    └─layer.11.intermediate.dense.bias                      ├─3,072\n",
      "│    └─layer.11.output.dense.weight                          ├─2,359,296\n",
      "│    └─layer.11.output.dense.bias                            ├─768\n",
      "│    └─layer.11.output.LayerNorm.weight                      ├─768\n",
      "│    └─layer.11.output.LayerNorm.bias                        └─768\n",
      "│    └─ModuleList: 2-6                                       --\n",
      "│    │    └─0.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─0.attention.self.query.bias                      ├─768\n",
      "│    │    └─0.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─0.attention.self.key.bias                        ├─768\n",
      "│    │    └─0.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─0.attention.self.value.bias                      ├─768\n",
      "│    │    └─0.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─0.attention.output.dense.bias                    ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─0.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─0.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─0.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─0.output.dense.bias                              ├─768\n",
      "│    │    └─0.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─0.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─1.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─1.attention.self.query.bias                      ├─768\n",
      "│    │    └─1.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─1.attention.self.key.bias                        ├─768\n",
      "│    │    └─1.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─1.attention.self.value.bias                      ├─768\n",
      "│    │    └─1.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─1.attention.output.dense.bias                    ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─1.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─1.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─1.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─1.output.dense.bias                              ├─768\n",
      "│    │    └─1.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─1.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─2.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─2.attention.self.query.bias                      ├─768\n",
      "│    │    └─2.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─2.attention.self.key.bias                        ├─768\n",
      "│    │    └─2.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─2.attention.self.value.bias                      ├─768\n",
      "│    │    └─2.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─2.attention.output.dense.bias                    ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─2.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─2.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─2.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─2.output.dense.bias                              ├─768\n",
      "│    │    └─2.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─2.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─3.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─3.attention.self.query.bias                      ├─768\n",
      "│    │    └─3.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─3.attention.self.key.bias                        ├─768\n",
      "│    │    └─3.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─3.attention.self.value.bias                      ├─768\n",
      "│    │    └─3.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─3.attention.output.dense.bias                    ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─3.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─3.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─3.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─3.output.dense.bias                              ├─768\n",
      "│    │    └─3.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─3.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─4.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─4.attention.self.query.bias                      ├─768\n",
      "│    │    └─4.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─4.attention.self.key.bias                        ├─768\n",
      "│    │    └─4.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─4.attention.self.value.bias                      ├─768\n",
      "│    │    └─4.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─4.attention.output.dense.bias                    ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─4.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─4.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─4.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─4.output.dense.bias                              ├─768\n",
      "│    │    └─4.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─4.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─5.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─5.attention.self.query.bias                      ├─768\n",
      "│    │    └─5.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─5.attention.self.key.bias                        ├─768\n",
      "│    │    └─5.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─5.attention.self.value.bias                      ├─768\n",
      "│    │    └─5.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─5.attention.output.dense.bias                    ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─5.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─5.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─5.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─5.output.dense.bias                              ├─768\n",
      "│    │    └─5.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─5.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─6.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─6.attention.self.query.bias                      ├─768\n",
      "│    │    └─6.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─6.attention.self.key.bias                        ├─768\n",
      "│    │    └─6.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─6.attention.self.value.bias                      ├─768\n",
      "│    │    └─6.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─6.attention.output.dense.bias                    ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─6.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─6.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─6.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─6.output.dense.bias                              ├─768\n",
      "│    │    └─6.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─6.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─7.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─7.attention.self.query.bias                      ├─768\n",
      "│    │    └─7.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─7.attention.self.key.bias                        ├─768\n",
      "│    │    └─7.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─7.attention.self.value.bias                      ├─768\n",
      "│    │    └─7.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─7.attention.output.dense.bias                    ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─7.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─7.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─7.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─7.output.dense.bias                              ├─768\n",
      "│    │    └─7.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─7.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─8.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─8.attention.self.query.bias                      ├─768\n",
      "│    │    └─8.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─8.attention.self.key.bias                        ├─768\n",
      "│    │    └─8.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─8.attention.self.value.bias                      ├─768\n",
      "│    │    └─8.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─8.attention.output.dense.bias                    ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─8.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─8.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─8.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─8.output.dense.bias                              ├─768\n",
      "│    │    └─8.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─8.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─9.attention.self.query.weight                    ├─589,824\n",
      "│    │    └─9.attention.self.query.bias                      ├─768\n",
      "│    │    └─9.attention.self.key.weight                      ├─589,824\n",
      "│    │    └─9.attention.self.key.bias                        ├─768\n",
      "│    │    └─9.attention.self.value.weight                    ├─589,824\n",
      "│    │    └─9.attention.self.value.bias                      ├─768\n",
      "│    │    └─9.attention.output.dense.weight                  ├─589,824\n",
      "│    │    └─9.attention.output.dense.bias                    ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.weight              ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.bias                ├─768\n",
      "│    │    └─9.intermediate.dense.weight                      ├─2,359,296\n",
      "│    │    └─9.intermediate.dense.bias                        ├─3,072\n",
      "│    │    └─9.output.dense.weight                            ├─2,359,296\n",
      "│    │    └─9.output.dense.bias                              ├─768\n",
      "│    │    └─9.output.LayerNorm.weight                        ├─768\n",
      "│    │    └─9.output.LayerNorm.bias                          ├─768\n",
      "│    │    └─10.attention.self.query.weight                   ├─589,824\n",
      "│    │    └─10.attention.self.query.bias                     ├─768\n",
      "│    │    └─10.attention.self.key.weight                     ├─589,824\n",
      "│    │    └─10.attention.self.key.bias                       ├─768\n",
      "│    │    └─10.attention.self.value.weight                   ├─589,824\n",
      "│    │    └─10.attention.self.value.bias                     ├─768\n",
      "│    │    └─10.attention.output.dense.weight                 ├─589,824\n",
      "│    │    └─10.attention.output.dense.bias                   ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.weight             ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.bias               ├─768\n",
      "│    │    └─10.intermediate.dense.weight                     ├─2,359,296\n",
      "│    │    └─10.intermediate.dense.bias                       ├─3,072\n",
      "│    │    └─10.output.dense.weight                           ├─2,359,296\n",
      "│    │    └─10.output.dense.bias                             ├─768\n",
      "│    │    └─10.output.LayerNorm.weight                       ├─768\n",
      "│    │    └─10.output.LayerNorm.bias                         ├─768\n",
      "│    │    └─11.attention.self.query.weight                   ├─589,824\n",
      "│    │    └─11.attention.self.query.bias                     ├─768\n",
      "│    │    └─11.attention.self.key.weight                     ├─589,824\n",
      "│    │    └─11.attention.self.key.bias                       ├─768\n",
      "│    │    └─11.attention.self.value.weight                   ├─589,824\n",
      "│    │    └─11.attention.self.value.bias                     ├─768\n",
      "│    │    └─11.attention.output.dense.weight                 ├─589,824\n",
      "│    │    └─11.attention.output.dense.bias                   ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.weight             ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.bias               ├─768\n",
      "│    │    └─11.intermediate.dense.weight                     ├─2,359,296\n",
      "│    │    └─11.intermediate.dense.bias                       ├─3,072\n",
      "│    │    └─11.output.dense.weight                           ├─2,359,296\n",
      "│    │    └─11.output.dense.bias                             ├─768\n",
      "│    │    └─11.output.LayerNorm.weight                       ├─768\n",
      "│    │    └─11.output.LayerNorm.bias                         └─768\n",
      "│    │    └─BigBirdLayer: 3-1                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-2                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-3                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-4                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-5                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-6                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-7                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-8                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-9                                7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-10                               7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-11                               7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "│    │    └─BigBirdLayer: 3-12                               7,087,872\n",
      "│    │    │    └─attention.self.query.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.query.bias                   ├─768\n",
      "│    │    │    └─attention.self.key.weight                   ├─589,824\n",
      "│    │    │    └─attention.self.key.bias                     ├─768\n",
      "│    │    │    └─attention.self.value.weight                 ├─589,824\n",
      "│    │    │    └─attention.self.value.bias                   ├─768\n",
      "│    │    │    └─attention.output.dense.weight               ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias                 ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─768\n",
      "│    │    │    └─intermediate.dense.weight                   ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias                     ├─3,072\n",
      "│    │    │    └─output.dense.weight                         ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                           ├─768\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─768\n",
      "│    │    │    └─output.LayerNorm.bias                       └─768\n",
      "├─Linear: 1-3                                                590,592\n",
      "│    └─weight                                                ├─589,824\n",
      "│    └─bias                                                  └─768\n",
      "├─Tanh: 1-4                                                  --\n",
      "=====================================================================================\n",
      "Total params: 127,468,800\n",
      "Trainable params: 127,468,800\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import BigBirdTokenizer, BigBirdModel\n",
    "\n",
    "bigbird_model = BigBirdModel.from_pretrained(\"google/bigbird-roberta-base\")\n",
    "print_summary(bigbird_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd968eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa9343fd563457194e1f948b05980d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/836 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f271cb30860b4bf7933d11304e17081d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at studio-ousia/luke-base were not used when initializing LukeModel: ['lm_head.layer_norm.bias', 'entity_predictions.transform.LayerNorm.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'entity_predictions.transform.dense.weight', 'lm_head.dense.bias', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.dense.weight', 'entity_predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LukeModel(\n",
      "  (embeddings): LukeEmbeddings(\n",
      "    (word_embeddings): Embedding(50267, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (entity_embeddings): LukeEntityEmbeddings(\n",
      "    (entity_embeddings): Embedding(500000, 256, padding_idx=0)\n",
      "    (entity_embedding_dense): Linear(in_features=256, out_features=768, bias=False)\n",
      "    (position_embeddings): Embedding(514, 768)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): LukeEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): LukeLayer(\n",
      "        (attention): LukeAttention(\n",
      "          (self): LukeSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (w2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2w_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (e2e_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): LukeSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): LukeIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): LukeOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): LukePooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "LukeModel                                          --\n",
      "├─LukeEmbeddings: 1-1                              --\n",
      "│    └─word_embeddings.weight                      ├─38,605,056\n",
      "│    └─position_embeddings.weight                  ├─394,752\n",
      "│    └─token_type_embeddings.weight                ├─768\n",
      "│    └─LayerNorm.weight                            ├─768\n",
      "│    └─LayerNorm.bias                              └─768\n",
      "│    └─Embedding: 2-1                              38,605,056\n",
      "│    │    └─weight                                 └─38,605,056\n",
      "│    └─Embedding: 2-2                              394,752\n",
      "│    │    └─weight                                 └─394,752\n",
      "│    └─Embedding: 2-3                              768\n",
      "│    │    └─weight                                 └─768\n",
      "│    └─LayerNorm: 2-4                              1,536\n",
      "│    │    └─weight                                 ├─768\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Dropout: 2-5                                --\n",
      "├─LukeEntityEmbeddings: 1-2                        --\n",
      "│    └─entity_embeddings.weight                    ├─128,000,000\n",
      "│    └─entity_embedding_dense.weight               ├─196,608\n",
      "│    └─position_embeddings.weight                  ├─394,752\n",
      "│    └─token_type_embeddings.weight                ├─768\n",
      "│    └─LayerNorm.weight                            ├─768\n",
      "│    └─LayerNorm.bias                              └─768\n",
      "│    └─Embedding: 2-6                              128,000,000\n",
      "│    │    └─weight                                 └─128,000,000\n",
      "│    └─Linear: 2-7                                 196,608\n",
      "│    │    └─weight                                 └─196,608\n",
      "│    └─Embedding: 2-8                              394,752\n",
      "│    │    └─weight                                 └─394,752\n",
      "│    └─Embedding: 2-9                              768\n",
      "│    │    └─weight                                 └─768\n",
      "│    └─LayerNorm: 2-10                             1,536\n",
      "│    │    └─weight                                 ├─768\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Dropout: 2-11                               --\n",
      "├─LukeEncoder: 1-3                                 --\n",
      "│    └─layer.0.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.query.bias           ├─768\n",
      "│    └─layer.0.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.0.attention.self.key.bias             ├─768\n",
      "│    └─layer.0.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.value.bias           ├─768\n",
      "│    └─layer.0.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.0.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.0.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.0.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.0.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.0.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.0.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.0.attention.output.dense.bias         ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.0.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.0.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.0.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.0.output.dense.bias                   ├─768\n",
      "│    └─layer.0.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.0.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.1.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.query.bias           ├─768\n",
      "│    └─layer.1.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.1.attention.self.key.bias             ├─768\n",
      "│    └─layer.1.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.value.bias           ├─768\n",
      "│    └─layer.1.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.1.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.1.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.1.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.1.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.1.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.1.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.1.attention.output.dense.bias         ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.1.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.1.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.1.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.1.output.dense.bias                   ├─768\n",
      "│    └─layer.1.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.1.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.2.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.query.bias           ├─768\n",
      "│    └─layer.2.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.2.attention.self.key.bias             ├─768\n",
      "│    └─layer.2.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.value.bias           ├─768\n",
      "│    └─layer.2.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.2.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.2.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.2.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.2.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.2.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.2.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.2.attention.output.dense.bias         ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.2.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.2.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.2.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.2.output.dense.bias                   ├─768\n",
      "│    └─layer.2.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.2.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.3.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.query.bias           ├─768\n",
      "│    └─layer.3.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.3.attention.self.key.bias             ├─768\n",
      "│    └─layer.3.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.value.bias           ├─768\n",
      "│    └─layer.3.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.3.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.3.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.3.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.3.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.3.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.3.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.3.attention.output.dense.bias         ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.3.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.3.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.3.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.3.output.dense.bias                   ├─768\n",
      "│    └─layer.3.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.3.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.4.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.query.bias           ├─768\n",
      "│    └─layer.4.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.4.attention.self.key.bias             ├─768\n",
      "│    └─layer.4.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.value.bias           ├─768\n",
      "│    └─layer.4.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.4.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.4.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.4.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.4.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.4.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.4.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.4.attention.output.dense.bias         ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.4.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.4.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.4.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.4.output.dense.bias                   ├─768\n",
      "│    └─layer.4.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.4.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.5.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.query.bias           ├─768\n",
      "│    └─layer.5.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.5.attention.self.key.bias             ├─768\n",
      "│    └─layer.5.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.value.bias           ├─768\n",
      "│    └─layer.5.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.5.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.5.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.5.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.5.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.5.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.5.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.5.attention.output.dense.bias         ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.5.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.5.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.5.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.5.output.dense.bias                   ├─768\n",
      "│    └─layer.5.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.5.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.6.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.query.bias           ├─768\n",
      "│    └─layer.6.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.6.attention.self.key.bias             ├─768\n",
      "│    └─layer.6.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.value.bias           ├─768\n",
      "│    └─layer.6.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.6.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.6.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.6.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.6.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.6.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.6.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.6.attention.output.dense.bias         ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.6.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.6.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.6.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.6.output.dense.bias                   ├─768\n",
      "│    └─layer.6.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.6.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.7.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.query.bias           ├─768\n",
      "│    └─layer.7.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.7.attention.self.key.bias             ├─768\n",
      "│    └─layer.7.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.value.bias           ├─768\n",
      "│    └─layer.7.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.7.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.7.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.7.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.7.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.7.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.7.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.7.attention.output.dense.bias         ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.7.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.7.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.7.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.7.output.dense.bias                   ├─768\n",
      "│    └─layer.7.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.7.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.8.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.query.bias           ├─768\n",
      "│    └─layer.8.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.8.attention.self.key.bias             ├─768\n",
      "│    └─layer.8.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.value.bias           ├─768\n",
      "│    └─layer.8.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.8.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.8.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.8.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.8.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.8.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.8.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.8.attention.output.dense.bias         ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.8.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.8.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.8.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.8.output.dense.bias                   ├─768\n",
      "│    └─layer.8.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.8.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.9.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.query.bias           ├─768\n",
      "│    └─layer.9.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.9.attention.self.key.bias             ├─768\n",
      "│    └─layer.9.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.value.bias           ├─768\n",
      "│    └─layer.9.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.9.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.9.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.9.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.9.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.9.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.9.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.9.attention.output.dense.bias         ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.9.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.9.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.9.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.9.output.dense.bias                   ├─768\n",
      "│    └─layer.9.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.9.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.10.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.query.bias          ├─768\n",
      "│    └─layer.10.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.10.attention.self.key.bias            ├─768\n",
      "│    └─layer.10.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.value.bias          ├─768\n",
      "│    └─layer.10.attention.self.w2e_query.weight    ├─589,824\n",
      "│    └─layer.10.attention.self.w2e_query.bias      ├─768\n",
      "│    └─layer.10.attention.self.e2w_query.weight    ├─589,824\n",
      "│    └─layer.10.attention.self.e2w_query.bias      ├─768\n",
      "│    └─layer.10.attention.self.e2e_query.weight    ├─589,824\n",
      "│    └─layer.10.attention.self.e2e_query.bias      ├─768\n",
      "│    └─layer.10.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.10.attention.output.dense.bias        ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.10.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.10.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.10.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.10.output.dense.bias                  ├─768\n",
      "│    └─layer.10.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.10.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.11.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.query.bias          ├─768\n",
      "│    └─layer.11.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.11.attention.self.key.bias            ├─768\n",
      "│    └─layer.11.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.value.bias          ├─768\n",
      "│    └─layer.11.attention.self.w2e_query.weight    ├─589,824\n",
      "│    └─layer.11.attention.self.w2e_query.bias      ├─768\n",
      "│    └─layer.11.attention.self.e2w_query.weight    ├─589,824\n",
      "│    └─layer.11.attention.self.e2w_query.bias      ├─768\n",
      "│    └─layer.11.attention.self.e2e_query.weight    ├─589,824\n",
      "│    └─layer.11.attention.self.e2e_query.bias      ├─768\n",
      "│    └─layer.11.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.11.attention.output.dense.bias        ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.11.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.11.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.11.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.11.output.dense.bias                  ├─768\n",
      "│    └─layer.11.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.11.output.LayerNorm.bias              └─768\n",
      "│    └─ModuleList: 2-12                            --\n",
      "│    │    └─0.attention.self.query.weight          ├─589,824\n",
      "│    │    └─0.attention.self.query.bias            ├─768\n",
      "│    │    └─0.attention.self.key.weight            ├─589,824\n",
      "│    │    └─0.attention.self.key.bias              ├─768\n",
      "│    │    └─0.attention.self.value.weight          ├─589,824\n",
      "│    │    └─0.attention.self.value.bias            ├─768\n",
      "│    │    └─0.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─0.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─0.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─0.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─0.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─0.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─0.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─0.attention.output.dense.bias          ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─0.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─0.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─0.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─0.output.dense.bias                    ├─768\n",
      "│    │    └─0.output.LayerNorm.weight              ├─768\n",
      "│    │    └─0.output.LayerNorm.bias                ├─768\n",
      "│    │    └─1.attention.self.query.weight          ├─589,824\n",
      "│    │    └─1.attention.self.query.bias            ├─768\n",
      "│    │    └─1.attention.self.key.weight            ├─589,824\n",
      "│    │    └─1.attention.self.key.bias              ├─768\n",
      "│    │    └─1.attention.self.value.weight          ├─589,824\n",
      "│    │    └─1.attention.self.value.bias            ├─768\n",
      "│    │    └─1.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─1.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─1.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─1.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─1.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─1.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─1.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─1.attention.output.dense.bias          ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─1.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─1.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─1.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─1.output.dense.bias                    ├─768\n",
      "│    │    └─1.output.LayerNorm.weight              ├─768\n",
      "│    │    └─1.output.LayerNorm.bias                ├─768\n",
      "│    │    └─2.attention.self.query.weight          ├─589,824\n",
      "│    │    └─2.attention.self.query.bias            ├─768\n",
      "│    │    └─2.attention.self.key.weight            ├─589,824\n",
      "│    │    └─2.attention.self.key.bias              ├─768\n",
      "│    │    └─2.attention.self.value.weight          ├─589,824\n",
      "│    │    └─2.attention.self.value.bias            ├─768\n",
      "│    │    └─2.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─2.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─2.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─2.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─2.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─2.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─2.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─2.attention.output.dense.bias          ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─2.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─2.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─2.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─2.output.dense.bias                    ├─768\n",
      "│    │    └─2.output.LayerNorm.weight              ├─768\n",
      "│    │    └─2.output.LayerNorm.bias                ├─768\n",
      "│    │    └─3.attention.self.query.weight          ├─589,824\n",
      "│    │    └─3.attention.self.query.bias            ├─768\n",
      "│    │    └─3.attention.self.key.weight            ├─589,824\n",
      "│    │    └─3.attention.self.key.bias              ├─768\n",
      "│    │    └─3.attention.self.value.weight          ├─589,824\n",
      "│    │    └─3.attention.self.value.bias            ├─768\n",
      "│    │    └─3.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─3.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─3.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─3.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─3.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─3.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─3.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─3.attention.output.dense.bias          ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─3.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─3.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─3.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─3.output.dense.bias                    ├─768\n",
      "│    │    └─3.output.LayerNorm.weight              ├─768\n",
      "│    │    └─3.output.LayerNorm.bias                ├─768\n",
      "│    │    └─4.attention.self.query.weight          ├─589,824\n",
      "│    │    └─4.attention.self.query.bias            ├─768\n",
      "│    │    └─4.attention.self.key.weight            ├─589,824\n",
      "│    │    └─4.attention.self.key.bias              ├─768\n",
      "│    │    └─4.attention.self.value.weight          ├─589,824\n",
      "│    │    └─4.attention.self.value.bias            ├─768\n",
      "│    │    └─4.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─4.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─4.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─4.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─4.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─4.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─4.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─4.attention.output.dense.bias          ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─4.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─4.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─4.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─4.output.dense.bias                    ├─768\n",
      "│    │    └─4.output.LayerNorm.weight              ├─768\n",
      "│    │    └─4.output.LayerNorm.bias                ├─768\n",
      "│    │    └─5.attention.self.query.weight          ├─589,824\n",
      "│    │    └─5.attention.self.query.bias            ├─768\n",
      "│    │    └─5.attention.self.key.weight            ├─589,824\n",
      "│    │    └─5.attention.self.key.bias              ├─768\n",
      "│    │    └─5.attention.self.value.weight          ├─589,824\n",
      "│    │    └─5.attention.self.value.bias            ├─768\n",
      "│    │    └─5.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─5.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─5.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─5.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─5.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─5.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─5.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─5.attention.output.dense.bias          ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─5.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─5.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─5.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─5.output.dense.bias                    ├─768\n",
      "│    │    └─5.output.LayerNorm.weight              ├─768\n",
      "│    │    └─5.output.LayerNorm.bias                ├─768\n",
      "│    │    └─6.attention.self.query.weight          ├─589,824\n",
      "│    │    └─6.attention.self.query.bias            ├─768\n",
      "│    │    └─6.attention.self.key.weight            ├─589,824\n",
      "│    │    └─6.attention.self.key.bias              ├─768\n",
      "│    │    └─6.attention.self.value.weight          ├─589,824\n",
      "│    │    └─6.attention.self.value.bias            ├─768\n",
      "│    │    └─6.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─6.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─6.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─6.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─6.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─6.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─6.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─6.attention.output.dense.bias          ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─6.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─6.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─6.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─6.output.dense.bias                    ├─768\n",
      "│    │    └─6.output.LayerNorm.weight              ├─768\n",
      "│    │    └─6.output.LayerNorm.bias                ├─768\n",
      "│    │    └─7.attention.self.query.weight          ├─589,824\n",
      "│    │    └─7.attention.self.query.bias            ├─768\n",
      "│    │    └─7.attention.self.key.weight            ├─589,824\n",
      "│    │    └─7.attention.self.key.bias              ├─768\n",
      "│    │    └─7.attention.self.value.weight          ├─589,824\n",
      "│    │    └─7.attention.self.value.bias            ├─768\n",
      "│    │    └─7.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─7.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─7.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─7.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─7.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─7.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─7.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─7.attention.output.dense.bias          ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─7.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─7.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─7.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─7.output.dense.bias                    ├─768\n",
      "│    │    └─7.output.LayerNorm.weight              ├─768\n",
      "│    │    └─7.output.LayerNorm.bias                ├─768\n",
      "│    │    └─8.attention.self.query.weight          ├─589,824\n",
      "│    │    └─8.attention.self.query.bias            ├─768\n",
      "│    │    └─8.attention.self.key.weight            ├─589,824\n",
      "│    │    └─8.attention.self.key.bias              ├─768\n",
      "│    │    └─8.attention.self.value.weight          ├─589,824\n",
      "│    │    └─8.attention.self.value.bias            ├─768\n",
      "│    │    └─8.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─8.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─8.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─8.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─8.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─8.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─8.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─8.attention.output.dense.bias          ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─8.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─8.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─8.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─8.output.dense.bias                    ├─768\n",
      "│    │    └─8.output.LayerNorm.weight              ├─768\n",
      "│    │    └─8.output.LayerNorm.bias                ├─768\n",
      "│    │    └─9.attention.self.query.weight          ├─589,824\n",
      "│    │    └─9.attention.self.query.bias            ├─768\n",
      "│    │    └─9.attention.self.key.weight            ├─589,824\n",
      "│    │    └─9.attention.self.key.bias              ├─768\n",
      "│    │    └─9.attention.self.value.weight          ├─589,824\n",
      "│    │    └─9.attention.self.value.bias            ├─768\n",
      "│    │    └─9.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─9.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─9.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─9.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─9.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─9.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─9.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─9.attention.output.dense.bias          ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─9.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─9.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─9.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─9.output.dense.bias                    ├─768\n",
      "│    │    └─9.output.LayerNorm.weight              ├─768\n",
      "│    │    └─9.output.LayerNorm.bias                ├─768\n",
      "│    │    └─10.attention.self.query.weight         ├─589,824\n",
      "│    │    └─10.attention.self.query.bias           ├─768\n",
      "│    │    └─10.attention.self.key.weight           ├─589,824\n",
      "│    │    └─10.attention.self.key.bias             ├─768\n",
      "│    │    └─10.attention.self.value.weight         ├─589,824\n",
      "│    │    └─10.attention.self.value.bias           ├─768\n",
      "│    │    └─10.attention.self.w2e_query.weight     ├─589,824\n",
      "│    │    └─10.attention.self.w2e_query.bias       ├─768\n",
      "│    │    └─10.attention.self.e2w_query.weight     ├─589,824\n",
      "│    │    └─10.attention.self.e2w_query.bias       ├─768\n",
      "│    │    └─10.attention.self.e2e_query.weight     ├─589,824\n",
      "│    │    └─10.attention.self.e2e_query.bias       ├─768\n",
      "│    │    └─10.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─10.attention.output.dense.bias         ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─10.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─10.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─10.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─10.output.dense.bias                   ├─768\n",
      "│    │    └─10.output.LayerNorm.weight             ├─768\n",
      "│    │    └─10.output.LayerNorm.bias               ├─768\n",
      "│    │    └─11.attention.self.query.weight         ├─589,824\n",
      "│    │    └─11.attention.self.query.bias           ├─768\n",
      "│    │    └─11.attention.self.key.weight           ├─589,824\n",
      "│    │    └─11.attention.self.key.bias             ├─768\n",
      "│    │    └─11.attention.self.value.weight         ├─589,824\n",
      "│    │    └─11.attention.self.value.bias           ├─768\n",
      "│    │    └─11.attention.self.w2e_query.weight     ├─589,824\n",
      "│    │    └─11.attention.self.w2e_query.bias       ├─768\n",
      "│    │    └─11.attention.self.e2w_query.weight     ├─589,824\n",
      "│    │    └─11.attention.self.e2w_query.bias       ├─768\n",
      "│    │    └─11.attention.self.e2e_query.weight     ├─589,824\n",
      "│    │    └─11.attention.self.e2e_query.bias       ├─768\n",
      "│    │    └─11.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─11.attention.output.dense.bias         ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─11.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─11.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─11.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─11.output.dense.bias                   ├─768\n",
      "│    │    └─11.output.LayerNorm.weight             ├─768\n",
      "│    │    └─11.output.LayerNorm.bias               └─768\n",
      "│    │    └─LukeLayer: 3-1                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-2                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-3                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-4                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-5                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-6                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-7                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-8                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-9                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-10                        8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-11                        8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-12                        8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "├─LukePooler: 1-4                                  --\n",
      "│    └─dense.weight                                ├─589,824\n",
      "│    └─dense.bias                                  └─768\n",
      "│    └─Linear: 2-13                                590,592\n",
      "│    │    └─weight                                 ├─589,824\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Tanh: 2-14                                  --\n",
      "===========================================================================\n",
      "Total params: 274,502,144\n",
      "Trainable params: 274,502,144\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "LukeModel                                          --\n",
      "├─LukeEmbeddings: 1-1                              --\n",
      "│    └─word_embeddings.weight                      ├─38,605,056\n",
      "│    └─position_embeddings.weight                  ├─394,752\n",
      "│    └─token_type_embeddings.weight                ├─768\n",
      "│    └─LayerNorm.weight                            ├─768\n",
      "│    └─LayerNorm.bias                              └─768\n",
      "│    └─Embedding: 2-1                              38,605,056\n",
      "│    │    └─weight                                 └─38,605,056\n",
      "│    └─Embedding: 2-2                              394,752\n",
      "│    │    └─weight                                 └─394,752\n",
      "│    └─Embedding: 2-3                              768\n",
      "│    │    └─weight                                 └─768\n",
      "│    └─LayerNorm: 2-4                              1,536\n",
      "│    │    └─weight                                 ├─768\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Dropout: 2-5                                --\n",
      "├─LukeEntityEmbeddings: 1-2                        --\n",
      "│    └─entity_embeddings.weight                    ├─128,000,000\n",
      "│    └─entity_embedding_dense.weight               ├─196,608\n",
      "│    └─position_embeddings.weight                  ├─394,752\n",
      "│    └─token_type_embeddings.weight                ├─768\n",
      "│    └─LayerNorm.weight                            ├─768\n",
      "│    └─LayerNorm.bias                              └─768\n",
      "│    └─Embedding: 2-6                              128,000,000\n",
      "│    │    └─weight                                 └─128,000,000\n",
      "│    └─Linear: 2-7                                 196,608\n",
      "│    │    └─weight                                 └─196,608\n",
      "│    └─Embedding: 2-8                              394,752\n",
      "│    │    └─weight                                 └─394,752\n",
      "│    └─Embedding: 2-9                              768\n",
      "│    │    └─weight                                 └─768\n",
      "│    └─LayerNorm: 2-10                             1,536\n",
      "│    │    └─weight                                 ├─768\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Dropout: 2-11                               --\n",
      "├─LukeEncoder: 1-3                                 --\n",
      "│    └─layer.0.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.query.bias           ├─768\n",
      "│    └─layer.0.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.0.attention.self.key.bias             ├─768\n",
      "│    └─layer.0.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.0.attention.self.value.bias           ├─768\n",
      "│    └─layer.0.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.0.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.0.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.0.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.0.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.0.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.0.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.0.attention.output.dense.bias         ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.0.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.0.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.0.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.0.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.0.output.dense.bias                   ├─768\n",
      "│    └─layer.0.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.0.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.1.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.query.bias           ├─768\n",
      "│    └─layer.1.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.1.attention.self.key.bias             ├─768\n",
      "│    └─layer.1.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.1.attention.self.value.bias           ├─768\n",
      "│    └─layer.1.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.1.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.1.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.1.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.1.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.1.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.1.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.1.attention.output.dense.bias         ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.1.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.1.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.1.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.1.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.1.output.dense.bias                   ├─768\n",
      "│    └─layer.1.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.1.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.2.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.query.bias           ├─768\n",
      "│    └─layer.2.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.2.attention.self.key.bias             ├─768\n",
      "│    └─layer.2.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.2.attention.self.value.bias           ├─768\n",
      "│    └─layer.2.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.2.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.2.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.2.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.2.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.2.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.2.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.2.attention.output.dense.bias         ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.2.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.2.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.2.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.2.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.2.output.dense.bias                   ├─768\n",
      "│    └─layer.2.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.2.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.3.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.query.bias           ├─768\n",
      "│    └─layer.3.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.3.attention.self.key.bias             ├─768\n",
      "│    └─layer.3.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.3.attention.self.value.bias           ├─768\n",
      "│    └─layer.3.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.3.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.3.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.3.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.3.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.3.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.3.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.3.attention.output.dense.bias         ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.3.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.3.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.3.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.3.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.3.output.dense.bias                   ├─768\n",
      "│    └─layer.3.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.3.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.4.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.query.bias           ├─768\n",
      "│    └─layer.4.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.4.attention.self.key.bias             ├─768\n",
      "│    └─layer.4.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.4.attention.self.value.bias           ├─768\n",
      "│    └─layer.4.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.4.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.4.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.4.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.4.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.4.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.4.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.4.attention.output.dense.bias         ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.4.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.4.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.4.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.4.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.4.output.dense.bias                   ├─768\n",
      "│    └─layer.4.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.4.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.5.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.query.bias           ├─768\n",
      "│    └─layer.5.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.5.attention.self.key.bias             ├─768\n",
      "│    └─layer.5.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.5.attention.self.value.bias           ├─768\n",
      "│    └─layer.5.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.5.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.5.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.5.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.5.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.5.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.5.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.5.attention.output.dense.bias         ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.5.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.5.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.5.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.5.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.5.output.dense.bias                   ├─768\n",
      "│    └─layer.5.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.5.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.6.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.query.bias           ├─768\n",
      "│    └─layer.6.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.6.attention.self.key.bias             ├─768\n",
      "│    └─layer.6.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.6.attention.self.value.bias           ├─768\n",
      "│    └─layer.6.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.6.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.6.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.6.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.6.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.6.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.6.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.6.attention.output.dense.bias         ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.6.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.6.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.6.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.6.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.6.output.dense.bias                   ├─768\n",
      "│    └─layer.6.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.6.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.7.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.query.bias           ├─768\n",
      "│    └─layer.7.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.7.attention.self.key.bias             ├─768\n",
      "│    └─layer.7.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.7.attention.self.value.bias           ├─768\n",
      "│    └─layer.7.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.7.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.7.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.7.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.7.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.7.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.7.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.7.attention.output.dense.bias         ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.7.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.7.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.7.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.7.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.7.output.dense.bias                   ├─768\n",
      "│    └─layer.7.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.7.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.8.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.query.bias           ├─768\n",
      "│    └─layer.8.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.8.attention.self.key.bias             ├─768\n",
      "│    └─layer.8.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.8.attention.self.value.bias           ├─768\n",
      "│    └─layer.8.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.8.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.8.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.8.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.8.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.8.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.8.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.8.attention.output.dense.bias         ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.8.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.8.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.8.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.8.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.8.output.dense.bias                   ├─768\n",
      "│    └─layer.8.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.8.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.9.attention.self.query.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.query.bias           ├─768\n",
      "│    └─layer.9.attention.self.key.weight           ├─589,824\n",
      "│    └─layer.9.attention.self.key.bias             ├─768\n",
      "│    └─layer.9.attention.self.value.weight         ├─589,824\n",
      "│    └─layer.9.attention.self.value.bias           ├─768\n",
      "│    └─layer.9.attention.self.w2e_query.weight     ├─589,824\n",
      "│    └─layer.9.attention.self.w2e_query.bias       ├─768\n",
      "│    └─layer.9.attention.self.e2w_query.weight     ├─589,824\n",
      "│    └─layer.9.attention.self.e2w_query.bias       ├─768\n",
      "│    └─layer.9.attention.self.e2e_query.weight     ├─589,824\n",
      "│    └─layer.9.attention.self.e2e_query.bias       ├─768\n",
      "│    └─layer.9.attention.output.dense.weight       ├─589,824\n",
      "│    └─layer.9.attention.output.dense.bias         ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.weight   ├─768\n",
      "│    └─layer.9.attention.output.LayerNorm.bias     ├─768\n",
      "│    └─layer.9.intermediate.dense.weight           ├─2,359,296\n",
      "│    └─layer.9.intermediate.dense.bias             ├─3,072\n",
      "│    └─layer.9.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.9.output.dense.bias                   ├─768\n",
      "│    └─layer.9.output.LayerNorm.weight             ├─768\n",
      "│    └─layer.9.output.LayerNorm.bias               ├─768\n",
      "│    └─layer.10.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.query.bias          ├─768\n",
      "│    └─layer.10.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.10.attention.self.key.bias            ├─768\n",
      "│    └─layer.10.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.10.attention.self.value.bias          ├─768\n",
      "│    └─layer.10.attention.self.w2e_query.weight    ├─589,824\n",
      "│    └─layer.10.attention.self.w2e_query.bias      ├─768\n",
      "│    └─layer.10.attention.self.e2w_query.weight    ├─589,824\n",
      "│    └─layer.10.attention.self.e2w_query.bias      ├─768\n",
      "│    └─layer.10.attention.self.e2e_query.weight    ├─589,824\n",
      "│    └─layer.10.attention.self.e2e_query.bias      ├─768\n",
      "│    └─layer.10.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.10.attention.output.dense.bias        ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.10.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.10.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.10.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.10.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.10.output.dense.bias                  ├─768\n",
      "│    └─layer.10.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.10.output.LayerNorm.bias              ├─768\n",
      "│    └─layer.11.attention.self.query.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.query.bias          ├─768\n",
      "│    └─layer.11.attention.self.key.weight          ├─589,824\n",
      "│    └─layer.11.attention.self.key.bias            ├─768\n",
      "│    └─layer.11.attention.self.value.weight        ├─589,824\n",
      "│    └─layer.11.attention.self.value.bias          ├─768\n",
      "│    └─layer.11.attention.self.w2e_query.weight    ├─589,824\n",
      "│    └─layer.11.attention.self.w2e_query.bias      ├─768\n",
      "│    └─layer.11.attention.self.e2w_query.weight    ├─589,824\n",
      "│    └─layer.11.attention.self.e2w_query.bias      ├─768\n",
      "│    └─layer.11.attention.self.e2e_query.weight    ├─589,824\n",
      "│    └─layer.11.attention.self.e2e_query.bias      ├─768\n",
      "│    └─layer.11.attention.output.dense.weight      ├─589,824\n",
      "│    └─layer.11.attention.output.dense.bias        ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.weight  ├─768\n",
      "│    └─layer.11.attention.output.LayerNorm.bias    ├─768\n",
      "│    └─layer.11.intermediate.dense.weight          ├─2,359,296\n",
      "│    └─layer.11.intermediate.dense.bias            ├─3,072\n",
      "│    └─layer.11.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.11.output.dense.bias                  ├─768\n",
      "│    └─layer.11.output.LayerNorm.weight            ├─768\n",
      "│    └─layer.11.output.LayerNorm.bias              └─768\n",
      "│    └─ModuleList: 2-12                            --\n",
      "│    │    └─0.attention.self.query.weight          ├─589,824\n",
      "│    │    └─0.attention.self.query.bias            ├─768\n",
      "│    │    └─0.attention.self.key.weight            ├─589,824\n",
      "│    │    └─0.attention.self.key.bias              ├─768\n",
      "│    │    └─0.attention.self.value.weight          ├─589,824\n",
      "│    │    └─0.attention.self.value.bias            ├─768\n",
      "│    │    └─0.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─0.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─0.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─0.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─0.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─0.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─0.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─0.attention.output.dense.bias          ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─0.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─0.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─0.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─0.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─0.output.dense.bias                    ├─768\n",
      "│    │    └─0.output.LayerNorm.weight              ├─768\n",
      "│    │    └─0.output.LayerNorm.bias                ├─768\n",
      "│    │    └─1.attention.self.query.weight          ├─589,824\n",
      "│    │    └─1.attention.self.query.bias            ├─768\n",
      "│    │    └─1.attention.self.key.weight            ├─589,824\n",
      "│    │    └─1.attention.self.key.bias              ├─768\n",
      "│    │    └─1.attention.self.value.weight          ├─589,824\n",
      "│    │    └─1.attention.self.value.bias            ├─768\n",
      "│    │    └─1.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─1.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─1.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─1.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─1.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─1.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─1.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─1.attention.output.dense.bias          ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─1.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─1.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─1.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─1.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─1.output.dense.bias                    ├─768\n",
      "│    │    └─1.output.LayerNorm.weight              ├─768\n",
      "│    │    └─1.output.LayerNorm.bias                ├─768\n",
      "│    │    └─2.attention.self.query.weight          ├─589,824\n",
      "│    │    └─2.attention.self.query.bias            ├─768\n",
      "│    │    └─2.attention.self.key.weight            ├─589,824\n",
      "│    │    └─2.attention.self.key.bias              ├─768\n",
      "│    │    └─2.attention.self.value.weight          ├─589,824\n",
      "│    │    └─2.attention.self.value.bias            ├─768\n",
      "│    │    └─2.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─2.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─2.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─2.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─2.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─2.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─2.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─2.attention.output.dense.bias          ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─2.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─2.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─2.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─2.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─2.output.dense.bias                    ├─768\n",
      "│    │    └─2.output.LayerNorm.weight              ├─768\n",
      "│    │    └─2.output.LayerNorm.bias                ├─768\n",
      "│    │    └─3.attention.self.query.weight          ├─589,824\n",
      "│    │    └─3.attention.self.query.bias            ├─768\n",
      "│    │    └─3.attention.self.key.weight            ├─589,824\n",
      "│    │    └─3.attention.self.key.bias              ├─768\n",
      "│    │    └─3.attention.self.value.weight          ├─589,824\n",
      "│    │    └─3.attention.self.value.bias            ├─768\n",
      "│    │    └─3.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─3.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─3.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─3.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─3.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─3.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─3.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─3.attention.output.dense.bias          ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─3.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─3.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─3.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─3.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─3.output.dense.bias                    ├─768\n",
      "│    │    └─3.output.LayerNorm.weight              ├─768\n",
      "│    │    └─3.output.LayerNorm.bias                ├─768\n",
      "│    │    └─4.attention.self.query.weight          ├─589,824\n",
      "│    │    └─4.attention.self.query.bias            ├─768\n",
      "│    │    └─4.attention.self.key.weight            ├─589,824\n",
      "│    │    └─4.attention.self.key.bias              ├─768\n",
      "│    │    └─4.attention.self.value.weight          ├─589,824\n",
      "│    │    └─4.attention.self.value.bias            ├─768\n",
      "│    │    └─4.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─4.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─4.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─4.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─4.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─4.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─4.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─4.attention.output.dense.bias          ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─4.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─4.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─4.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─4.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─4.output.dense.bias                    ├─768\n",
      "│    │    └─4.output.LayerNorm.weight              ├─768\n",
      "│    │    └─4.output.LayerNorm.bias                ├─768\n",
      "│    │    └─5.attention.self.query.weight          ├─589,824\n",
      "│    │    └─5.attention.self.query.bias            ├─768\n",
      "│    │    └─5.attention.self.key.weight            ├─589,824\n",
      "│    │    └─5.attention.self.key.bias              ├─768\n",
      "│    │    └─5.attention.self.value.weight          ├─589,824\n",
      "│    │    └─5.attention.self.value.bias            ├─768\n",
      "│    │    └─5.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─5.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─5.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─5.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─5.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─5.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─5.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─5.attention.output.dense.bias          ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─5.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─5.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─5.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─5.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─5.output.dense.bias                    ├─768\n",
      "│    │    └─5.output.LayerNorm.weight              ├─768\n",
      "│    │    └─5.output.LayerNorm.bias                ├─768\n",
      "│    │    └─6.attention.self.query.weight          ├─589,824\n",
      "│    │    └─6.attention.self.query.bias            ├─768\n",
      "│    │    └─6.attention.self.key.weight            ├─589,824\n",
      "│    │    └─6.attention.self.key.bias              ├─768\n",
      "│    │    └─6.attention.self.value.weight          ├─589,824\n",
      "│    │    └─6.attention.self.value.bias            ├─768\n",
      "│    │    └─6.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─6.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─6.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─6.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─6.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─6.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─6.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─6.attention.output.dense.bias          ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─6.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─6.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─6.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─6.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─6.output.dense.bias                    ├─768\n",
      "│    │    └─6.output.LayerNorm.weight              ├─768\n",
      "│    │    └─6.output.LayerNorm.bias                ├─768\n",
      "│    │    └─7.attention.self.query.weight          ├─589,824\n",
      "│    │    └─7.attention.self.query.bias            ├─768\n",
      "│    │    └─7.attention.self.key.weight            ├─589,824\n",
      "│    │    └─7.attention.self.key.bias              ├─768\n",
      "│    │    └─7.attention.self.value.weight          ├─589,824\n",
      "│    │    └─7.attention.self.value.bias            ├─768\n",
      "│    │    └─7.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─7.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─7.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─7.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─7.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─7.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─7.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─7.attention.output.dense.bias          ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─7.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─7.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─7.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─7.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─7.output.dense.bias                    ├─768\n",
      "│    │    └─7.output.LayerNorm.weight              ├─768\n",
      "│    │    └─7.output.LayerNorm.bias                ├─768\n",
      "│    │    └─8.attention.self.query.weight          ├─589,824\n",
      "│    │    └─8.attention.self.query.bias            ├─768\n",
      "│    │    └─8.attention.self.key.weight            ├─589,824\n",
      "│    │    └─8.attention.self.key.bias              ├─768\n",
      "│    │    └─8.attention.self.value.weight          ├─589,824\n",
      "│    │    └─8.attention.self.value.bias            ├─768\n",
      "│    │    └─8.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─8.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─8.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─8.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─8.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─8.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─8.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─8.attention.output.dense.bias          ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─8.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─8.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─8.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─8.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─8.output.dense.bias                    ├─768\n",
      "│    │    └─8.output.LayerNorm.weight              ├─768\n",
      "│    │    └─8.output.LayerNorm.bias                ├─768\n",
      "│    │    └─9.attention.self.query.weight          ├─589,824\n",
      "│    │    └─9.attention.self.query.bias            ├─768\n",
      "│    │    └─9.attention.self.key.weight            ├─589,824\n",
      "│    │    └─9.attention.self.key.bias              ├─768\n",
      "│    │    └─9.attention.self.value.weight          ├─589,824\n",
      "│    │    └─9.attention.self.value.bias            ├─768\n",
      "│    │    └─9.attention.self.w2e_query.weight      ├─589,824\n",
      "│    │    └─9.attention.self.w2e_query.bias        ├─768\n",
      "│    │    └─9.attention.self.e2w_query.weight      ├─589,824\n",
      "│    │    └─9.attention.self.e2w_query.bias        ├─768\n",
      "│    │    └─9.attention.self.e2e_query.weight      ├─589,824\n",
      "│    │    └─9.attention.self.e2e_query.bias        ├─768\n",
      "│    │    └─9.attention.output.dense.weight        ├─589,824\n",
      "│    │    └─9.attention.output.dense.bias          ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.weight    ├─768\n",
      "│    │    └─9.attention.output.LayerNorm.bias      ├─768\n",
      "│    │    └─9.intermediate.dense.weight            ├─2,359,296\n",
      "│    │    └─9.intermediate.dense.bias              ├─3,072\n",
      "│    │    └─9.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─9.output.dense.bias                    ├─768\n",
      "│    │    └─9.output.LayerNorm.weight              ├─768\n",
      "│    │    └─9.output.LayerNorm.bias                ├─768\n",
      "│    │    └─10.attention.self.query.weight         ├─589,824\n",
      "│    │    └─10.attention.self.query.bias           ├─768\n",
      "│    │    └─10.attention.self.key.weight           ├─589,824\n",
      "│    │    └─10.attention.self.key.bias             ├─768\n",
      "│    │    └─10.attention.self.value.weight         ├─589,824\n",
      "│    │    └─10.attention.self.value.bias           ├─768\n",
      "│    │    └─10.attention.self.w2e_query.weight     ├─589,824\n",
      "│    │    └─10.attention.self.w2e_query.bias       ├─768\n",
      "│    │    └─10.attention.self.e2w_query.weight     ├─589,824\n",
      "│    │    └─10.attention.self.e2w_query.bias       ├─768\n",
      "│    │    └─10.attention.self.e2e_query.weight     ├─589,824\n",
      "│    │    └─10.attention.self.e2e_query.bias       ├─768\n",
      "│    │    └─10.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─10.attention.output.dense.bias         ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─10.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─10.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─10.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─10.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─10.output.dense.bias                   ├─768\n",
      "│    │    └─10.output.LayerNorm.weight             ├─768\n",
      "│    │    └─10.output.LayerNorm.bias               ├─768\n",
      "│    │    └─11.attention.self.query.weight         ├─589,824\n",
      "│    │    └─11.attention.self.query.bias           ├─768\n",
      "│    │    └─11.attention.self.key.weight           ├─589,824\n",
      "│    │    └─11.attention.self.key.bias             ├─768\n",
      "│    │    └─11.attention.self.value.weight         ├─589,824\n",
      "│    │    └─11.attention.self.value.bias           ├─768\n",
      "│    │    └─11.attention.self.w2e_query.weight     ├─589,824\n",
      "│    │    └─11.attention.self.w2e_query.bias       ├─768\n",
      "│    │    └─11.attention.self.e2w_query.weight     ├─589,824\n",
      "│    │    └─11.attention.self.e2w_query.bias       ├─768\n",
      "│    │    └─11.attention.self.e2e_query.weight     ├─589,824\n",
      "│    │    └─11.attention.self.e2e_query.bias       ├─768\n",
      "│    │    └─11.attention.output.dense.weight       ├─589,824\n",
      "│    │    └─11.attention.output.dense.bias         ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.weight   ├─768\n",
      "│    │    └─11.attention.output.LayerNorm.bias     ├─768\n",
      "│    │    └─11.intermediate.dense.weight           ├─2,359,296\n",
      "│    │    └─11.intermediate.dense.bias             ├─3,072\n",
      "│    │    └─11.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─11.output.dense.bias                   ├─768\n",
      "│    │    └─11.output.LayerNorm.weight             ├─768\n",
      "│    │    └─11.output.LayerNorm.bias               └─768\n",
      "│    │    └─LukeLayer: 3-1                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-2                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-3                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-4                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-5                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-6                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-7                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-8                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-9                         8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-10                        8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-11                        8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "│    │    └─LukeLayer: 3-12                        8,859,648\n",
      "│    │    │    └─attention.self.query.weight       ├─589,824\n",
      "│    │    │    └─attention.self.query.bias         ├─768\n",
      "│    │    │    └─attention.self.key.weight         ├─589,824\n",
      "│    │    │    └─attention.self.key.bias           ├─768\n",
      "│    │    │    └─attention.self.value.weight       ├─589,824\n",
      "│    │    │    └─attention.self.value.bias         ├─768\n",
      "│    │    │    └─attention.self.w2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.w2e_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2w_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2w_query.bias     ├─768\n",
      "│    │    │    └─attention.self.e2e_query.weight   ├─589,824\n",
      "│    │    │    └─attention.self.e2e_query.bias     ├─768\n",
      "│    │    │    └─attention.output.dense.weight     ├─589,824\n",
      "│    │    │    └─attention.output.dense.bias       ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.weight ├─768\n",
      "│    │    │    └─attention.output.LayerNorm.bias   ├─768\n",
      "│    │    │    └─intermediate.dense.weight         ├─2,359,296\n",
      "│    │    │    └─intermediate.dense.bias           ├─3,072\n",
      "│    │    │    └─output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─output.dense.bias                 ├─768\n",
      "│    │    │    └─output.LayerNorm.weight           ├─768\n",
      "│    │    │    └─output.LayerNorm.bias             └─768\n",
      "├─LukePooler: 1-4                                  --\n",
      "│    └─dense.weight                                ├─589,824\n",
      "│    └─dense.bias                                  └─768\n",
      "│    └─Linear: 2-13                                590,592\n",
      "│    │    └─weight                                 ├─589,824\n",
      "│    │    └─bias                                   └─768\n",
      "│    └─Tanh: 2-14                                  --\n",
      "===========================================================================\n",
      "Total params: 274,502,144\n",
      "Trainable params: 274,502,144\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import LukeModel\n",
    "\n",
    "luka_model = LukeModel.from_pretrained(\"studio-ousia/luke-base\")\n",
    "print_summary(luka_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe655f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd5c357a2b845bfb16a69d23f199aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/908 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89922fe42a3e410ea3de2872de1571d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/m2m100_418M were not used when initializing M2M100Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing M2M100Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing M2M100Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of M2M100Model were not initialized from the model checkpoint at facebook/m2m100_418M and are newly initialized: ['model.decoder.embed_positions.weights', 'model.encoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2M100Model(\n",
      "  (shared): Embedding(128112, 1024, padding_idx=1)\n",
      "  (encoder): M2M100Encoder(\n",
      "    (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
      "    (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): M2M100EncoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): ReLU()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): M2M100Decoder(\n",
      "    (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
      "    (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): M2M100DecoderLayer(\n",
      "        (self_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): M2M100Attention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "M2M100Model                                             --\n",
      "├─Embedding: 1-1                                        131,186,688\n",
      "│    └─weight                                           └─131,186,688\n",
      "├─M2M100Encoder: 1-2                                    131,186,688\n",
      "│    └─embed_tokens.weight                              ├─131,186,688\n",
      "│    └─layers.0.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.0.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.0.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc1.bias                                ├─4,096\n",
      "│    └─layers.0.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc2.bias                                ├─1,024\n",
      "│    └─layers.0.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.0.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.1.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.1.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc1.bias                                ├─4,096\n",
      "│    └─layers.1.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc2.bias                                ├─1,024\n",
      "│    └─layers.1.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.1.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.2.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.2.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc1.bias                                ├─4,096\n",
      "│    └─layers.2.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc2.bias                                ├─1,024\n",
      "│    └─layers.2.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.2.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.3.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.3.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc1.bias                                ├─4,096\n",
      "│    └─layers.3.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc2.bias                                ├─1,024\n",
      "│    └─layers.3.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.3.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.4.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.4.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc1.bias                                ├─4,096\n",
      "│    └─layers.4.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc2.bias                                ├─1,024\n",
      "│    └─layers.4.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.4.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.5.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.5.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc1.bias                                ├─4,096\n",
      "│    └─layers.5.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc2.bias                                ├─1,024\n",
      "│    └─layers.5.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.5.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.6.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.6.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc1.bias                                ├─4,096\n",
      "│    └─layers.6.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc2.bias                                ├─1,024\n",
      "│    └─layers.6.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.6.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.7.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.7.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc1.bias                                ├─4,096\n",
      "│    └─layers.7.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc2.bias                                ├─1,024\n",
      "│    └─layers.7.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.7.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.8.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.8.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc1.bias                                ├─4,096\n",
      "│    └─layers.8.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc2.bias                                ├─1,024\n",
      "│    └─layers.8.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.8.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.9.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.9.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc1.bias                                ├─4,096\n",
      "│    └─layers.9.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc2.bias                                ├─1,024\n",
      "│    └─layers.9.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.9.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.10.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.10.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.10.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc1.bias                               ├─4,096\n",
      "│    └─layers.10.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc2.bias                               ├─1,024\n",
      "│    └─layers.10.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.10.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.11.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.11.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc1.bias                               ├─4,096\n",
      "│    └─layers.11.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc2.bias                               ├─1,024\n",
      "│    └─layers.11.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.11.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layer_norm.weight                                ├─1,024\n",
      "│    └─layer_norm.bias                                  └─1,024\n",
      "│    └─Embedding: 2-1                                   (recursive)\n",
      "│    │    └─weight                                      └─131,186,688\n",
      "│    └─M2M100SinusoidalPositionalEmbedding: 2-2         --\n",
      "│    └─ModuleList: 2-3                                  --\n",
      "│    │    └─0.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─0.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─0.fc1.weight                                ├─4,194,304\n",
      "│    │    └─0.fc1.bias                                  ├─4,096\n",
      "│    │    └─0.fc2.weight                                ├─4,194,304\n",
      "│    │    └─0.fc2.bias                                  ├─1,024\n",
      "│    │    └─0.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─0.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─1.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─1.fc1.weight                                ├─4,194,304\n",
      "│    │    └─1.fc1.bias                                  ├─4,096\n",
      "│    │    └─1.fc2.weight                                ├─4,194,304\n",
      "│    │    └─1.fc2.bias                                  ├─1,024\n",
      "│    │    └─1.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─1.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─2.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─2.fc1.weight                                ├─4,194,304\n",
      "│    │    └─2.fc1.bias                                  ├─4,096\n",
      "│    │    └─2.fc2.weight                                ├─4,194,304\n",
      "│    │    └─2.fc2.bias                                  ├─1,024\n",
      "│    │    └─2.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─2.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─3.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─3.fc1.weight                                ├─4,194,304\n",
      "│    │    └─3.fc1.bias                                  ├─4,096\n",
      "│    │    └─3.fc2.weight                                ├─4,194,304\n",
      "│    │    └─3.fc2.bias                                  ├─1,024\n",
      "│    │    └─3.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─3.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─4.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─4.fc1.weight                                ├─4,194,304\n",
      "│    │    └─4.fc1.bias                                  ├─4,096\n",
      "│    │    └─4.fc2.weight                                ├─4,194,304\n",
      "│    │    └─4.fc2.bias                                  ├─1,024\n",
      "│    │    └─4.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─4.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─5.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─5.fc1.weight                                ├─4,194,304\n",
      "│    │    └─5.fc1.bias                                  ├─4,096\n",
      "│    │    └─5.fc2.weight                                ├─4,194,304\n",
      "│    │    └─5.fc2.bias                                  ├─1,024\n",
      "│    │    └─5.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─5.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─6.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─6.fc1.weight                                ├─4,194,304\n",
      "│    │    └─6.fc1.bias                                  ├─4,096\n",
      "│    │    └─6.fc2.weight                                ├─4,194,304\n",
      "│    │    └─6.fc2.bias                                  ├─1,024\n",
      "│    │    └─6.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─6.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─7.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─7.fc1.weight                                ├─4,194,304\n",
      "│    │    └─7.fc1.bias                                  ├─4,096\n",
      "│    │    └─7.fc2.weight                                ├─4,194,304\n",
      "│    │    └─7.fc2.bias                                  ├─1,024\n",
      "│    │    └─7.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─7.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─8.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─8.fc1.weight                                ├─4,194,304\n",
      "│    │    └─8.fc1.bias                                  ├─4,096\n",
      "│    │    └─8.fc2.weight                                ├─4,194,304\n",
      "│    │    └─8.fc2.bias                                  ├─1,024\n",
      "│    │    └─8.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─8.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─9.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─9.fc1.weight                                ├─4,194,304\n",
      "│    │    └─9.fc1.bias                                  ├─4,096\n",
      "│    │    └─9.fc2.weight                                ├─4,194,304\n",
      "│    │    └─9.fc2.bias                                  ├─1,024\n",
      "│    │    └─9.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─9.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─10.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─10.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─10.fc1.weight                               ├─4,194,304\n",
      "│    │    └─10.fc1.bias                                 ├─4,096\n",
      "│    │    └─10.fc2.weight                               ├─4,194,304\n",
      "│    │    └─10.fc2.bias                                 ├─1,024\n",
      "│    │    └─10.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─10.final_layer_norm.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─11.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─11.fc1.weight                               ├─4,194,304\n",
      "│    │    └─11.fc1.bias                                 ├─4,096\n",
      "│    │    └─11.fc2.weight                               ├─4,194,304\n",
      "│    │    └─11.fc2.bias                                 ├─1,024\n",
      "│    │    └─11.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─11.final_layer_norm.bias                    └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-1                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-2                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-3                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-4                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-5                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-6                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-7                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-8                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-9                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-10                    12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-11                    12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-12                    12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    └─LayerNorm: 2-4                                   2,048\n",
      "│    │    └─weight                                      ├─1,024\n",
      "│    │    └─bias                                        └─1,024\n",
      "├─M2M100Decoder: 1-3                                    131,186,688\n",
      "│    └─embed_tokens.weight                              ├─131,186,688\n",
      "│    └─layers.0.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.0.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.0.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.0.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.0.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.0.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.0.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.0.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.0.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc1.bias                                ├─4,096\n",
      "│    └─layers.0.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc2.bias                                ├─1,024\n",
      "│    └─layers.0.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.0.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.1.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.1.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.1.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.1.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.1.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.1.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.1.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.1.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc1.bias                                ├─4,096\n",
      "│    └─layers.1.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc2.bias                                ├─1,024\n",
      "│    └─layers.1.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.1.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.2.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.2.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.2.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.2.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.2.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.2.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.2.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.2.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc1.bias                                ├─4,096\n",
      "│    └─layers.2.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc2.bias                                ├─1,024\n",
      "│    └─layers.2.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.2.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.3.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.3.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.3.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.3.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.3.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.3.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.3.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.3.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc1.bias                                ├─4,096\n",
      "│    └─layers.3.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc2.bias                                ├─1,024\n",
      "│    └─layers.3.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.3.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.4.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.4.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.4.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.4.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.4.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.4.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.4.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.4.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc1.bias                                ├─4,096\n",
      "│    └─layers.4.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc2.bias                                ├─1,024\n",
      "│    └─layers.4.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.4.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.5.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.5.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.5.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.5.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.5.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.5.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.5.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.5.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc1.bias                                ├─4,096\n",
      "│    └─layers.5.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc2.bias                                ├─1,024\n",
      "│    └─layers.5.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.5.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.6.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.6.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.6.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.6.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.6.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.6.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.6.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.6.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc1.bias                                ├─4,096\n",
      "│    └─layers.6.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc2.bias                                ├─1,024\n",
      "│    └─layers.6.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.6.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.7.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.7.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.7.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.7.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.7.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.7.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.7.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.7.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc1.bias                                ├─4,096\n",
      "│    └─layers.7.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc2.bias                                ├─1,024\n",
      "│    └─layers.7.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.7.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.8.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.8.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.8.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.8.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.8.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.8.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.8.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.8.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc1.bias                                ├─4,096\n",
      "│    └─layers.8.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc2.bias                                ├─1,024\n",
      "│    └─layers.8.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.8.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.9.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.9.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.9.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.9.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.9.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.9.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.9.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.9.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc1.bias                                ├─4,096\n",
      "│    └─layers.9.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc2.bias                                ├─1,024\n",
      "│    └─layers.9.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.9.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.10.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.10.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.10.encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.k_proj.bias               ├─1,024\n",
      "│    └─layers.10.encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.v_proj.bias               ├─1,024\n",
      "│    └─layers.10.encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.q_proj.bias               ├─1,024\n",
      "│    └─layers.10.encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.out_proj.bias             ├─1,024\n",
      "│    └─layers.10.encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    └─layers.10.encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    └─layers.10.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc1.bias                               ├─4,096\n",
      "│    └─layers.10.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc2.bias                               ├─1,024\n",
      "│    └─layers.10.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.10.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.11.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.11.encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.k_proj.bias               ├─1,024\n",
      "│    └─layers.11.encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.v_proj.bias               ├─1,024\n",
      "│    └─layers.11.encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.q_proj.bias               ├─1,024\n",
      "│    └─layers.11.encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.out_proj.bias             ├─1,024\n",
      "│    └─layers.11.encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    └─layers.11.encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    └─layers.11.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc1.bias                               ├─4,096\n",
      "│    └─layers.11.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc2.bias                               ├─1,024\n",
      "│    └─layers.11.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.11.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layer_norm.weight                                ├─1,024\n",
      "│    └─layer_norm.bias                                  └─1,024\n",
      "│    └─Embedding: 2-5                                   (recursive)\n",
      "│    │    └─weight                                      └─131,186,688\n",
      "│    └─M2M100SinusoidalPositionalEmbedding: 2-6         --\n",
      "│    └─ModuleList: 2-7                                  --\n",
      "│    │    └─0.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─0.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─0.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─0.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─0.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─0.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─0.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─0.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─0.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─0.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─0.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─0.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─0.fc1.weight                                ├─4,194,304\n",
      "│    │    └─0.fc1.bias                                  ├─4,096\n",
      "│    │    └─0.fc2.weight                                ├─4,194,304\n",
      "│    │    └─0.fc2.bias                                  ├─1,024\n",
      "│    │    └─0.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─0.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─1.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─1.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─1.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─1.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─1.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─1.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─1.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─1.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─1.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─1.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─1.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─1.fc1.weight                                ├─4,194,304\n",
      "│    │    └─1.fc1.bias                                  ├─4,096\n",
      "│    │    └─1.fc2.weight                                ├─4,194,304\n",
      "│    │    └─1.fc2.bias                                  ├─1,024\n",
      "│    │    └─1.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─1.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─2.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─2.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─2.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─2.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─2.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─2.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─2.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─2.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─2.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─2.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─2.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─2.fc1.weight                                ├─4,194,304\n",
      "│    │    └─2.fc1.bias                                  ├─4,096\n",
      "│    │    └─2.fc2.weight                                ├─4,194,304\n",
      "│    │    └─2.fc2.bias                                  ├─1,024\n",
      "│    │    └─2.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─2.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─3.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─3.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─3.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─3.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─3.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─3.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─3.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─3.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─3.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─3.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─3.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─3.fc1.weight                                ├─4,194,304\n",
      "│    │    └─3.fc1.bias                                  ├─4,096\n",
      "│    │    └─3.fc2.weight                                ├─4,194,304\n",
      "│    │    └─3.fc2.bias                                  ├─1,024\n",
      "│    │    └─3.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─3.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─4.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─4.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─4.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─4.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─4.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─4.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─4.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─4.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─4.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─4.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─4.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─4.fc1.weight                                ├─4,194,304\n",
      "│    │    └─4.fc1.bias                                  ├─4,096\n",
      "│    │    └─4.fc2.weight                                ├─4,194,304\n",
      "│    │    └─4.fc2.bias                                  ├─1,024\n",
      "│    │    └─4.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─4.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─5.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─5.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─5.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─5.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─5.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─5.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─5.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─5.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─5.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─5.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─5.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─5.fc1.weight                                ├─4,194,304\n",
      "│    │    └─5.fc1.bias                                  ├─4,096\n",
      "│    │    └─5.fc2.weight                                ├─4,194,304\n",
      "│    │    └─5.fc2.bias                                  ├─1,024\n",
      "│    │    └─5.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─5.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─6.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─6.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─6.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─6.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─6.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─6.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─6.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─6.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─6.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─6.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─6.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─6.fc1.weight                                ├─4,194,304\n",
      "│    │    └─6.fc1.bias                                  ├─4,096\n",
      "│    │    └─6.fc2.weight                                ├─4,194,304\n",
      "│    │    └─6.fc2.bias                                  ├─1,024\n",
      "│    │    └─6.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─6.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─7.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─7.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─7.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─7.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─7.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─7.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─7.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─7.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─7.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─7.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─7.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─7.fc1.weight                                ├─4,194,304\n",
      "│    │    └─7.fc1.bias                                  ├─4,096\n",
      "│    │    └─7.fc2.weight                                ├─4,194,304\n",
      "│    │    └─7.fc2.bias                                  ├─1,024\n",
      "│    │    └─7.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─7.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─8.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─8.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─8.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─8.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─8.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─8.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─8.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─8.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─8.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─8.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─8.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─8.fc1.weight                                ├─4,194,304\n",
      "│    │    └─8.fc1.bias                                  ├─4,096\n",
      "│    │    └─8.fc2.weight                                ├─4,194,304\n",
      "│    │    └─8.fc2.bias                                  ├─1,024\n",
      "│    │    └─8.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─8.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─9.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─9.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─9.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─9.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─9.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─9.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─9.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─9.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─9.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─9.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─9.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─9.fc1.weight                                ├─4,194,304\n",
      "│    │    └─9.fc1.bias                                  ├─4,096\n",
      "│    │    └─9.fc2.weight                                ├─4,194,304\n",
      "│    │    └─9.fc2.bias                                  ├─1,024\n",
      "│    │    └─9.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─9.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─10.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─10.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─10.encoder_attn.k_proj.weight               ├─1,048,576\n",
      "│    │    └─10.encoder_attn.k_proj.bias                 ├─1,024\n",
      "│    │    └─10.encoder_attn.v_proj.weight               ├─1,048,576\n",
      "│    │    └─10.encoder_attn.v_proj.bias                 ├─1,024\n",
      "│    │    └─10.encoder_attn.q_proj.weight               ├─1,048,576\n",
      "│    │    └─10.encoder_attn.q_proj.bias                 ├─1,024\n",
      "│    │    └─10.encoder_attn.out_proj.weight             ├─1,048,576\n",
      "│    │    └─10.encoder_attn.out_proj.bias               ├─1,024\n",
      "│    │    └─10.encoder_attn_layer_norm.weight           ├─1,024\n",
      "│    │    └─10.encoder_attn_layer_norm.bias             ├─1,024\n",
      "│    │    └─10.fc1.weight                               ├─4,194,304\n",
      "│    │    └─10.fc1.bias                                 ├─4,096\n",
      "│    │    └─10.fc2.weight                               ├─4,194,304\n",
      "│    │    └─10.fc2.bias                                 ├─1,024\n",
      "│    │    └─10.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─10.final_layer_norm.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─11.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─11.encoder_attn.k_proj.weight               ├─1,048,576\n",
      "│    │    └─11.encoder_attn.k_proj.bias                 ├─1,024\n",
      "│    │    └─11.encoder_attn.v_proj.weight               ├─1,048,576\n",
      "│    │    └─11.encoder_attn.v_proj.bias                 ├─1,024\n",
      "│    │    └─11.encoder_attn.q_proj.weight               ├─1,048,576\n",
      "│    │    └─11.encoder_attn.q_proj.bias                 ├─1,024\n",
      "│    │    └─11.encoder_attn.out_proj.weight             ├─1,048,576\n",
      "│    │    └─11.encoder_attn.out_proj.bias               ├─1,024\n",
      "│    │    └─11.encoder_attn_layer_norm.weight           ├─1,024\n",
      "│    │    └─11.encoder_attn_layer_norm.bias             ├─1,024\n",
      "│    │    └─11.fc1.weight                               ├─4,194,304\n",
      "│    │    └─11.fc1.bias                                 ├─4,096\n",
      "│    │    └─11.fc2.weight                               ├─4,194,304\n",
      "│    │    └─11.fc2.bias                                 ├─1,024\n",
      "│    │    └─11.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─11.final_layer_norm.bias                    └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-13                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-14                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-15                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-16                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-17                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-18                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-19                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-20                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-21                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-22                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-23                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-24                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    └─LayerNorm: 2-8                                   2,048\n",
      "│    │    └─weight                                      ├─1,024\n",
      "│    │    └─bias                                        └─1,024\n",
      "================================================================================\n",
      "Total params: 483,905,536\n",
      "Trainable params: 483,905,536\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "M2M100Model                                             --\n",
      "├─Embedding: 1-1                                        131,186,688\n",
      "│    └─weight                                           └─131,186,688\n",
      "├─M2M100Encoder: 1-2                                    131,186,688\n",
      "│    └─embed_tokens.weight                              ├─131,186,688\n",
      "│    └─layers.0.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.0.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.0.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc1.bias                                ├─4,096\n",
      "│    └─layers.0.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc2.bias                                ├─1,024\n",
      "│    └─layers.0.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.0.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.1.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.1.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc1.bias                                ├─4,096\n",
      "│    └─layers.1.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc2.bias                                ├─1,024\n",
      "│    └─layers.1.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.1.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.2.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.2.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc1.bias                                ├─4,096\n",
      "│    └─layers.2.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc2.bias                                ├─1,024\n",
      "│    └─layers.2.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.2.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.3.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.3.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc1.bias                                ├─4,096\n",
      "│    └─layers.3.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc2.bias                                ├─1,024\n",
      "│    └─layers.3.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.3.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.4.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.4.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc1.bias                                ├─4,096\n",
      "│    └─layers.4.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc2.bias                                ├─1,024\n",
      "│    └─layers.4.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.4.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.5.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.5.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc1.bias                                ├─4,096\n",
      "│    └─layers.5.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc2.bias                                ├─1,024\n",
      "│    └─layers.5.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.5.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.6.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.6.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc1.bias                                ├─4,096\n",
      "│    └─layers.6.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc2.bias                                ├─1,024\n",
      "│    └─layers.6.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.6.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.7.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.7.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc1.bias                                ├─4,096\n",
      "│    └─layers.7.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc2.bias                                ├─1,024\n",
      "│    └─layers.7.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.7.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.8.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.8.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc1.bias                                ├─4,096\n",
      "│    └─layers.8.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc2.bias                                ├─1,024\n",
      "│    └─layers.8.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.8.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.9.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.9.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc1.bias                                ├─4,096\n",
      "│    └─layers.9.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc2.bias                                ├─1,024\n",
      "│    └─layers.9.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.9.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.10.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.10.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.10.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc1.bias                               ├─4,096\n",
      "│    └─layers.10.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc2.bias                               ├─1,024\n",
      "│    └─layers.10.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.10.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.11.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.11.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc1.bias                               ├─4,096\n",
      "│    └─layers.11.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc2.bias                               ├─1,024\n",
      "│    └─layers.11.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.11.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layer_norm.weight                                ├─1,024\n",
      "│    └─layer_norm.bias                                  └─1,024\n",
      "│    └─Embedding: 2-1                                   (recursive)\n",
      "│    │    └─weight                                      └─131,186,688\n",
      "│    └─M2M100SinusoidalPositionalEmbedding: 2-2         --\n",
      "│    └─ModuleList: 2-3                                  --\n",
      "│    │    └─0.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─0.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─0.fc1.weight                                ├─4,194,304\n",
      "│    │    └─0.fc1.bias                                  ├─4,096\n",
      "│    │    └─0.fc2.weight                                ├─4,194,304\n",
      "│    │    └─0.fc2.bias                                  ├─1,024\n",
      "│    │    └─0.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─0.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─1.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─1.fc1.weight                                ├─4,194,304\n",
      "│    │    └─1.fc1.bias                                  ├─4,096\n",
      "│    │    └─1.fc2.weight                                ├─4,194,304\n",
      "│    │    └─1.fc2.bias                                  ├─1,024\n",
      "│    │    └─1.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─1.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─2.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─2.fc1.weight                                ├─4,194,304\n",
      "│    │    └─2.fc1.bias                                  ├─4,096\n",
      "│    │    └─2.fc2.weight                                ├─4,194,304\n",
      "│    │    └─2.fc2.bias                                  ├─1,024\n",
      "│    │    └─2.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─2.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─3.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─3.fc1.weight                                ├─4,194,304\n",
      "│    │    └─3.fc1.bias                                  ├─4,096\n",
      "│    │    └─3.fc2.weight                                ├─4,194,304\n",
      "│    │    └─3.fc2.bias                                  ├─1,024\n",
      "│    │    └─3.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─3.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─4.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─4.fc1.weight                                ├─4,194,304\n",
      "│    │    └─4.fc1.bias                                  ├─4,096\n",
      "│    │    └─4.fc2.weight                                ├─4,194,304\n",
      "│    │    └─4.fc2.bias                                  ├─1,024\n",
      "│    │    └─4.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─4.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─5.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─5.fc1.weight                                ├─4,194,304\n",
      "│    │    └─5.fc1.bias                                  ├─4,096\n",
      "│    │    └─5.fc2.weight                                ├─4,194,304\n",
      "│    │    └─5.fc2.bias                                  ├─1,024\n",
      "│    │    └─5.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─5.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─6.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─6.fc1.weight                                ├─4,194,304\n",
      "│    │    └─6.fc1.bias                                  ├─4,096\n",
      "│    │    └─6.fc2.weight                                ├─4,194,304\n",
      "│    │    └─6.fc2.bias                                  ├─1,024\n",
      "│    │    └─6.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─6.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─7.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─7.fc1.weight                                ├─4,194,304\n",
      "│    │    └─7.fc1.bias                                  ├─4,096\n",
      "│    │    └─7.fc2.weight                                ├─4,194,304\n",
      "│    │    └─7.fc2.bias                                  ├─1,024\n",
      "│    │    └─7.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─7.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─8.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─8.fc1.weight                                ├─4,194,304\n",
      "│    │    └─8.fc1.bias                                  ├─4,096\n",
      "│    │    └─8.fc2.weight                                ├─4,194,304\n",
      "│    │    └─8.fc2.bias                                  ├─1,024\n",
      "│    │    └─8.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─8.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─9.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─9.fc1.weight                                ├─4,194,304\n",
      "│    │    └─9.fc1.bias                                  ├─4,096\n",
      "│    │    └─9.fc2.weight                                ├─4,194,304\n",
      "│    │    └─9.fc2.bias                                  ├─1,024\n",
      "│    │    └─9.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─9.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─10.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─10.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─10.fc1.weight                               ├─4,194,304\n",
      "│    │    └─10.fc1.bias                                 ├─4,096\n",
      "│    │    └─10.fc2.weight                               ├─4,194,304\n",
      "│    │    └─10.fc2.bias                                 ├─1,024\n",
      "│    │    └─10.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─10.final_layer_norm.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─11.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─11.fc1.weight                               ├─4,194,304\n",
      "│    │    └─11.fc1.bias                                 ├─4,096\n",
      "│    │    └─11.fc2.weight                               ├─4,194,304\n",
      "│    │    └─11.fc2.bias                                 ├─1,024\n",
      "│    │    └─11.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─11.final_layer_norm.bias                    └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-1                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-2                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-3                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-4                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-5                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-6                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-7                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-8                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-9                     12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-10                    12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-11                    12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100EncoderLayer: 3-12                    12,596,224\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    └─LayerNorm: 2-4                                   2,048\n",
      "│    │    └─weight                                      ├─1,024\n",
      "│    │    └─bias                                        └─1,024\n",
      "├─M2M100Decoder: 1-3                                    131,186,688\n",
      "│    └─embed_tokens.weight                              ├─131,186,688\n",
      "│    └─layers.0.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.0.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.0.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.0.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.0.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.0.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.0.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.0.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.0.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.0.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.0.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.0.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.0.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc1.bias                                ├─4,096\n",
      "│    └─layers.0.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.0.fc2.bias                                ├─1,024\n",
      "│    └─layers.0.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.0.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.1.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.1.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.1.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.1.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.1.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.1.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.1.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.1.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.1.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.1.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.1.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.1.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc1.bias                                ├─4,096\n",
      "│    └─layers.1.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.1.fc2.bias                                ├─1,024\n",
      "│    └─layers.1.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.1.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.2.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.2.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.2.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.2.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.2.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.2.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.2.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.2.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.2.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.2.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.2.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.2.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc1.bias                                ├─4,096\n",
      "│    └─layers.2.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.2.fc2.bias                                ├─1,024\n",
      "│    └─layers.2.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.2.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.3.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.3.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.3.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.3.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.3.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.3.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.3.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.3.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.3.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.3.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.3.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.3.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc1.bias                                ├─4,096\n",
      "│    └─layers.3.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.3.fc2.bias                                ├─1,024\n",
      "│    └─layers.3.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.3.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.4.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.4.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.4.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.4.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.4.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.4.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.4.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.4.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.4.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.4.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.4.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.4.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc1.bias                                ├─4,096\n",
      "│    └─layers.4.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.4.fc2.bias                                ├─1,024\n",
      "│    └─layers.4.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.4.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.5.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.5.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.5.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.5.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.5.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.5.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.5.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.5.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.5.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.5.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.5.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.5.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc1.bias                                ├─4,096\n",
      "│    └─layers.5.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.5.fc2.bias                                ├─1,024\n",
      "│    └─layers.5.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.5.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.6.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.6.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.6.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.6.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.6.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.6.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.6.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.6.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.6.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.6.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.6.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.6.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc1.bias                                ├─4,096\n",
      "│    └─layers.6.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.6.fc2.bias                                ├─1,024\n",
      "│    └─layers.6.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.6.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.7.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.7.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.7.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.7.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.7.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.7.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.7.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.7.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.7.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.7.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.7.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.7.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc1.bias                                ├─4,096\n",
      "│    └─layers.7.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.7.fc2.bias                                ├─1,024\n",
      "│    └─layers.7.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.7.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.8.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.8.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.8.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.8.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.8.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.8.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.8.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.8.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.8.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.8.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.8.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.8.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc1.bias                                ├─4,096\n",
      "│    └─layers.8.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.8.fc2.bias                                ├─1,024\n",
      "│    └─layers.8.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.8.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.k_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.k_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.v_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.v_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.q_proj.weight                 ├─1,048,576\n",
      "│    └─layers.9.self_attn.q_proj.bias                   ├─1,024\n",
      "│    └─layers.9.self_attn.out_proj.weight               ├─1,048,576\n",
      "│    └─layers.9.self_attn.out_proj.bias                 ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.weight             ├─1,024\n",
      "│    └─layers.9.self_attn_layer_norm.bias               ├─1,024\n",
      "│    └─layers.9.encoder_attn.k_proj.weight              ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.k_proj.bias                ├─1,024\n",
      "│    └─layers.9.encoder_attn.v_proj.weight              ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.v_proj.bias                ├─1,024\n",
      "│    └─layers.9.encoder_attn.q_proj.weight              ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.q_proj.bias                ├─1,024\n",
      "│    └─layers.9.encoder_attn.out_proj.weight            ├─1,048,576\n",
      "│    └─layers.9.encoder_attn.out_proj.bias              ├─1,024\n",
      "│    └─layers.9.encoder_attn_layer_norm.weight          ├─1,024\n",
      "│    └─layers.9.encoder_attn_layer_norm.bias            ├─1,024\n",
      "│    └─layers.9.fc1.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc1.bias                                ├─4,096\n",
      "│    └─layers.9.fc2.weight                              ├─4,194,304\n",
      "│    └─layers.9.fc2.bias                                ├─1,024\n",
      "│    └─layers.9.final_layer_norm.weight                 ├─1,024\n",
      "│    └─layers.9.final_layer_norm.bias                   ├─1,024\n",
      "│    └─layers.10.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.10.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.10.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.10.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.10.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.10.encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.k_proj.bias               ├─1,024\n",
      "│    └─layers.10.encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.v_proj.bias               ├─1,024\n",
      "│    └─layers.10.encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.q_proj.bias               ├─1,024\n",
      "│    └─layers.10.encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    └─layers.10.encoder_attn.out_proj.bias             ├─1,024\n",
      "│    └─layers.10.encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    └─layers.10.encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    └─layers.10.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc1.bias                               ├─4,096\n",
      "│    └─layers.10.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.10.fc2.bias                               ├─1,024\n",
      "│    └─layers.10.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.10.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.k_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.k_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.v_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.v_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.q_proj.weight                ├─1,048,576\n",
      "│    └─layers.11.self_attn.q_proj.bias                  ├─1,024\n",
      "│    └─layers.11.self_attn.out_proj.weight              ├─1,048,576\n",
      "│    └─layers.11.self_attn.out_proj.bias                ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.weight            ├─1,024\n",
      "│    └─layers.11.self_attn_layer_norm.bias              ├─1,024\n",
      "│    └─layers.11.encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.k_proj.bias               ├─1,024\n",
      "│    └─layers.11.encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.v_proj.bias               ├─1,024\n",
      "│    └─layers.11.encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.q_proj.bias               ├─1,024\n",
      "│    └─layers.11.encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    └─layers.11.encoder_attn.out_proj.bias             ├─1,024\n",
      "│    └─layers.11.encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    └─layers.11.encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    └─layers.11.fc1.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc1.bias                               ├─4,096\n",
      "│    └─layers.11.fc2.weight                             ├─4,194,304\n",
      "│    └─layers.11.fc2.bias                               ├─1,024\n",
      "│    └─layers.11.final_layer_norm.weight                ├─1,024\n",
      "│    └─layers.11.final_layer_norm.bias                  ├─1,024\n",
      "│    └─layer_norm.weight                                ├─1,024\n",
      "│    └─layer_norm.bias                                  └─1,024\n",
      "│    └─Embedding: 2-5                                   (recursive)\n",
      "│    │    └─weight                                      └─131,186,688\n",
      "│    └─M2M100SinusoidalPositionalEmbedding: 2-6         --\n",
      "│    └─ModuleList: 2-7                                  --\n",
      "│    │    └─0.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─0.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─0.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─0.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─0.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─0.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─0.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─0.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─0.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─0.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─0.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─0.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─0.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─0.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─0.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─0.fc1.weight                                ├─4,194,304\n",
      "│    │    └─0.fc1.bias                                  ├─4,096\n",
      "│    │    └─0.fc2.weight                                ├─4,194,304\n",
      "│    │    └─0.fc2.bias                                  ├─1,024\n",
      "│    │    └─0.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─0.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─1.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─1.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─1.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─1.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─1.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─1.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─1.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─1.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─1.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─1.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─1.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─1.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─1.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─1.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─1.fc1.weight                                ├─4,194,304\n",
      "│    │    └─1.fc1.bias                                  ├─4,096\n",
      "│    │    └─1.fc2.weight                                ├─4,194,304\n",
      "│    │    └─1.fc2.bias                                  ├─1,024\n",
      "│    │    └─1.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─1.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─2.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─2.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─2.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─2.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─2.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─2.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─2.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─2.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─2.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─2.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─2.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─2.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─2.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─2.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─2.fc1.weight                                ├─4,194,304\n",
      "│    │    └─2.fc1.bias                                  ├─4,096\n",
      "│    │    └─2.fc2.weight                                ├─4,194,304\n",
      "│    │    └─2.fc2.bias                                  ├─1,024\n",
      "│    │    └─2.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─2.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─3.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─3.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─3.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─3.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─3.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─3.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─3.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─3.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─3.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─3.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─3.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─3.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─3.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─3.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─3.fc1.weight                                ├─4,194,304\n",
      "│    │    └─3.fc1.bias                                  ├─4,096\n",
      "│    │    └─3.fc2.weight                                ├─4,194,304\n",
      "│    │    └─3.fc2.bias                                  ├─1,024\n",
      "│    │    └─3.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─3.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─4.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─4.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─4.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─4.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─4.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─4.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─4.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─4.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─4.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─4.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─4.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─4.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─4.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─4.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─4.fc1.weight                                ├─4,194,304\n",
      "│    │    └─4.fc1.bias                                  ├─4,096\n",
      "│    │    └─4.fc2.weight                                ├─4,194,304\n",
      "│    │    └─4.fc2.bias                                  ├─1,024\n",
      "│    │    └─4.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─4.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─5.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─5.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─5.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─5.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─5.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─5.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─5.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─5.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─5.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─5.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─5.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─5.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─5.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─5.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─5.fc1.weight                                ├─4,194,304\n",
      "│    │    └─5.fc1.bias                                  ├─4,096\n",
      "│    │    └─5.fc2.weight                                ├─4,194,304\n",
      "│    │    └─5.fc2.bias                                  ├─1,024\n",
      "│    │    └─5.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─5.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─6.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─6.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─6.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─6.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─6.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─6.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─6.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─6.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─6.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─6.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─6.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─6.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─6.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─6.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─6.fc1.weight                                ├─4,194,304\n",
      "│    │    └─6.fc1.bias                                  ├─4,096\n",
      "│    │    └─6.fc2.weight                                ├─4,194,304\n",
      "│    │    └─6.fc2.bias                                  ├─1,024\n",
      "│    │    └─6.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─6.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─7.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─7.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─7.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─7.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─7.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─7.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─7.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─7.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─7.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─7.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─7.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─7.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─7.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─7.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─7.fc1.weight                                ├─4,194,304\n",
      "│    │    └─7.fc1.bias                                  ├─4,096\n",
      "│    │    └─7.fc2.weight                                ├─4,194,304\n",
      "│    │    └─7.fc2.bias                                  ├─1,024\n",
      "│    │    └─7.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─7.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─8.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─8.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─8.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─8.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─8.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─8.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─8.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─8.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─8.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─8.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─8.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─8.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─8.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─8.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─8.fc1.weight                                ├─4,194,304\n",
      "│    │    └─8.fc1.bias                                  ├─4,096\n",
      "│    │    └─8.fc2.weight                                ├─4,194,304\n",
      "│    │    └─8.fc2.bias                                  ├─1,024\n",
      "│    │    └─8.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─8.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.k_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.k_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.v_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.v_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.q_proj.weight                   ├─1,048,576\n",
      "│    │    └─9.self_attn.q_proj.bias                     ├─1,024\n",
      "│    │    └─9.self_attn.out_proj.weight                 ├─1,048,576\n",
      "│    │    └─9.self_attn.out_proj.bias                   ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.weight               ├─1,024\n",
      "│    │    └─9.self_attn_layer_norm.bias                 ├─1,024\n",
      "│    │    └─9.encoder_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    └─9.encoder_attn.k_proj.bias                  ├─1,024\n",
      "│    │    └─9.encoder_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    └─9.encoder_attn.v_proj.bias                  ├─1,024\n",
      "│    │    └─9.encoder_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    └─9.encoder_attn.q_proj.bias                  ├─1,024\n",
      "│    │    └─9.encoder_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    └─9.encoder_attn.out_proj.bias                ├─1,024\n",
      "│    │    └─9.encoder_attn_layer_norm.weight            ├─1,024\n",
      "│    │    └─9.encoder_attn_layer_norm.bias              ├─1,024\n",
      "│    │    └─9.fc1.weight                                ├─4,194,304\n",
      "│    │    └─9.fc1.bias                                  ├─4,096\n",
      "│    │    └─9.fc2.weight                                ├─4,194,304\n",
      "│    │    └─9.fc2.bias                                  ├─1,024\n",
      "│    │    └─9.final_layer_norm.weight                   ├─1,024\n",
      "│    │    └─9.final_layer_norm.bias                     ├─1,024\n",
      "│    │    └─10.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─10.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─10.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─10.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─10.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─10.encoder_attn.k_proj.weight               ├─1,048,576\n",
      "│    │    └─10.encoder_attn.k_proj.bias                 ├─1,024\n",
      "│    │    └─10.encoder_attn.v_proj.weight               ├─1,048,576\n",
      "│    │    └─10.encoder_attn.v_proj.bias                 ├─1,024\n",
      "│    │    └─10.encoder_attn.q_proj.weight               ├─1,048,576\n",
      "│    │    └─10.encoder_attn.q_proj.bias                 ├─1,024\n",
      "│    │    └─10.encoder_attn.out_proj.weight             ├─1,048,576\n",
      "│    │    └─10.encoder_attn.out_proj.bias               ├─1,024\n",
      "│    │    └─10.encoder_attn_layer_norm.weight           ├─1,024\n",
      "│    │    └─10.encoder_attn_layer_norm.bias             ├─1,024\n",
      "│    │    └─10.fc1.weight                               ├─4,194,304\n",
      "│    │    └─10.fc1.bias                                 ├─4,096\n",
      "│    │    └─10.fc2.weight                               ├─4,194,304\n",
      "│    │    └─10.fc2.bias                                 ├─1,024\n",
      "│    │    └─10.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─10.final_layer_norm.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.k_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.k_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.v_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.v_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.q_proj.weight                  ├─1,048,576\n",
      "│    │    └─11.self_attn.q_proj.bias                    ├─1,024\n",
      "│    │    └─11.self_attn.out_proj.weight                ├─1,048,576\n",
      "│    │    └─11.self_attn.out_proj.bias                  ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.weight              ├─1,024\n",
      "│    │    └─11.self_attn_layer_norm.bias                ├─1,024\n",
      "│    │    └─11.encoder_attn.k_proj.weight               ├─1,048,576\n",
      "│    │    └─11.encoder_attn.k_proj.bias                 ├─1,024\n",
      "│    │    └─11.encoder_attn.v_proj.weight               ├─1,048,576\n",
      "│    │    └─11.encoder_attn.v_proj.bias                 ├─1,024\n",
      "│    │    └─11.encoder_attn.q_proj.weight               ├─1,048,576\n",
      "│    │    └─11.encoder_attn.q_proj.bias                 ├─1,024\n",
      "│    │    └─11.encoder_attn.out_proj.weight             ├─1,048,576\n",
      "│    │    └─11.encoder_attn.out_proj.bias               ├─1,024\n",
      "│    │    └─11.encoder_attn_layer_norm.weight           ├─1,024\n",
      "│    │    └─11.encoder_attn_layer_norm.bias             ├─1,024\n",
      "│    │    └─11.fc1.weight                               ├─4,194,304\n",
      "│    │    └─11.fc1.bias                                 ├─4,096\n",
      "│    │    └─11.fc2.weight                               ├─4,194,304\n",
      "│    │    └─11.fc2.bias                                 ├─1,024\n",
      "│    │    └─11.final_layer_norm.weight                  ├─1,024\n",
      "│    │    └─11.final_layer_norm.bias                    └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-13                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-14                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-15                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-16                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-17                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-18                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-19                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-20                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-21                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-22                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-23                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    │    └─M2M100DecoderLayer: 3-24                    16,796,672\n",
      "│    │    │    └─self_attn.k_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.k_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.v_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.v_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.q_proj.weight                ├─1,048,576\n",
      "│    │    │    └─self_attn.q_proj.bias                  ├─1,024\n",
      "│    │    │    └─self_attn.out_proj.weight              ├─1,048,576\n",
      "│    │    │    └─self_attn.out_proj.bias                ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.weight            ├─1,024\n",
      "│    │    │    └─self_attn_layer_norm.bias              ├─1,024\n",
      "│    │    │    └─encoder_attn.k_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.k_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.v_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.v_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.q_proj.weight             ├─1,048,576\n",
      "│    │    │    └─encoder_attn.q_proj.bias               ├─1,024\n",
      "│    │    │    └─encoder_attn.out_proj.weight           ├─1,048,576\n",
      "│    │    │    └─encoder_attn.out_proj.bias             ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.weight         ├─1,024\n",
      "│    │    │    └─encoder_attn_layer_norm.bias           ├─1,024\n",
      "│    │    │    └─fc1.weight                             ├─4,194,304\n",
      "│    │    │    └─fc1.bias                               ├─4,096\n",
      "│    │    │    └─fc2.weight                             ├─4,194,304\n",
      "│    │    │    └─fc2.bias                               ├─1,024\n",
      "│    │    │    └─final_layer_norm.weight                ├─1,024\n",
      "│    │    │    └─final_layer_norm.bias                  └─1,024\n",
      "│    └─LayerNorm: 2-8                                   2,048\n",
      "│    │    └─weight                                      ├─1,024\n",
      "│    │    └─bias                                        └─1,024\n",
      "================================================================================\n",
      "Total params: 483,905,536\n",
      "Trainable params: 483,905,536\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100Model\n",
    "\n",
    "m2m100_model = M2M100Model.from_pretrained(\"facebook/m2m100_418M\")\n",
    "print_summary(m2m100_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85b9c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c8c0b8fb1042c6b91947d9103f0c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b8a7f581d1465ba91337fc3b035528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2Model(\n",
      "  (embeddings): DebertaV2Embeddings(\n",
      "    (word_embeddings): Embedding(128100, 1536, padding_idx=0)\n",
      "    (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (encoder): DebertaV2Encoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (1): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (2): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (3): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (4): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (5): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (6): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (7): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (8): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (9): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (10): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (11): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (12): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (13): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (14): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (15): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (16): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (17): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (18): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (19): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (20): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (21): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (22): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "      (23): DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rel_embeddings): Embedding(512, 1536)\n",
      "    (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "    (conv): ConvLayer(\n",
      "      (conv): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "DebertaV2Model                                               --\n",
      "├─DebertaV2Embeddings: 1-1                                   --\n",
      "│    └─word_embeddings.weight                                ├─196,761,600\n",
      "│    └─LayerNorm.weight                                      ├─1,536\n",
      "│    └─LayerNorm.bias                                        └─1,536\n",
      "│    └─Embedding: 2-1                                        196,761,600\n",
      "│    │    └─weight                                           └─196,761,600\n",
      "│    └─LayerNorm: 2-2                                        3,072\n",
      "│    │    └─weight                                           ├─1,536\n",
      "│    │    └─bias                                             └─1,536\n",
      "│    └─StableDropout: 2-3                                    --\n",
      "├─DebertaV2Encoder: 1-2                                      --\n",
      "│    └─layer.0.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.0.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.0.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.0.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.0.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.0.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.0.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.0.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.0.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.0.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.0.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.0.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.0.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.0.output.dense.bias                             ├─1,536\n",
      "│    └─layer.0.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.0.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.1.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.1.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.1.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.1.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.1.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.1.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.1.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.1.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.1.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.1.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.1.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.1.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.1.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.1.output.dense.bias                             ├─1,536\n",
      "│    └─layer.1.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.1.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.2.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.2.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.2.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.2.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.2.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.2.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.2.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.2.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.2.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.2.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.2.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.2.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.2.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.2.output.dense.bias                             ├─1,536\n",
      "│    └─layer.2.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.2.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.3.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.3.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.3.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.3.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.3.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.3.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.3.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.3.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.3.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.3.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.3.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.3.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.3.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.3.output.dense.bias                             ├─1,536\n",
      "│    └─layer.3.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.3.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.4.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.4.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.4.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.4.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.4.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.4.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.4.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.4.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.4.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.4.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.4.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.4.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.4.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.4.output.dense.bias                             ├─1,536\n",
      "│    └─layer.4.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.4.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.5.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.5.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.5.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.5.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.5.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.5.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.5.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.5.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.5.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.5.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.5.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.5.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.5.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.5.output.dense.bias                             ├─1,536\n",
      "│    └─layer.5.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.5.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.6.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.6.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.6.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.6.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.6.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.6.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.6.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.6.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.6.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.6.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.6.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.6.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.6.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.6.output.dense.bias                             ├─1,536\n",
      "│    └─layer.6.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.6.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.7.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.7.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.7.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.7.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.7.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.7.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.7.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.7.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.7.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.7.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.7.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.7.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.7.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.7.output.dense.bias                             ├─1,536\n",
      "│    └─layer.7.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.7.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.8.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.8.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.8.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.8.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.8.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.8.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.8.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.8.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.8.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.8.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.8.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.8.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.8.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.8.output.dense.bias                             ├─1,536\n",
      "│    └─layer.8.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.8.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.9.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.9.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.9.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.9.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.9.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.9.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.9.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.9.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.9.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.9.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.9.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.9.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.9.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.9.output.dense.bias                             ├─1,536\n",
      "│    └─layer.9.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.9.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.10.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.10.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.10.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.10.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.10.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.10.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.10.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.10.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.10.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.10.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.10.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.10.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.10.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.10.output.dense.bias                            ├─1,536\n",
      "│    └─layer.10.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.10.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.11.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.11.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.11.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.11.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.11.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.11.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.11.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.11.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.11.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.11.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.11.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.11.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.11.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.11.output.dense.bias                            ├─1,536\n",
      "│    └─layer.11.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.11.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.12.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.12.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.12.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.12.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.12.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.12.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.12.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.12.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.12.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.12.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.12.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.12.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.12.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.12.output.dense.bias                            ├─1,536\n",
      "│    └─layer.12.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.12.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.13.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.13.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.13.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.13.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.13.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.13.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.13.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.13.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.13.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.13.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.13.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.13.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.13.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.13.output.dense.bias                            ├─1,536\n",
      "│    └─layer.13.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.13.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.14.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.14.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.14.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.14.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.14.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.14.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.14.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.14.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.14.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.14.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.14.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.14.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.14.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.14.output.dense.bias                            ├─1,536\n",
      "│    └─layer.14.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.14.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.15.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.15.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.15.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.15.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.15.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.15.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.15.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.15.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.15.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.15.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.15.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.15.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.15.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.15.output.dense.bias                            ├─1,536\n",
      "│    └─layer.15.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.15.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.16.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.16.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.16.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.16.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.16.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.16.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.16.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.16.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.16.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.16.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.16.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.16.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.16.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.16.output.dense.bias                            ├─1,536\n",
      "│    └─layer.16.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.16.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.17.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.17.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.17.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.17.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.17.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.17.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.17.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.17.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.17.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.17.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.17.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.17.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.17.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.17.output.dense.bias                            ├─1,536\n",
      "│    └─layer.17.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.17.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.18.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.18.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.18.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.18.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.18.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.18.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.18.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.18.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.18.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.18.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.18.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.18.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.18.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.18.output.dense.bias                            ├─1,536\n",
      "│    └─layer.18.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.18.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.19.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.19.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.19.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.19.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.19.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.19.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.19.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.19.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.19.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.19.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.19.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.19.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.19.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.19.output.dense.bias                            ├─1,536\n",
      "│    └─layer.19.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.19.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.20.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.20.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.20.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.20.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.20.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.20.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.20.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.20.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.20.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.20.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.20.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.20.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.20.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.20.output.dense.bias                            ├─1,536\n",
      "│    └─layer.20.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.20.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.21.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.21.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.21.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.21.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.21.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.21.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.21.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.21.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.21.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.21.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.21.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.21.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.21.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.21.output.dense.bias                            ├─1,536\n",
      "│    └─layer.21.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.21.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.22.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.22.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.22.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.22.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.22.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.22.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.22.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.22.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.22.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.22.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.22.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.22.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.22.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.22.output.dense.bias                            ├─1,536\n",
      "│    └─layer.22.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.22.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.23.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.23.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.23.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.23.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.23.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.23.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.23.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.23.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.23.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.23.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.23.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.23.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.23.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.23.output.dense.bias                            ├─1,536\n",
      "│    └─layer.23.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.23.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─rel_embeddings.weight                                 ├─786,432\n",
      "│    └─LayerNorm.weight                                      ├─1,536\n",
      "│    └─LayerNorm.bias                                        ├─1,536\n",
      "│    └─conv.conv.weight                                      ├─7,077,888\n",
      "│    └─conv.conv.bias                                        ├─1,536\n",
      "│    └─conv.LayerNorm.weight                                 ├─1,536\n",
      "│    └─conv.LayerNorm.bias                                   └─1,536\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─0.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─0.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─0.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─0.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─0.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─0.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─0.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─0.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─0.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─0.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─0.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─0.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─0.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─0.output.dense.bias                              ├─1,536\n",
      "│    │    └─0.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─0.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─1.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─1.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─1.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─1.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─1.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─1.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─1.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─1.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─1.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─1.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─1.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─1.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─1.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─1.output.dense.bias                              ├─1,536\n",
      "│    │    └─1.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─1.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─2.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─2.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─2.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─2.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─2.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─2.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─2.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─2.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─2.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─2.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─2.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─2.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─2.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─2.output.dense.bias                              ├─1,536\n",
      "│    │    └─2.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─2.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─3.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─3.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─3.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─3.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─3.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─3.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─3.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─3.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─3.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─3.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─3.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─3.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─3.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─3.output.dense.bias                              ├─1,536\n",
      "│    │    └─3.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─3.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─4.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─4.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─4.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─4.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─4.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─4.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─4.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─4.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─4.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─4.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─4.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─4.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─4.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─4.output.dense.bias                              ├─1,536\n",
      "│    │    └─4.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─4.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─5.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─5.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─5.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─5.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─5.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─5.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─5.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─5.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─5.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─5.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─5.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─5.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─5.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─5.output.dense.bias                              ├─1,536\n",
      "│    │    └─5.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─5.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─6.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─6.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─6.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─6.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─6.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─6.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─6.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─6.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─6.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─6.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─6.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─6.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─6.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─6.output.dense.bias                              ├─1,536\n",
      "│    │    └─6.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─6.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─7.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─7.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─7.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─7.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─7.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─7.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─7.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─7.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─7.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─7.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─7.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─7.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─7.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─7.output.dense.bias                              ├─1,536\n",
      "│    │    └─7.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─7.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─8.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─8.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─8.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─8.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─8.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─8.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─8.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─8.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─8.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─8.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─8.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─8.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─8.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─8.output.dense.bias                              ├─1,536\n",
      "│    │    └─8.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─8.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─9.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─9.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─9.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─9.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─9.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─9.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─9.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─9.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─9.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─9.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─9.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─9.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─9.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─9.output.dense.bias                              ├─1,536\n",
      "│    │    └─9.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─9.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─10.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─10.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─10.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─10.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─10.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─10.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─10.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─10.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─10.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─10.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─10.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─10.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─10.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─10.output.dense.bias                             ├─1,536\n",
      "│    │    └─10.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─10.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─11.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─11.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─11.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─11.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─11.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─11.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─11.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─11.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─11.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─11.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─11.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─11.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─11.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─11.output.dense.bias                             ├─1,536\n",
      "│    │    └─11.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─11.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─12.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─12.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─12.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─12.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─12.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─12.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─12.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─12.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─12.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─12.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─12.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─12.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─12.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─12.output.dense.bias                             ├─1,536\n",
      "│    │    └─12.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─12.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─13.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─13.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─13.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─13.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─13.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─13.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─13.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─13.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─13.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─13.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─13.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─13.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─13.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─13.output.dense.bias                             ├─1,536\n",
      "│    │    └─13.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─13.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─14.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─14.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─14.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─14.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─14.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─14.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─14.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─14.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─14.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─14.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─14.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─14.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─14.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─14.output.dense.bias                             ├─1,536\n",
      "│    │    └─14.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─14.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─15.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─15.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─15.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─15.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─15.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─15.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─15.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─15.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─15.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─15.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─15.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─15.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─15.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─15.output.dense.bias                             ├─1,536\n",
      "│    │    └─15.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─15.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─16.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─16.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─16.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─16.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─16.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─16.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─16.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─16.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─16.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─16.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─16.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─16.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─16.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─16.output.dense.bias                             ├─1,536\n",
      "│    │    └─16.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─16.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─17.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─17.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─17.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─17.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─17.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─17.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─17.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─17.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─17.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─17.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─17.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─17.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─17.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─17.output.dense.bias                             ├─1,536\n",
      "│    │    └─17.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─17.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─18.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─18.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─18.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─18.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─18.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─18.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─18.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─18.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─18.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─18.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─18.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─18.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─18.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─18.output.dense.bias                             ├─1,536\n",
      "│    │    └─18.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─18.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─19.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─19.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─19.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─19.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─19.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─19.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─19.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─19.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─19.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─19.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─19.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─19.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─19.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─19.output.dense.bias                             ├─1,536\n",
      "│    │    └─19.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─19.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─20.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─20.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─20.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─20.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─20.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─20.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─20.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─20.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─20.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─20.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─20.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─20.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─20.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─20.output.dense.bias                             ├─1,536\n",
      "│    │    └─20.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─20.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─21.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─21.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─21.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─21.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─21.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─21.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─21.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─21.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─21.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─21.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─21.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─21.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─21.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─21.output.dense.bias                             ├─1,536\n",
      "│    │    └─21.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─21.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─22.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─22.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─22.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─22.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─22.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─22.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─22.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─22.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─22.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─22.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─22.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─22.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─22.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─22.output.dense.bias                             ├─1,536\n",
      "│    │    └─22.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─22.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─23.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─23.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─23.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─23.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─23.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─23.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─23.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─23.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─23.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─23.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─23.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─23.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─23.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─23.output.dense.bias                             ├─1,536\n",
      "│    │    └─23.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─23.output.LayerNorm.bias                         └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-1                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-2                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-3                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-4                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-5                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-6                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-7                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-8                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-9                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-10                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-11                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-12                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-13                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-14                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-15                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-16                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-17                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-18                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-19                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-20                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-21                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-22                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-23                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-24                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    └─Embedding: 2-5                                        786,432\n",
      "│    │    └─weight                                           └─786,432\n",
      "│    └─LayerNorm: 2-6                                        3,072\n",
      "│    │    └─weight                                           ├─1,536\n",
      "│    │    └─bias                                             └─1,536\n",
      "│    └─ConvLayer: 2-7                                        --\n",
      "│    │    └─conv.weight                                      ├─7,077,888\n",
      "│    │    └─conv.bias                                        ├─1,536\n",
      "│    │    └─LayerNorm.weight                                 ├─1,536\n",
      "│    │    └─LayerNorm.bias                                   └─1,536\n",
      "│    │    └─Conv1d: 3-25                                     7,079,424\n",
      "│    │    │    └─weight                                      ├─7,077,888\n",
      "│    │    │    └─bias                                        └─1,536\n",
      "│    │    └─LayerNorm: 3-26                                  3,072\n",
      "│    │    │    └─weight                                      ├─1,536\n",
      "│    │    │    └─bias                                        └─1,536\n",
      "│    │    └─StableDropout: 3-27                              --\n",
      "=====================================================================================\n",
      "Total params: 884,593,152\n",
      "Trainable params: 884,593,152\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "DebertaV2Model                                               --\n",
      "├─DebertaV2Embeddings: 1-1                                   --\n",
      "│    └─word_embeddings.weight                                ├─196,761,600\n",
      "│    └─LayerNorm.weight                                      ├─1,536\n",
      "│    └─LayerNorm.bias                                        └─1,536\n",
      "│    └─Embedding: 2-1                                        196,761,600\n",
      "│    │    └─weight                                           └─196,761,600\n",
      "│    └─LayerNorm: 2-2                                        3,072\n",
      "│    │    └─weight                                           ├─1,536\n",
      "│    │    └─bias                                             └─1,536\n",
      "│    └─StableDropout: 2-3                                    --\n",
      "├─DebertaV2Encoder: 1-2                                      --\n",
      "│    └─layer.0.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.0.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.0.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.0.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.0.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.0.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.0.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.0.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.0.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.0.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.0.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.0.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.0.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.0.output.dense.bias                             ├─1,536\n",
      "│    └─layer.0.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.0.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.1.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.1.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.1.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.1.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.1.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.1.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.1.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.1.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.1.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.1.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.1.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.1.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.1.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.1.output.dense.bias                             ├─1,536\n",
      "│    └─layer.1.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.1.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.2.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.2.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.2.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.2.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.2.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.2.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.2.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.2.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.2.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.2.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.2.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.2.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.2.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.2.output.dense.bias                             ├─1,536\n",
      "│    └─layer.2.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.2.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.3.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.3.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.3.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.3.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.3.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.3.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.3.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.3.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.3.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.3.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.3.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.3.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.3.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.3.output.dense.bias                             ├─1,536\n",
      "│    └─layer.3.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.3.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.4.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.4.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.4.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.4.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.4.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.4.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.4.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.4.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.4.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.4.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.4.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.4.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.4.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.4.output.dense.bias                             ├─1,536\n",
      "│    └─layer.4.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.4.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.5.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.5.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.5.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.5.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.5.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.5.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.5.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.5.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.5.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.5.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.5.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.5.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.5.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.5.output.dense.bias                             ├─1,536\n",
      "│    └─layer.5.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.5.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.6.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.6.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.6.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.6.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.6.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.6.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.6.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.6.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.6.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.6.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.6.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.6.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.6.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.6.output.dense.bias                             ├─1,536\n",
      "│    └─layer.6.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.6.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.7.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.7.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.7.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.7.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.7.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.7.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.7.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.7.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.7.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.7.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.7.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.7.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.7.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.7.output.dense.bias                             ├─1,536\n",
      "│    └─layer.7.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.7.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.8.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.8.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.8.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.8.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.8.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.8.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.8.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.8.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.8.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.8.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.8.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.8.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.8.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.8.output.dense.bias                             ├─1,536\n",
      "│    └─layer.8.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.8.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.9.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    └─layer.9.attention.self.query_proj.bias                ├─1,536\n",
      "│    └─layer.9.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    └─layer.9.attention.self.key_proj.bias                  ├─1,536\n",
      "│    └─layer.9.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    └─layer.9.attention.self.value_proj.bias                ├─1,536\n",
      "│    └─layer.9.attention.output.dense.weight                 ├─2,359,296\n",
      "│    └─layer.9.attention.output.dense.bias                   ├─1,536\n",
      "│    └─layer.9.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    └─layer.9.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    └─layer.9.intermediate.dense.weight                     ├─9,437,184\n",
      "│    └─layer.9.intermediate.dense.bias                       ├─6,144\n",
      "│    └─layer.9.output.dense.weight                           ├─9,437,184\n",
      "│    └─layer.9.output.dense.bias                             ├─1,536\n",
      "│    └─layer.9.output.LayerNorm.weight                       ├─1,536\n",
      "│    └─layer.9.output.LayerNorm.bias                         ├─1,536\n",
      "│    └─layer.10.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.10.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.10.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.10.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.10.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.10.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.10.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.10.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.10.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.10.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.10.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.10.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.10.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.10.output.dense.bias                            ├─1,536\n",
      "│    └─layer.10.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.10.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.11.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.11.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.11.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.11.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.11.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.11.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.11.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.11.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.11.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.11.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.11.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.11.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.11.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.11.output.dense.bias                            ├─1,536\n",
      "│    └─layer.11.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.11.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.12.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.12.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.12.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.12.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.12.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.12.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.12.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.12.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.12.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.12.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.12.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.12.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.12.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.12.output.dense.bias                            ├─1,536\n",
      "│    └─layer.12.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.12.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.13.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.13.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.13.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.13.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.13.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.13.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.13.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.13.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.13.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.13.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.13.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.13.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.13.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.13.output.dense.bias                            ├─1,536\n",
      "│    └─layer.13.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.13.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.14.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.14.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.14.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.14.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.14.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.14.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.14.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.14.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.14.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.14.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.14.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.14.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.14.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.14.output.dense.bias                            ├─1,536\n",
      "│    └─layer.14.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.14.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.15.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.15.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.15.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.15.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.15.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.15.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.15.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.15.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.15.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.15.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.15.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.15.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.15.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.15.output.dense.bias                            ├─1,536\n",
      "│    └─layer.15.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.15.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.16.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.16.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.16.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.16.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.16.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.16.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.16.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.16.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.16.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.16.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.16.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.16.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.16.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.16.output.dense.bias                            ├─1,536\n",
      "│    └─layer.16.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.16.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.17.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.17.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.17.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.17.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.17.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.17.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.17.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.17.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.17.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.17.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.17.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.17.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.17.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.17.output.dense.bias                            ├─1,536\n",
      "│    └─layer.17.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.17.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.18.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.18.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.18.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.18.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.18.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.18.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.18.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.18.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.18.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.18.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.18.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.18.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.18.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.18.output.dense.bias                            ├─1,536\n",
      "│    └─layer.18.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.18.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.19.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.19.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.19.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.19.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.19.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.19.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.19.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.19.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.19.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.19.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.19.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.19.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.19.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.19.output.dense.bias                            ├─1,536\n",
      "│    └─layer.19.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.19.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.20.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.20.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.20.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.20.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.20.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.20.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.20.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.20.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.20.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.20.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.20.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.20.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.20.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.20.output.dense.bias                            ├─1,536\n",
      "│    └─layer.20.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.20.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.21.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.21.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.21.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.21.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.21.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.21.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.21.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.21.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.21.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.21.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.21.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.21.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.21.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.21.output.dense.bias                            ├─1,536\n",
      "│    └─layer.21.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.21.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.22.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.22.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.22.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.22.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.22.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.22.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.22.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.22.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.22.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.22.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.22.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.22.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.22.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.22.output.dense.bias                            ├─1,536\n",
      "│    └─layer.22.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.22.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─layer.23.attention.self.query_proj.weight             ├─2,359,296\n",
      "│    └─layer.23.attention.self.query_proj.bias               ├─1,536\n",
      "│    └─layer.23.attention.self.key_proj.weight               ├─2,359,296\n",
      "│    └─layer.23.attention.self.key_proj.bias                 ├─1,536\n",
      "│    └─layer.23.attention.self.value_proj.weight             ├─2,359,296\n",
      "│    └─layer.23.attention.self.value_proj.bias               ├─1,536\n",
      "│    └─layer.23.attention.output.dense.weight                ├─2,359,296\n",
      "│    └─layer.23.attention.output.dense.bias                  ├─1,536\n",
      "│    └─layer.23.attention.output.LayerNorm.weight            ├─1,536\n",
      "│    └─layer.23.attention.output.LayerNorm.bias              ├─1,536\n",
      "│    └─layer.23.intermediate.dense.weight                    ├─9,437,184\n",
      "│    └─layer.23.intermediate.dense.bias                      ├─6,144\n",
      "│    └─layer.23.output.dense.weight                          ├─9,437,184\n",
      "│    └─layer.23.output.dense.bias                            ├─1,536\n",
      "│    └─layer.23.output.LayerNorm.weight                      ├─1,536\n",
      "│    └─layer.23.output.LayerNorm.bias                        ├─1,536\n",
      "│    └─rel_embeddings.weight                                 ├─786,432\n",
      "│    └─LayerNorm.weight                                      ├─1,536\n",
      "│    └─LayerNorm.bias                                        ├─1,536\n",
      "│    └─conv.conv.weight                                      ├─7,077,888\n",
      "│    └─conv.conv.bias                                        ├─1,536\n",
      "│    └─conv.LayerNorm.weight                                 ├─1,536\n",
      "│    └─conv.LayerNorm.bias                                   └─1,536\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─0.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─0.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─0.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─0.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─0.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─0.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─0.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─0.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─0.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─0.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─0.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─0.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─0.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─0.output.dense.bias                              ├─1,536\n",
      "│    │    └─0.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─0.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─1.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─1.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─1.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─1.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─1.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─1.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─1.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─1.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─1.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─1.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─1.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─1.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─1.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─1.output.dense.bias                              ├─1,536\n",
      "│    │    └─1.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─1.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─2.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─2.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─2.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─2.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─2.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─2.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─2.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─2.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─2.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─2.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─2.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─2.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─2.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─2.output.dense.bias                              ├─1,536\n",
      "│    │    └─2.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─2.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─3.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─3.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─3.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─3.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─3.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─3.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─3.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─3.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─3.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─3.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─3.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─3.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─3.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─3.output.dense.bias                              ├─1,536\n",
      "│    │    └─3.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─3.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─4.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─4.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─4.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─4.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─4.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─4.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─4.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─4.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─4.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─4.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─4.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─4.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─4.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─4.output.dense.bias                              ├─1,536\n",
      "│    │    └─4.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─4.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─5.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─5.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─5.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─5.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─5.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─5.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─5.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─5.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─5.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─5.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─5.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─5.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─5.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─5.output.dense.bias                              ├─1,536\n",
      "│    │    └─5.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─5.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─6.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─6.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─6.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─6.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─6.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─6.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─6.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─6.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─6.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─6.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─6.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─6.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─6.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─6.output.dense.bias                              ├─1,536\n",
      "│    │    └─6.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─6.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─7.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─7.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─7.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─7.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─7.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─7.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─7.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─7.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─7.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─7.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─7.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─7.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─7.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─7.output.dense.bias                              ├─1,536\n",
      "│    │    └─7.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─7.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─8.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─8.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─8.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─8.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─8.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─8.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─8.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─8.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─8.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─8.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─8.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─8.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─8.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─8.output.dense.bias                              ├─1,536\n",
      "│    │    └─8.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─8.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─9.attention.self.query_proj.weight               ├─2,359,296\n",
      "│    │    └─9.attention.self.query_proj.bias                 ├─1,536\n",
      "│    │    └─9.attention.self.key_proj.weight                 ├─2,359,296\n",
      "│    │    └─9.attention.self.key_proj.bias                   ├─1,536\n",
      "│    │    └─9.attention.self.value_proj.weight               ├─2,359,296\n",
      "│    │    └─9.attention.self.value_proj.bias                 ├─1,536\n",
      "│    │    └─9.attention.output.dense.weight                  ├─2,359,296\n",
      "│    │    └─9.attention.output.dense.bias                    ├─1,536\n",
      "│    │    └─9.attention.output.LayerNorm.weight              ├─1,536\n",
      "│    │    └─9.attention.output.LayerNorm.bias                ├─1,536\n",
      "│    │    └─9.intermediate.dense.weight                      ├─9,437,184\n",
      "│    │    └─9.intermediate.dense.bias                        ├─6,144\n",
      "│    │    └─9.output.dense.weight                            ├─9,437,184\n",
      "│    │    └─9.output.dense.bias                              ├─1,536\n",
      "│    │    └─9.output.LayerNorm.weight                        ├─1,536\n",
      "│    │    └─9.output.LayerNorm.bias                          ├─1,536\n",
      "│    │    └─10.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─10.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─10.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─10.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─10.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─10.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─10.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─10.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─10.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─10.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─10.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─10.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─10.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─10.output.dense.bias                             ├─1,536\n",
      "│    │    └─10.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─10.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─11.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─11.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─11.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─11.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─11.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─11.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─11.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─11.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─11.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─11.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─11.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─11.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─11.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─11.output.dense.bias                             ├─1,536\n",
      "│    │    └─11.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─11.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─12.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─12.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─12.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─12.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─12.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─12.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─12.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─12.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─12.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─12.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─12.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─12.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─12.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─12.output.dense.bias                             ├─1,536\n",
      "│    │    └─12.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─12.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─13.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─13.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─13.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─13.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─13.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─13.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─13.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─13.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─13.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─13.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─13.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─13.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─13.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─13.output.dense.bias                             ├─1,536\n",
      "│    │    └─13.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─13.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─14.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─14.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─14.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─14.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─14.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─14.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─14.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─14.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─14.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─14.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─14.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─14.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─14.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─14.output.dense.bias                             ├─1,536\n",
      "│    │    └─14.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─14.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─15.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─15.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─15.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─15.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─15.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─15.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─15.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─15.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─15.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─15.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─15.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─15.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─15.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─15.output.dense.bias                             ├─1,536\n",
      "│    │    └─15.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─15.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─16.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─16.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─16.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─16.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─16.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─16.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─16.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─16.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─16.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─16.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─16.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─16.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─16.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─16.output.dense.bias                             ├─1,536\n",
      "│    │    └─16.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─16.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─17.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─17.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─17.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─17.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─17.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─17.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─17.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─17.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─17.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─17.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─17.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─17.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─17.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─17.output.dense.bias                             ├─1,536\n",
      "│    │    └─17.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─17.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─18.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─18.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─18.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─18.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─18.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─18.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─18.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─18.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─18.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─18.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─18.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─18.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─18.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─18.output.dense.bias                             ├─1,536\n",
      "│    │    └─18.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─18.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─19.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─19.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─19.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─19.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─19.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─19.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─19.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─19.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─19.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─19.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─19.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─19.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─19.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─19.output.dense.bias                             ├─1,536\n",
      "│    │    └─19.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─19.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─20.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─20.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─20.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─20.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─20.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─20.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─20.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─20.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─20.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─20.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─20.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─20.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─20.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─20.output.dense.bias                             ├─1,536\n",
      "│    │    └─20.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─20.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─21.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─21.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─21.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─21.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─21.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─21.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─21.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─21.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─21.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─21.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─21.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─21.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─21.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─21.output.dense.bias                             ├─1,536\n",
      "│    │    └─21.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─21.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─22.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─22.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─22.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─22.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─22.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─22.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─22.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─22.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─22.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─22.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─22.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─22.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─22.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─22.output.dense.bias                             ├─1,536\n",
      "│    │    └─22.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─22.output.LayerNorm.bias                         ├─1,536\n",
      "│    │    └─23.attention.self.query_proj.weight              ├─2,359,296\n",
      "│    │    └─23.attention.self.query_proj.bias                ├─1,536\n",
      "│    │    └─23.attention.self.key_proj.weight                ├─2,359,296\n",
      "│    │    └─23.attention.self.key_proj.bias                  ├─1,536\n",
      "│    │    └─23.attention.self.value_proj.weight              ├─2,359,296\n",
      "│    │    └─23.attention.self.value_proj.bias                ├─1,536\n",
      "│    │    └─23.attention.output.dense.weight                 ├─2,359,296\n",
      "│    │    └─23.attention.output.dense.bias                   ├─1,536\n",
      "│    │    └─23.attention.output.LayerNorm.weight             ├─1,536\n",
      "│    │    └─23.attention.output.LayerNorm.bias               ├─1,536\n",
      "│    │    └─23.intermediate.dense.weight                     ├─9,437,184\n",
      "│    │    └─23.intermediate.dense.bias                       ├─6,144\n",
      "│    │    └─23.output.dense.weight                           ├─9,437,184\n",
      "│    │    └─23.output.dense.bias                             ├─1,536\n",
      "│    │    └─23.output.LayerNorm.weight                       ├─1,536\n",
      "│    │    └─23.output.LayerNorm.bias                         └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-1                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-2                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-3                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-4                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-5                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-6                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-7                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-8                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-9                              28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-10                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-11                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-12                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-13                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-14                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-15                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-16                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-17                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-18                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-19                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-20                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-21                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-22                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-23                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    │    └─DebertaV2Layer: 3-24                             28,331,520\n",
      "│    │    │    └─attention.self.query_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.query_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.self.key_proj.weight              ├─2,359,296\n",
      "│    │    │    └─attention.self.key_proj.bias                ├─1,536\n",
      "│    │    │    └─attention.self.value_proj.weight            ├─2,359,296\n",
      "│    │    │    └─attention.self.value_proj.bias              ├─1,536\n",
      "│    │    │    └─attention.output.dense.weight               ├─2,359,296\n",
      "│    │    │    └─attention.output.dense.bias                 ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.weight           ├─1,536\n",
      "│    │    │    └─attention.output.LayerNorm.bias             ├─1,536\n",
      "│    │    │    └─intermediate.dense.weight                   ├─9,437,184\n",
      "│    │    │    └─intermediate.dense.bias                     ├─6,144\n",
      "│    │    │    └─output.dense.weight                         ├─9,437,184\n",
      "│    │    │    └─output.dense.bias                           ├─1,536\n",
      "│    │    │    └─output.LayerNorm.weight                     ├─1,536\n",
      "│    │    │    └─output.LayerNorm.bias                       └─1,536\n",
      "│    └─Embedding: 2-5                                        786,432\n",
      "│    │    └─weight                                           └─786,432\n",
      "│    └─LayerNorm: 2-6                                        3,072\n",
      "│    │    └─weight                                           ├─1,536\n",
      "│    │    └─bias                                             └─1,536\n",
      "│    └─ConvLayer: 2-7                                        --\n",
      "│    │    └─conv.weight                                      ├─7,077,888\n",
      "│    │    └─conv.bias                                        ├─1,536\n",
      "│    │    └─LayerNorm.weight                                 ├─1,536\n",
      "│    │    └─LayerNorm.bias                                   └─1,536\n",
      "│    │    └─Conv1d: 3-25                                     7,079,424\n",
      "│    │    │    └─weight                                      ├─7,077,888\n",
      "│    │    │    └─bias                                        └─1,536\n",
      "│    │    └─LayerNorm: 3-26                                  3,072\n",
      "│    │    │    └─weight                                      ├─1,536\n",
      "│    │    │    └─bias                                        └─1,536\n",
      "│    │    └─StableDropout: 3-27                              --\n",
      "=====================================================================================\n",
      "Total params: 884,593,152\n",
      "Trainable params: 884,593,152\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaV2Model\n",
    "\n",
    "deberta_model = DebertaV2Model.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
    "print_summary(deberta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d849cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14acb35270cc485bb9b0fa8562f49bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/3.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeaeee654ca4cd4ab7db82a114ea5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at studio-ousia/luke-large-finetuned-tacred were not used when initializing LukeForEntityPairClassification: ['luke.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LukeForEntityPairClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeForEntityPairClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LukeForEntityPairClassification(\n",
      "  (luke): LukeModel(\n",
      "    (embeddings): LukeEmbeddings(\n",
      "      (word_embeddings): Embedding(50267, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (entity_embeddings): LukeEntityEmbeddings(\n",
      "      (entity_embeddings): Embedding(500000, 256, padding_idx=0)\n",
      "      (entity_embedding_dense): Linear(in_features=256, out_features=1024, bias=False)\n",
      "      (position_embeddings): Embedding(514, 1024)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): LukeEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (18): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (19): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (20): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (21): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (22): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (23): LukeLayer(\n",
      "          (attention): LukeAttention(\n",
      "            (self): LukeSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LukeSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LukeIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LukeOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): LukePooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=2048, out_features=42, bias=False)\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "LukeForEntityPairClassification                         --\n",
      "├─LukeModel: 1-1                                        --\n",
      "│    └─embeddings.word_embeddings.weight                ├─51,473,408\n",
      "│    └─embeddings.position_embeddings.weight            ├─526,336\n",
      "│    └─embeddings.token_type_embeddings.weight          ├─1,024\n",
      "│    └─embeddings.LayerNorm.weight                      ├─1,024\n",
      "│    └─embeddings.LayerNorm.bias                        ├─1,024\n",
      "│    └─entity_embeddings.entity_embeddings.weight       ├─128,000,000\n",
      "│    └─entity_embeddings.entity_embedding_dense.weight  ├─262,144\n",
      "│    └─entity_embeddings.position_embeddings.weight     ├─526,336\n",
      "│    └─entity_embeddings.token_type_embeddings.weight   ├─1,024\n",
      "│    └─entity_embeddings.LayerNorm.weight               ├─1,024\n",
      "│    └─entity_embeddings.LayerNorm.bias                 ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.0.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.0.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.0.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.0.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.0.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.0.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.0.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.0.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.0.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.1.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.1.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.1.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.1.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.1.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.1.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.1.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.1.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.1.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.2.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.2.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.2.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.2.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.2.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.2.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.2.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.2.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.2.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.3.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.3.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.3.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.3.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.3.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.3.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.3.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.3.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.3.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.4.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.4.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.4.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.4.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.4.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.4.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.4.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.4.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.4.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.5.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.5.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.5.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.5.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.5.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.5.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.5.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.5.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.5.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.6.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.6.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.6.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.6.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.6.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.6.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.6.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.6.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.6.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.7.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.7.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.7.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.7.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.7.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.7.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.7.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.7.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.7.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.8.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.8.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.8.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.8.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.8.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.8.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.8.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.8.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.8.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.9.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.9.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.9.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.9.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.9.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.9.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.9.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.9.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.9.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.10.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.10.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.10.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.10.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.10.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.10.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.10.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.10.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.10.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.11.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.11.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.11.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.11.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.11.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.11.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.11.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.11.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.11.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.12.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.12.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.12.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.12.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.12.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.12.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.12.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.12.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.12.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.13.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.13.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.13.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.13.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.13.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.13.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.13.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.13.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.13.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.14.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.14.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.14.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.14.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.14.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.14.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.14.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.14.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.14.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.15.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.15.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.15.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.15.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.15.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.15.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.15.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.15.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.15.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.16.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.16.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.16.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.16.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.16.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.16.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.16.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.16.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.16.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.17.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.17.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.17.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.17.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.17.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.17.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.17.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.17.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.17.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.18.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.18.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.18.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.18.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.18.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.18.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.18.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.18.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.18.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.19.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.19.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.19.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.19.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.19.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.19.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.19.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.19.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.19.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.20.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.20.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.20.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.20.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.20.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.20.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.20.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.20.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.20.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.21.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.21.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.21.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.21.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.21.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.21.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.21.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.21.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.21.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.22.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.22.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.22.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.22.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.22.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.22.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.22.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.22.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.22.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.23.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.23.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.23.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.23.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.23.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.23.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.23.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.23.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.23.output.LayerNorm.bias           ├─1,024\n",
      "│    └─pooler.dense.weight                              ├─1,048,576\n",
      "│    └─pooler.dense.bias                                └─1,024\n",
      "│    └─LukeEmbeddings: 2-1                              --\n",
      "│    │    └─word_embeddings.weight                      ├─51,473,408\n",
      "│    │    └─position_embeddings.weight                  ├─526,336\n",
      "│    │    └─token_type_embeddings.weight                ├─1,024\n",
      "│    │    └─LayerNorm.weight                            ├─1,024\n",
      "│    │    └─LayerNorm.bias                              └─1,024\n",
      "│    │    └─Embedding: 3-1                              51,473,408\n",
      "│    │    │    └─weight                                 └─51,473,408\n",
      "│    │    └─Embedding: 3-2                              526,336\n",
      "│    │    │    └─weight                                 └─526,336\n",
      "│    │    └─Embedding: 3-3                              1,024\n",
      "│    │    │    └─weight                                 └─1,024\n",
      "│    │    └─LayerNorm: 3-4                              2,048\n",
      "│    │    │    └─weight                                 ├─1,024\n",
      "│    │    │    └─bias                                   └─1,024\n",
      "│    │    └─Dropout: 3-5                                --\n",
      "│    └─LukeEntityEmbeddings: 2-2                        --\n",
      "│    │    └─entity_embeddings.weight                    ├─128,000,000\n",
      "│    │    └─entity_embedding_dense.weight               ├─262,144\n",
      "│    │    └─position_embeddings.weight                  ├─526,336\n",
      "│    │    └─token_type_embeddings.weight                ├─1,024\n",
      "│    │    └─LayerNorm.weight                            ├─1,024\n",
      "│    │    └─LayerNorm.bias                              └─1,024\n",
      "│    │    └─Embedding: 3-6                              128,000,000\n",
      "│    │    │    └─weight                                 └─128,000,000\n",
      "│    │    └─Linear: 3-7                                 262,144\n",
      "│    │    │    └─weight                                 └─262,144\n",
      "│    │    └─Embedding: 3-8                              526,336\n",
      "│    │    │    └─weight                                 └─526,336\n",
      "│    │    └─Embedding: 3-9                              1,024\n",
      "│    │    │    └─weight                                 └─1,024\n",
      "│    │    └─LayerNorm: 3-10                             2,048\n",
      "│    │    │    └─weight                                 ├─1,024\n",
      "│    │    │    └─bias                                   └─1,024\n",
      "│    │    └─Dropout: 3-11                               --\n",
      "│    └─LukeEncoder: 2-3                                 --\n",
      "│    │    └─layer.0.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.0.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.0.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.0.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.0.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.0.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.0.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.0.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.0.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.0.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.0.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.0.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.0.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.0.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.0.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.0.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.1.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.1.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.1.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.1.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.1.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.1.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.1.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.1.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.1.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.1.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.1.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.1.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.1.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.1.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.1.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.1.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.2.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.2.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.2.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.2.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.2.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.2.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.2.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.2.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.2.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.2.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.2.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.2.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.2.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.2.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.2.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.2.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.3.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.3.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.3.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.3.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.3.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.3.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.3.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.3.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.3.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.3.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.3.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.3.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.3.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.3.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.3.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.3.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.4.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.4.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.4.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.4.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.4.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.4.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.4.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.4.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.4.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.4.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.4.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.4.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.4.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.4.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.4.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.4.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.5.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.5.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.5.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.5.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.5.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.5.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.5.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.5.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.5.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.5.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.5.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.5.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.5.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.5.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.5.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.5.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.6.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.6.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.6.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.6.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.6.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.6.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.6.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.6.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.6.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.6.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.6.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.6.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.6.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.6.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.6.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.6.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.7.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.7.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.7.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.7.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.7.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.7.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.7.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.7.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.7.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.7.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.7.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.7.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.7.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.7.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.7.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.7.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.8.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.8.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.8.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.8.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.8.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.8.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.8.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.8.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.8.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.8.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.8.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.8.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.8.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.8.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.8.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.8.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.9.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.9.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.9.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.9.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.9.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.9.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.9.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.9.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.9.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.9.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.9.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.9.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.9.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.9.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.9.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.9.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.10.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.10.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.10.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.10.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.10.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.10.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.10.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.10.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.10.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.10.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.10.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.10.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.10.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.10.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.10.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.10.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.11.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.11.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.11.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.11.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.11.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.11.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.11.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.11.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.11.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.11.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.11.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.11.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.11.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.11.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.11.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.11.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.12.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.12.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.12.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.12.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.12.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.12.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.12.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.12.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.12.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.12.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.12.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.12.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.12.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.12.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.12.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.12.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.13.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.13.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.13.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.13.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.13.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.13.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.13.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.13.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.13.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.13.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.13.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.13.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.13.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.13.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.13.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.13.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.14.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.14.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.14.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.14.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.14.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.14.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.14.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.14.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.14.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.14.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.14.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.14.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.14.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.14.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.14.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.14.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.15.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.15.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.15.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.15.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.15.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.15.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.15.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.15.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.15.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.15.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.15.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.15.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.15.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.15.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.15.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.15.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.16.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.16.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.16.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.16.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.16.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.16.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.16.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.16.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.16.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.16.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.16.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.16.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.16.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.16.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.16.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.16.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.17.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.17.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.17.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.17.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.17.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.17.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.17.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.17.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.17.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.17.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.17.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.17.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.17.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.17.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.17.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.17.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.18.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.18.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.18.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.18.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.18.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.18.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.18.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.18.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.18.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.18.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.18.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.18.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.18.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.18.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.18.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.18.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.19.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.19.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.19.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.19.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.19.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.19.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.19.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.19.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.19.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.19.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.19.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.19.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.19.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.19.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.19.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.19.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.20.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.20.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.20.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.20.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.20.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.20.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.20.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.20.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.20.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.20.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.20.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.20.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.20.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.20.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.20.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.20.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.21.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.21.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.21.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.21.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.21.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.21.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.21.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.21.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.21.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.21.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.21.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.21.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.21.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.21.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.21.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.21.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.22.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.22.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.22.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.22.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.22.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.22.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.22.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.22.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.22.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.22.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.22.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.22.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.22.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.22.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.22.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.22.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.23.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.23.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.23.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.23.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.23.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.23.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.23.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.23.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.23.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.23.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.23.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.23.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.23.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.23.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.23.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.23.output.LayerNorm.bias              └─1,024\n",
      "│    │    └─ModuleList: 3-12                            377,880,576\n",
      "│    │    │    └─0.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─0.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─0.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─0.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─0.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─0.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─0.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─0.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─0.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─0.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─0.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─0.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─0.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─0.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─0.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─0.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─0.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─0.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─0.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─0.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─0.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─0.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─1.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─1.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─1.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─1.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─1.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─1.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─1.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─1.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─1.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─1.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─1.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─1.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─1.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─1.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─1.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─1.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─1.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─1.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─1.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─1.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─1.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─1.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─2.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─2.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─2.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─2.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─2.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─2.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─2.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─2.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─2.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─2.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─2.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─2.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─2.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─2.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─2.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─2.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─2.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─2.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─2.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─2.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─2.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─2.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─3.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─3.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─3.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─3.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─3.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─3.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─3.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─3.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─3.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─3.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─3.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─3.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─3.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─3.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─3.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─3.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─3.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─3.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─3.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─3.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─3.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─3.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─4.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─4.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─4.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─4.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─4.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─4.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─4.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─4.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─4.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─4.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─4.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─4.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─4.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─4.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─4.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─4.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─4.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─4.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─4.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─4.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─4.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─4.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─5.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─5.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─5.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─5.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─5.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─5.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─5.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─5.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─5.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─5.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─5.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─5.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─5.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─5.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─5.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─5.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─5.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─5.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─5.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─5.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─5.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─5.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─6.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─6.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─6.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─6.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─6.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─6.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─6.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─6.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─6.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─6.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─6.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─6.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─6.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─6.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─6.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─6.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─6.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─6.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─6.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─6.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─6.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─6.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─7.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─7.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─7.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─7.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─7.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─7.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─7.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─7.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─7.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─7.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─7.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─7.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─7.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─7.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─7.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─7.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─7.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─7.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─7.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─7.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─7.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─7.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─8.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─8.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─8.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─8.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─8.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─8.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─8.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─8.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─8.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─8.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─8.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─8.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─8.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─8.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─8.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─8.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─8.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─8.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─8.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─8.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─8.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─8.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─9.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─9.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─9.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─9.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─9.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─9.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─9.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─9.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─9.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─9.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─9.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─9.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─9.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─9.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─9.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─9.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─9.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─9.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─9.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─9.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─9.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─9.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─10.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─10.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─10.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─10.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─10.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─10.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─10.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─10.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─10.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─10.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─10.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─10.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─10.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─10.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─10.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─10.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─10.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─10.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─10.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─10.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─10.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─10.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─11.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─11.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─11.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─11.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─11.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─11.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─11.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─11.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─11.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─11.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─11.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─11.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─11.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─11.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─11.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─11.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─11.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─11.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─11.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─11.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─11.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─11.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─12.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─12.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─12.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─12.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─12.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─12.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─12.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─12.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─12.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─12.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─12.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─12.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─12.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─12.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─12.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─12.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─12.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─12.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─12.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─12.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─12.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─12.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─13.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─13.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─13.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─13.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─13.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─13.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─13.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─13.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─13.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─13.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─13.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─13.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─13.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─13.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─13.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─13.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─13.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─13.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─13.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─13.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─13.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─13.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─14.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─14.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─14.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─14.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─14.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─14.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─14.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─14.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─14.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─14.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─14.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─14.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─14.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─14.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─14.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─14.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─14.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─14.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─14.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─14.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─14.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─14.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─15.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─15.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─15.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─15.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─15.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─15.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─15.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─15.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─15.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─15.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─15.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─15.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─15.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─15.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─15.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─15.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─15.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─15.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─15.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─15.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─15.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─15.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─16.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─16.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─16.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─16.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─16.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─16.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─16.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─16.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─16.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─16.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─16.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─16.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─16.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─16.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─16.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─16.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─16.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─16.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─16.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─16.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─16.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─16.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─17.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─17.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─17.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─17.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─17.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─17.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─17.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─17.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─17.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─17.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─17.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─17.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─17.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─17.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─17.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─17.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─17.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─17.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─17.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─17.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─17.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─17.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─18.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─18.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─18.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─18.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─18.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─18.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─18.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─18.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─18.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─18.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─18.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─18.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─18.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─18.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─18.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─18.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─18.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─18.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─18.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─18.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─18.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─18.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─19.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─19.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─19.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─19.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─19.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─19.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─19.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─19.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─19.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─19.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─19.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─19.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─19.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─19.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─19.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─19.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─19.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─19.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─19.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─19.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─19.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─19.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─20.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─20.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─20.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─20.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─20.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─20.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─20.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─20.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─20.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─20.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─20.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─20.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─20.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─20.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─20.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─20.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─20.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─20.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─20.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─20.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─20.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─20.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─21.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─21.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─21.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─21.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─21.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─21.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─21.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─21.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─21.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─21.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─21.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─21.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─21.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─21.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─21.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─21.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─21.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─21.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─21.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─21.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─21.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─21.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─22.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─22.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─22.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─22.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─22.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─22.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─22.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─22.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─22.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─22.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─22.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─22.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─22.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─22.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─22.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─22.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─22.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─22.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─22.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─22.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─22.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─22.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─23.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─23.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─23.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─23.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─23.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─23.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─23.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─23.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─23.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─23.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─23.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─23.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─23.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─23.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─23.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─23.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─23.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─23.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─23.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─23.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─23.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─23.output.LayerNorm.bias               └─1,024\n",
      "│    └─LukePooler: 2-4                                  --\n",
      "│    │    └─dense.weight                                ├─1,048,576\n",
      "│    │    └─dense.bias                                  └─1,024\n",
      "│    │    └─Linear: 3-13                                1,049,600\n",
      "│    │    │    └─weight                                 ├─1,048,576\n",
      "│    │    │    └─bias                                   └─1,024\n",
      "│    │    └─Tanh: 3-14                                  --\n",
      "├─Dropout: 1-2                                          --\n",
      "├─Linear: 1-3                                           86,016\n",
      "│    └─weight                                           └─86,016\n",
      "================================================================================\n",
      "Total params: 559,810,560\n",
      "Trainable params: 559,810,560\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "LukeForEntityPairClassification                         --\n",
      "├─LukeModel: 1-1                                        --\n",
      "│    └─embeddings.word_embeddings.weight                ├─51,473,408\n",
      "│    └─embeddings.position_embeddings.weight            ├─526,336\n",
      "│    └─embeddings.token_type_embeddings.weight          ├─1,024\n",
      "│    └─embeddings.LayerNorm.weight                      ├─1,024\n",
      "│    └─embeddings.LayerNorm.bias                        ├─1,024\n",
      "│    └─entity_embeddings.entity_embeddings.weight       ├─128,000,000\n",
      "│    └─entity_embeddings.entity_embedding_dense.weight  ├─262,144\n",
      "│    └─entity_embeddings.position_embeddings.weight     ├─526,336\n",
      "│    └─entity_embeddings.token_type_embeddings.weight   ├─1,024\n",
      "│    └─entity_embeddings.LayerNorm.weight               ├─1,024\n",
      "│    └─entity_embeddings.LayerNorm.bias                 ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.0.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.0.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.0.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.0.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.0.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.0.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.0.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.0.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.0.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.0.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.0.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.1.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.1.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.1.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.1.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.1.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.1.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.1.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.1.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.1.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.1.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.1.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.2.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.2.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.2.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.2.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.2.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.2.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.2.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.2.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.2.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.2.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.2.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.3.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.3.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.3.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.3.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.3.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.3.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.3.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.3.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.3.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.3.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.3.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.4.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.4.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.4.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.4.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.4.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.4.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.4.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.4.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.4.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.4.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.4.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.5.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.5.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.5.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.5.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.5.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.5.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.5.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.5.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.5.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.5.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.5.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.6.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.6.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.6.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.6.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.6.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.6.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.6.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.6.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.6.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.6.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.6.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.7.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.7.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.7.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.7.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.7.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.7.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.7.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.7.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.7.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.7.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.7.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.8.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.8.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.8.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.8.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.8.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.8.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.8.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.8.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.8.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.8.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.8.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.query.weight      ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.query.bias        ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.key.weight        ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.key.bias          ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.value.weight      ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.value.bias        ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.w2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.w2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.e2w_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.e2w_query.bias    ├─1,024\n",
      "│    └─encoder.layer.9.attention.self.e2e_query.weight  ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.self.e2e_query.bias    ├─1,024\n",
      "│    └─encoder.layer.9.attention.output.dense.weight    ├─1,048,576\n",
      "│    └─encoder.layer.9.attention.output.dense.bias      ├─1,024\n",
      "│    └─encoder.layer.9.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.9.attention.output.LayerNorm.bias  ├─1,024\n",
      "│    └─encoder.layer.9.intermediate.dense.weight        ├─4,194,304\n",
      "│    └─encoder.layer.9.intermediate.dense.bias          ├─4,096\n",
      "│    └─encoder.layer.9.output.dense.weight              ├─4,194,304\n",
      "│    └─encoder.layer.9.output.dense.bias                ├─1,024\n",
      "│    └─encoder.layer.9.output.LayerNorm.weight          ├─1,024\n",
      "│    └─encoder.layer.9.output.LayerNorm.bias            ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.10.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.10.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.10.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.10.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.10.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.10.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.10.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.10.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.10.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.10.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.10.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.11.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.11.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.11.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.11.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.11.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.11.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.11.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.11.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.11.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.11.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.11.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.12.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.12.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.12.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.12.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.12.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.12.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.12.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.12.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.12.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.12.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.12.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.13.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.13.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.13.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.13.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.13.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.13.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.13.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.13.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.13.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.13.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.13.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.14.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.14.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.14.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.14.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.14.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.14.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.14.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.14.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.14.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.14.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.14.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.15.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.15.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.15.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.15.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.15.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.15.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.15.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.15.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.15.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.15.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.15.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.16.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.16.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.16.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.16.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.16.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.16.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.16.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.16.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.16.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.16.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.16.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.17.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.17.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.17.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.17.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.17.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.17.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.17.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.17.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.17.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.17.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.17.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.18.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.18.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.18.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.18.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.18.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.18.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.18.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.18.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.18.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.18.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.18.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.19.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.19.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.19.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.19.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.19.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.19.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.19.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.19.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.19.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.19.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.19.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.20.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.20.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.20.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.20.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.20.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.20.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.20.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.20.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.20.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.20.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.20.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.21.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.21.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.21.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.21.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.21.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.21.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.21.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.21.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.21.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.21.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.21.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.22.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.22.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.22.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.22.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.22.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.22.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.22.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.22.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.22.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.22.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.22.output.LayerNorm.bias           ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.query.weight     ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.query.bias       ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.key.weight       ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.key.bias         ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.value.weight     ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.value.bias       ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.w2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.w2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.e2w_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.e2w_query.bias   ├─1,024\n",
      "│    └─encoder.layer.23.attention.self.e2e_query.weight ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.self.e2e_query.bias   ├─1,024\n",
      "│    └─encoder.layer.23.attention.output.dense.weight   ├─1,048,576\n",
      "│    └─encoder.layer.23.attention.output.dense.bias     ├─1,024\n",
      "│    └─encoder.layer.23.attention.output.LayerNorm.weight ├─1,024\n",
      "│    └─encoder.layer.23.attention.output.LayerNorm.bias ├─1,024\n",
      "│    └─encoder.layer.23.intermediate.dense.weight       ├─4,194,304\n",
      "│    └─encoder.layer.23.intermediate.dense.bias         ├─4,096\n",
      "│    └─encoder.layer.23.output.dense.weight             ├─4,194,304\n",
      "│    └─encoder.layer.23.output.dense.bias               ├─1,024\n",
      "│    └─encoder.layer.23.output.LayerNorm.weight         ├─1,024\n",
      "│    └─encoder.layer.23.output.LayerNorm.bias           ├─1,024\n",
      "│    └─pooler.dense.weight                              ├─1,048,576\n",
      "│    └─pooler.dense.bias                                └─1,024\n",
      "│    └─LukeEmbeddings: 2-1                              --\n",
      "│    │    └─word_embeddings.weight                      ├─51,473,408\n",
      "│    │    └─position_embeddings.weight                  ├─526,336\n",
      "│    │    └─token_type_embeddings.weight                ├─1,024\n",
      "│    │    └─LayerNorm.weight                            ├─1,024\n",
      "│    │    └─LayerNorm.bias                              └─1,024\n",
      "│    │    └─Embedding: 3-1                              51,473,408\n",
      "│    │    │    └─weight                                 └─51,473,408\n",
      "│    │    └─Embedding: 3-2                              526,336\n",
      "│    │    │    └─weight                                 └─526,336\n",
      "│    │    └─Embedding: 3-3                              1,024\n",
      "│    │    │    └─weight                                 └─1,024\n",
      "│    │    └─LayerNorm: 3-4                              2,048\n",
      "│    │    │    └─weight                                 ├─1,024\n",
      "│    │    │    └─bias                                   └─1,024\n",
      "│    │    └─Dropout: 3-5                                --\n",
      "│    └─LukeEntityEmbeddings: 2-2                        --\n",
      "│    │    └─entity_embeddings.weight                    ├─128,000,000\n",
      "│    │    └─entity_embedding_dense.weight               ├─262,144\n",
      "│    │    └─position_embeddings.weight                  ├─526,336\n",
      "│    │    └─token_type_embeddings.weight                ├─1,024\n",
      "│    │    └─LayerNorm.weight                            ├─1,024\n",
      "│    │    └─LayerNorm.bias                              └─1,024\n",
      "│    │    └─Embedding: 3-6                              128,000,000\n",
      "│    │    │    └─weight                                 └─128,000,000\n",
      "│    │    └─Linear: 3-7                                 262,144\n",
      "│    │    │    └─weight                                 └─262,144\n",
      "│    │    └─Embedding: 3-8                              526,336\n",
      "│    │    │    └─weight                                 └─526,336\n",
      "│    │    └─Embedding: 3-9                              1,024\n",
      "│    │    │    └─weight                                 └─1,024\n",
      "│    │    └─LayerNorm: 3-10                             2,048\n",
      "│    │    │    └─weight                                 ├─1,024\n",
      "│    │    │    └─bias                                   └─1,024\n",
      "│    │    └─Dropout: 3-11                               --\n",
      "│    └─LukeEncoder: 2-3                                 --\n",
      "│    │    └─layer.0.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.0.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.0.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.0.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.0.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.0.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.0.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.0.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.0.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.0.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.0.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.0.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.0.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.0.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.0.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.0.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.0.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.1.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.1.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.1.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.1.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.1.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.1.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.1.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.1.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.1.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.1.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.1.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.1.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.1.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.1.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.1.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.1.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.1.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.2.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.2.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.2.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.2.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.2.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.2.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.2.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.2.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.2.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.2.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.2.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.2.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.2.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.2.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.2.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.2.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.2.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.3.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.3.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.3.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.3.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.3.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.3.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.3.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.3.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.3.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.3.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.3.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.3.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.3.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.3.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.3.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.3.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.3.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.4.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.4.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.4.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.4.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.4.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.4.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.4.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.4.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.4.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.4.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.4.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.4.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.4.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.4.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.4.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.4.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.4.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.5.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.5.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.5.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.5.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.5.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.5.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.5.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.5.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.5.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.5.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.5.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.5.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.5.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.5.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.5.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.5.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.5.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.6.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.6.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.6.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.6.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.6.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.6.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.6.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.6.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.6.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.6.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.6.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.6.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.6.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.6.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.6.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.6.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.6.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.7.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.7.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.7.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.7.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.7.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.7.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.7.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.7.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.7.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.7.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.7.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.7.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.7.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.7.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.7.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.7.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.7.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.8.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.8.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.8.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.8.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.8.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.8.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.8.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.8.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.8.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.8.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.8.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.8.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.8.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.8.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.8.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.8.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.8.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.9.attention.self.query.weight         ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.query.bias           ├─1,024\n",
      "│    │    └─layer.9.attention.self.key.weight           ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.key.bias             ├─1,024\n",
      "│    │    └─layer.9.attention.self.value.weight         ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.value.bias           ├─1,024\n",
      "│    │    └─layer.9.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    └─layer.9.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    └─layer.9.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    └─layer.9.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    └─layer.9.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    └─layer.9.attention.output.dense.bias         ├─1,024\n",
      "│    │    └─layer.9.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    └─layer.9.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    └─layer.9.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    └─layer.9.intermediate.dense.bias             ├─4,096\n",
      "│    │    └─layer.9.output.dense.weight                 ├─4,194,304\n",
      "│    │    └─layer.9.output.dense.bias                   ├─1,024\n",
      "│    │    └─layer.9.output.LayerNorm.weight             ├─1,024\n",
      "│    │    └─layer.9.output.LayerNorm.bias               ├─1,024\n",
      "│    │    └─layer.10.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.10.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.10.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.10.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.10.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.10.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.10.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.10.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.10.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.10.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.10.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.10.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.10.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.10.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.10.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.10.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.10.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.11.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.11.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.11.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.11.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.11.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.11.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.11.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.11.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.11.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.11.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.11.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.11.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.11.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.11.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.11.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.11.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.11.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.12.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.12.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.12.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.12.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.12.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.12.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.12.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.12.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.12.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.12.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.12.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.12.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.12.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.12.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.12.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.12.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.12.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.13.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.13.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.13.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.13.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.13.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.13.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.13.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.13.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.13.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.13.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.13.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.13.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.13.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.13.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.13.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.13.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.13.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.14.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.14.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.14.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.14.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.14.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.14.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.14.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.14.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.14.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.14.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.14.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.14.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.14.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.14.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.14.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.14.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.14.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.15.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.15.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.15.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.15.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.15.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.15.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.15.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.15.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.15.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.15.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.15.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.15.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.15.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.15.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.15.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.15.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.15.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.16.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.16.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.16.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.16.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.16.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.16.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.16.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.16.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.16.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.16.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.16.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.16.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.16.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.16.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.16.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.16.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.16.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.17.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.17.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.17.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.17.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.17.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.17.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.17.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.17.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.17.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.17.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.17.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.17.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.17.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.17.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.17.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.17.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.17.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.18.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.18.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.18.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.18.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.18.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.18.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.18.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.18.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.18.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.18.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.18.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.18.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.18.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.18.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.18.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.18.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.18.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.19.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.19.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.19.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.19.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.19.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.19.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.19.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.19.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.19.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.19.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.19.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.19.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.19.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.19.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.19.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.19.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.19.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.20.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.20.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.20.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.20.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.20.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.20.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.20.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.20.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.20.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.20.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.20.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.20.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.20.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.20.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.20.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.20.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.20.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.21.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.21.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.21.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.21.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.21.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.21.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.21.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.21.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.21.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.21.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.21.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.21.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.21.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.21.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.21.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.21.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.21.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.22.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.22.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.22.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.22.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.22.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.22.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.22.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.22.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.22.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.22.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.22.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.22.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.22.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.22.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.22.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.22.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.22.output.LayerNorm.bias              ├─1,024\n",
      "│    │    └─layer.23.attention.self.query.weight        ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.query.bias          ├─1,024\n",
      "│    │    └─layer.23.attention.self.key.weight          ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.key.bias            ├─1,024\n",
      "│    │    └─layer.23.attention.self.value.weight        ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.value.bias          ├─1,024\n",
      "│    │    └─layer.23.attention.self.w2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.w2e_query.bias      ├─1,024\n",
      "│    │    └─layer.23.attention.self.e2w_query.weight    ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.e2w_query.bias      ├─1,024\n",
      "│    │    └─layer.23.attention.self.e2e_query.weight    ├─1,048,576\n",
      "│    │    └─layer.23.attention.self.e2e_query.bias      ├─1,024\n",
      "│    │    └─layer.23.attention.output.dense.weight      ├─1,048,576\n",
      "│    │    └─layer.23.attention.output.dense.bias        ├─1,024\n",
      "│    │    └─layer.23.attention.output.LayerNorm.weight  ├─1,024\n",
      "│    │    └─layer.23.attention.output.LayerNorm.bias    ├─1,024\n",
      "│    │    └─layer.23.intermediate.dense.weight          ├─4,194,304\n",
      "│    │    └─layer.23.intermediate.dense.bias            ├─4,096\n",
      "│    │    └─layer.23.output.dense.weight                ├─4,194,304\n",
      "│    │    └─layer.23.output.dense.bias                  ├─1,024\n",
      "│    │    └─layer.23.output.LayerNorm.weight            ├─1,024\n",
      "│    │    └─layer.23.output.LayerNorm.bias              └─1,024\n",
      "│    │    └─ModuleList: 3-12                            377,880,576\n",
      "│    │    │    └─0.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─0.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─0.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─0.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─0.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─0.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─0.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─0.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─0.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─0.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─0.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─0.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─0.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─0.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─0.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─0.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─0.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─0.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─0.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─0.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─0.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─0.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─1.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─1.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─1.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─1.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─1.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─1.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─1.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─1.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─1.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─1.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─1.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─1.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─1.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─1.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─1.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─1.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─1.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─1.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─1.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─1.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─1.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─1.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─2.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─2.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─2.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─2.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─2.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─2.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─2.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─2.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─2.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─2.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─2.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─2.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─2.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─2.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─2.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─2.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─2.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─2.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─2.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─2.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─2.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─2.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─3.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─3.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─3.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─3.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─3.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─3.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─3.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─3.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─3.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─3.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─3.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─3.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─3.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─3.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─3.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─3.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─3.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─3.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─3.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─3.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─3.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─3.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─4.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─4.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─4.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─4.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─4.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─4.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─4.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─4.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─4.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─4.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─4.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─4.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─4.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─4.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─4.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─4.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─4.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─4.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─4.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─4.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─4.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─4.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─5.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─5.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─5.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─5.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─5.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─5.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─5.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─5.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─5.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─5.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─5.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─5.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─5.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─5.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─5.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─5.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─5.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─5.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─5.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─5.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─5.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─5.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─6.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─6.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─6.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─6.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─6.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─6.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─6.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─6.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─6.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─6.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─6.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─6.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─6.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─6.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─6.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─6.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─6.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─6.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─6.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─6.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─6.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─6.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─7.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─7.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─7.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─7.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─7.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─7.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─7.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─7.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─7.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─7.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─7.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─7.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─7.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─7.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─7.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─7.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─7.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─7.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─7.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─7.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─7.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─7.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─8.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─8.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─8.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─8.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─8.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─8.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─8.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─8.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─8.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─8.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─8.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─8.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─8.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─8.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─8.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─8.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─8.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─8.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─8.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─8.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─8.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─8.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─9.attention.self.query.weight          ├─1,048,576\n",
      "│    │    │    └─9.attention.self.query.bias            ├─1,024\n",
      "│    │    │    └─9.attention.self.key.weight            ├─1,048,576\n",
      "│    │    │    └─9.attention.self.key.bias              ├─1,024\n",
      "│    │    │    └─9.attention.self.value.weight          ├─1,048,576\n",
      "│    │    │    └─9.attention.self.value.bias            ├─1,024\n",
      "│    │    │    └─9.attention.self.w2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─9.attention.self.w2e_query.bias        ├─1,024\n",
      "│    │    │    └─9.attention.self.e2w_query.weight      ├─1,048,576\n",
      "│    │    │    └─9.attention.self.e2w_query.bias        ├─1,024\n",
      "│    │    │    └─9.attention.self.e2e_query.weight      ├─1,048,576\n",
      "│    │    │    └─9.attention.self.e2e_query.bias        ├─1,024\n",
      "│    │    │    └─9.attention.output.dense.weight        ├─1,048,576\n",
      "│    │    │    └─9.attention.output.dense.bias          ├─1,024\n",
      "│    │    │    └─9.attention.output.LayerNorm.weight    ├─1,024\n",
      "│    │    │    └─9.attention.output.LayerNorm.bias      ├─1,024\n",
      "│    │    │    └─9.intermediate.dense.weight            ├─4,194,304\n",
      "│    │    │    └─9.intermediate.dense.bias              ├─4,096\n",
      "│    │    │    └─9.output.dense.weight                  ├─4,194,304\n",
      "│    │    │    └─9.output.dense.bias                    ├─1,024\n",
      "│    │    │    └─9.output.LayerNorm.weight              ├─1,024\n",
      "│    │    │    └─9.output.LayerNorm.bias                ├─1,024\n",
      "│    │    │    └─10.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─10.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─10.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─10.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─10.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─10.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─10.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─10.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─10.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─10.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─10.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─10.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─10.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─10.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─10.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─10.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─10.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─10.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─10.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─10.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─10.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─10.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─11.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─11.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─11.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─11.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─11.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─11.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─11.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─11.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─11.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─11.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─11.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─11.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─11.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─11.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─11.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─11.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─11.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─11.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─11.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─11.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─11.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─11.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─12.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─12.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─12.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─12.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─12.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─12.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─12.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─12.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─12.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─12.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─12.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─12.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─12.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─12.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─12.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─12.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─12.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─12.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─12.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─12.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─12.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─12.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─13.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─13.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─13.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─13.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─13.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─13.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─13.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─13.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─13.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─13.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─13.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─13.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─13.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─13.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─13.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─13.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─13.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─13.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─13.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─13.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─13.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─13.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─14.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─14.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─14.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─14.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─14.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─14.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─14.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─14.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─14.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─14.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─14.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─14.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─14.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─14.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─14.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─14.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─14.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─14.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─14.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─14.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─14.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─14.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─15.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─15.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─15.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─15.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─15.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─15.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─15.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─15.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─15.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─15.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─15.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─15.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─15.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─15.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─15.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─15.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─15.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─15.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─15.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─15.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─15.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─15.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─16.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─16.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─16.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─16.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─16.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─16.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─16.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─16.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─16.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─16.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─16.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─16.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─16.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─16.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─16.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─16.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─16.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─16.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─16.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─16.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─16.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─16.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─17.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─17.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─17.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─17.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─17.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─17.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─17.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─17.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─17.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─17.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─17.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─17.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─17.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─17.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─17.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─17.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─17.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─17.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─17.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─17.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─17.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─17.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─18.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─18.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─18.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─18.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─18.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─18.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─18.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─18.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─18.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─18.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─18.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─18.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─18.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─18.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─18.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─18.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─18.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─18.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─18.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─18.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─18.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─18.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─19.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─19.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─19.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─19.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─19.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─19.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─19.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─19.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─19.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─19.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─19.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─19.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─19.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─19.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─19.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─19.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─19.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─19.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─19.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─19.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─19.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─19.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─20.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─20.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─20.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─20.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─20.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─20.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─20.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─20.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─20.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─20.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─20.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─20.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─20.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─20.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─20.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─20.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─20.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─20.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─20.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─20.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─20.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─20.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─21.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─21.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─21.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─21.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─21.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─21.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─21.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─21.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─21.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─21.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─21.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─21.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─21.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─21.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─21.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─21.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─21.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─21.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─21.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─21.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─21.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─21.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─22.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─22.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─22.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─22.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─22.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─22.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─22.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─22.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─22.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─22.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─22.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─22.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─22.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─22.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─22.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─22.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─22.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─22.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─22.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─22.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─22.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─22.output.LayerNorm.bias               ├─1,024\n",
      "│    │    │    └─23.attention.self.query.weight         ├─1,048,576\n",
      "│    │    │    └─23.attention.self.query.bias           ├─1,024\n",
      "│    │    │    └─23.attention.self.key.weight           ├─1,048,576\n",
      "│    │    │    └─23.attention.self.key.bias             ├─1,024\n",
      "│    │    │    └─23.attention.self.value.weight         ├─1,048,576\n",
      "│    │    │    └─23.attention.self.value.bias           ├─1,024\n",
      "│    │    │    └─23.attention.self.w2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─23.attention.self.w2e_query.bias       ├─1,024\n",
      "│    │    │    └─23.attention.self.e2w_query.weight     ├─1,048,576\n",
      "│    │    │    └─23.attention.self.e2w_query.bias       ├─1,024\n",
      "│    │    │    └─23.attention.self.e2e_query.weight     ├─1,048,576\n",
      "│    │    │    └─23.attention.self.e2e_query.bias       ├─1,024\n",
      "│    │    │    └─23.attention.output.dense.weight       ├─1,048,576\n",
      "│    │    │    └─23.attention.output.dense.bias         ├─1,024\n",
      "│    │    │    └─23.attention.output.LayerNorm.weight   ├─1,024\n",
      "│    │    │    └─23.attention.output.LayerNorm.bias     ├─1,024\n",
      "│    │    │    └─23.intermediate.dense.weight           ├─4,194,304\n",
      "│    │    │    └─23.intermediate.dense.bias             ├─4,096\n",
      "│    │    │    └─23.output.dense.weight                 ├─4,194,304\n",
      "│    │    │    └─23.output.dense.bias                   ├─1,024\n",
      "│    │    │    └─23.output.LayerNorm.weight             ├─1,024\n",
      "│    │    │    └─23.output.LayerNorm.bias               └─1,024\n",
      "│    └─LukePooler: 2-4                                  --\n",
      "│    │    └─dense.weight                                ├─1,048,576\n",
      "│    │    └─dense.bias                                  └─1,024\n",
      "│    │    └─Linear: 3-13                                1,049,600\n",
      "│    │    │    └─weight                                 ├─1,048,576\n",
      "│    │    │    └─bias                                   └─1,024\n",
      "│    │    └─Tanh: 3-14                                  --\n",
      "├─Dropout: 1-2                                          --\n",
      "├─Linear: 1-3                                           86,016\n",
      "│    └─weight                                           └─86,016\n",
      "================================================================================\n",
      "Total params: 559,810,560\n",
      "Trainable params: 559,810,560\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import LukeForEntityPairClassification\n",
    "\n",
    "model = LukeForEntityPairClassification.from_pretrained(\"studio-ousia/luke-large-finetuned-tacred\")\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50684df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
